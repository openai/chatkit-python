{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ChatKit Python SDK","text":"<p>Welcome to the ChatKit Python SDK documentation. This overview page links to the most important places to get started.</p> <ul> <li>Quick start</li> <li>Core concepts</li> <li>Respond to a user message</li> <li>Prepare your app for production</li> <li>API reference</li> <li>ChatKit JS docs</li> <li>Release process / changelog</li> </ul> <p>Use the navigation on the left to browse the full set of guides and API reference.</p>"},{"location":"quickstart/","title":"Quick start","text":"<p>To get a basic ChatKit app running\u2014a React chat UI talking to a Python server\u2014clone and run the starter app:</p> <pre><code>git clone https://github.com/openai/openai-chatkit-starter-app.git\ncd openai-chatkit-starter-app/chatkit\nnpm install\nnpm run dev\n</code></pre> <p>The sections below explain the core components and steps behind the starter app.</p>"},{"location":"quickstart/#render-chat-ui","title":"Render chat UI","text":"<p>!!! note \"Quick start uses React\"     This section shows the React integration using <code>@openai/chatkit-react</code>.     If you\u2019re not using React, you can render ChatKit directly with vanilla JavaScript using <code>@openai/chatkit</code>. See the ChatKit.js quick start for details.</p> <p>Install the React bindings:</p> <pre><code>npm install @openai/chatkit-react\n</code></pre> <p>In your index.html, load ChatKit.js:</p> <pre><code>&lt;!doctype html&gt;\n&lt;html lang=\"en\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"UTF-8\" /&gt;\n    &lt;script src=\"https://cdn.platform.openai.com/deployments/chatkit/chatkit.js\"&gt;&lt;/script&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"root\"&gt;&lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Wire up a minimal React app. Point <code>api.url</code> at your ChatKit server endpoint and pass the domain key you configured there.</p> <pre><code>import {ChatKit, useChatKit} from \"@openai/chatkit-react\";\n\nexport function App() {\n  const chatkit = useChatKit({\n    api: {\n      url: \"http://localhost:8000/chatkit\",\n      domainKey: \"local-dev\", // domain keys are optional in dev\n    },\n  });\n\n  return &lt;ChatKit control={chatkit.control} /&gt;;\n}\n</code></pre> <p>The chat UI will render, but sending messages will fail until you start the server below and provide a store for threads and messages.</p>"},{"location":"quickstart/#run-your-chatkit-server","title":"Run your ChatKit server","text":"<p>Install the ChatKit Python package and expose a single <code>/chatkit</code> endpoint that forwards requests to a <code>ChatKitServer</code> instance.</p> <pre><code>pip install openai-chatkit\n</code></pre> <p>Create <code>main.py</code> with a minimal server that is hard-coded to always reply \u201cHello, world!\u201d\u2014you'll replace this with an actual call to a model in Respond to a user message.</p> <pre><code># Other imports omitted for brevity; see the starter repo for a runnable file with all imports.\nfrom chatkit.server import ChatKitServer\n\napp = FastAPI()\n\n\nclass MyChatKitServer(ChatKitServer[dict]):\n    async def respond(\n        self,\n        thread: ThreadMetadata,\n        input_user_message: UserMessageItem | None,\n        context: dict,\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        # Streams a fixed \"Hello, world!\" assistant message\n        yield ThreadItemDoneEvent(\n            item=AssistantMessageItem(\n                thread_id=thread.id,\n                id=self.store.generate_item_id(\"message\", thread, context),\n                created_at=datetime.now(),\n                content=[AssistantMessageContent(text=\"Hello, world!\")],\n            ),\n        )\n\n# Create your server by passing a store implementation.\n# MyChatKitStore is defined in the next section.\nserver = MyChatKitServer(store=MyChatKitStore())\n\n\n@app.post(\"/chatkit\")\nasync def chatkit(request: Request):\n    result = await server.process(await request.body(), context={})\n    if isinstance(result, StreamingResult):\n        return StreamingResponse(result, media_type=\"text/event-stream\")\n    return Response(content=result.json, media_type=\"application/json\")\n</code></pre> <p>All ChatKit requests go to this single endpoint. Set <code>api.url</code> on the React side to match (<code>/chatkit</code> here), and <code>ChatKitServer</code> routes each request internally.</p>"},{"location":"quickstart/#store-chat-data","title":"Store chat data","text":"<p>ChatKit servers require a store to load and save threads, messages, and other items.</p> <p>For this quickstart, use a small in-memory store so conversations persist while the process is running, without introducing a database. This keeps the example minimal while still matching real ChatKit behavior.</p> <pre><code>from collections import defaultdict\nfrom chatkit.store import NotFoundError, Store\nfrom chatkit.types import Attachment, Page, ThreadItem, ThreadMetadata\n\n\nclass MyChatKitStore(Store[dict]):\n    def __init__(self):\n        self.threads: dict[str, ThreadMetadata] = {}\n        self.items: dict[str, list[ThreadItem]] = defaultdict(list)\n\n    async def load_thread(self, thread_id: str, context: dict) -&gt; ThreadMetadata:\n        if thread_id not in self.threads:\n            raise NotFoundError(f\"Thread {thread_id} not found\")\n        return self.threads[thread_id]\n\n    async def save_thread(self, thread: ThreadMetadata, context: dict) -&gt; None:\n        self.threads[thread.id] = thread\n\n    async def load_threads(\n        self, limit: int, after: str | None, order: str, context: dict\n    ) -&gt; Page[ThreadMetadata]:\n        threads = list(self.threads.values())\n        return self._paginate(\n            threads, after, limit, order, sort_key=lambda t: t.created_at, cursor_key=lambda t: t.id\n        )\n\n    async def load_thread_items(\n        self, thread_id: str, after: str | None, limit: int, order: str, context: dict\n    ) -&gt; Page[ThreadItem]:\n        items = self.items.get(thread_id, [])\n        return self._paginate(\n            items, after, limit, order, sort_key=lambda i: i.created_at, cursor_key=lambda i: i.id\n        )\n\n    async def add_thread_item(\n        self, thread_id: str, item: ThreadItem, context: dict\n    ) -&gt; None:\n        self.items[thread_id].append(item)\n\n    async def save_item(\n        self, thread_id: str, item: ThreadItem, context: dict\n    ) -&gt; None:\n        items = self.items[thread_id]\n        for idx, existing in enumerate(items):\n            if existing.id == item.id:\n                items[idx] = item\n                return\n        items.append(item)\n\n    async def load_item(\n        self, thread_id: str, item_id: str, context: dict\n    ) -&gt; ThreadItem:\n        for item in self.items.get(thread_id, []):\n            if item.id == item_id:\n                return item\n        raise NotFoundError(f\"Item {item_id} not found in thread {thread_id}\")\n\n    async def delete_thread(self, thread_id: str, context: dict) -&gt; None:\n        self.threads.pop(thread_id, None)\n        self.items.pop(thread_id, None)\n\n    async def delete_thread_item(\n        self, thread_id: str, item_id: str, context: dict\n    ) -&gt; None:\n        self.items[thread_id] = [\n            item for item in self.items.get(thread_id, []) if item.id != item_id\n        ]\n\n    def _paginate(self, rows: list, after: str | None, limit: int, order: str, sort_key, cursor_key):\n        sorted_rows = sorted(rows, key=sort_key, reverse=order == \"desc\")\n        start = 0\n        if after:\n            for idx, row in enumerate(sorted_rows):\n                if cursor_key(row) == after:\n                    start = idx + 1\n                    break\n        data = sorted_rows[start : start + limit]\n        has_more = start + limit &lt; len(sorted_rows)\n        next_after = cursor_key(data[-1]) if has_more and data else None\n        return Page(data=data, has_more=has_more, after=next_after)\n\n    # Attachments are intentionally not implemented for the quickstart\n\n    async def save_attachment(\n        self, attachment: Attachment, context: dict\n    ) -&gt; None:\n        raise NotImplementedError()\n\n    async def load_attachment(\n        self, attachment_id: str, context: dict\n    ) -&gt; Attachment:\n        raise NotImplementedError()\n\n    async def delete_attachment(self, attachment_id: str, context: dict) -&gt; None:\n        raise NotImplementedError()\n</code></pre> <p>This store implements only the methods required for basic chat while the server is running; persistence across restarts and attachments are intentionally omitted.</p> <p>For production, replace this with a database-backed store (for example, Postgres or MySQL) so threads and items persist across restarts.</p>"},{"location":"quickstart/#generate-model-responses","title":"Generate model responses","text":"<p>Replace the hardcoded \"Hello, World!\" reply from Run your ChatKit server with an Agents SDK call to generate real responses. Set <code>OPENAI_API_KEY</code> in your environment before running.</p> <p>Use ChatKit's Agents SDK helpers to simplify request conversion and streaming. The <code>simple_to_agent_input</code> helper translates ChatKit thread items to agent input items, and <code>stream_agent_response</code> turns the streamed run into ChatKit events:</p> <pre><code>from agents import Agent, Runner\nfrom chatkit.agents import AgentContext, simple_to_agent_input, stream_agent_response\n\nassistant = Agent(\n    name=\"assistant\",\n    instructions=\"You are a helpful assistant.\",\n    model=\"gpt-4.1-mini\",\n)\n\nclass MyChatKitServer(ChatKitServer[dict]):\n    async def respond(\n        self,\n        thread: ThreadMetadata,\n        input_user_message: UserMessageItem | None,\n        context: dict,\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        # Convert recent thread items (which includes the user message) to model input\n        items_page = await self.store.load_thread_items(\n            thread.id,\n            after=None,\n            limit=20,\n            order=\"asc\",\n            context=context,\n        )\n        input_items = await simple_to_agent_input(items_page.data)\n\n        # Stream the run through ChatKit events\n        agent_context = AgentContext(thread=thread, store=self.store, request_context=context)\n        result = Runner.run_streamed(assistant, input_items, context=agent_context)\n        async for event in stream_agent_response(agent_context, result):\n            yield event\n</code></pre>"},{"location":"release/","title":"Release process/changelog","text":"<p>The project follows a slightly modified version of semantic versioning. The SDK is still evolving and certain backwards-incompatible changes may be released as minor versions.</p> <p>For full release notes, see https://github.com/openai/chatkit-python/releases.</p>"},{"location":"release/#minor-versions","title":"Minor versions","text":"<p>We will increase minor versions for breaking changes to any public interfaces. For example, going from <code>1.0.x</code> to <code>1.1.x</code> might include breaking changes.</p> <p>If you don't want breaking changes, we recommend pinning to <code>1.0.x</code> versions in your project.</p>"},{"location":"release/#patch-versions","title":"Patch versions","text":"<p>We will increment patch versions for non-breaking changes:</p> <ul> <li>Bug fixes</li> <li>New features</li> <li>Changes to private interfaces</li> </ul>"},{"location":"release/#breaking-change-changelog","title":"Breaking change changelog","text":""},{"location":"release/#160","title":"1.6.0","text":"<ul> <li><code>Store.save_attachment</code> may now be called with updates to existing attachments (treated as an upsert), not only inserts.</li> </ul>"},{"location":"release/#150","title":"1.5.0","text":"<p>Two-phase uploads:</p> <ul> <li><code>upload_url</code> was removed from <code>FileAttachment</code> and <code>ImageAttachment</code>; use <code>upload_descriptor</code> instead.</li> <li><code>ChatKitServer</code> now saves the created attachment metadata in the store when handling the <code>attachments.create</code> request; remove the store-write step in <code>AttachmentStore.create_attachment</code>.</li> </ul>"},{"location":"release/#140","title":"1.4.0","text":"<ul> <li>Widget and action classes are still usable but marked as deprecated in favor of using <code>WidgetTemplate</code> to build widgets from <code>.widget</code> files.</li> <li>Added <code>jinja2</code> as a required dependency for widget template rendering.</li> <li>A stop button is now shown by default during streaming, allowing users to cancel the stream mid-response. Integrations can override <code>ChatKitServer.get_stream_options</code> to change this behavior.</li> </ul>"},{"location":"release/#130","title":"1.3.0","text":"<ul> <li>Fixed the type for the <code>defaultChecked</code> property of <code>Checkbox</code> widgets, updating it from <code>string</code> to <code>bool</code>.</li> </ul>"},{"location":"release/#120","title":"1.2.0","text":"<ul> <li>Updated <code>agents.stream_agent_response</code> to add annotation parts as they are received rather than adding all the annotations at the end after the response is completed.</li> <li>Added support for rendering <code>container_file_citation</code>.</li> </ul>"},{"location":"release/#110","title":"1.1.0","text":"<ul> <li><code>CustomSummary</code>, <code>CustomTask</code>, and <code>EntitySource</code> types have been updated to restrict <code>icon</code> to <code>IconName</code>.</li> <li>All <code>ThreadItemConverter</code> methods have been updated to be asynchronous.</li> </ul>"},{"location":"api/chatkit/","title":"Chatkit Python API Reference","text":"<p>What you'll find here:</p> <ul> <li>Core server API: <code>chatkit.server</code> \u2013 <code>ChatKitServer</code> and related helpers for receiving messages, streaming responses, and wiring up tools and widgets.</li> <li>Store integration: <code>chatkit.store</code> \u2013 interfaces and utilities for persisting threads, items, and metadata.</li> <li>Agents integration helpers: <code>chatkit.agents</code> \u2013 helpers and utilities for using ChatKit together with the Agents SDK.</li> <li>Data models and types: <code>chatkit.types</code> \u2013 Pydantic models for threads, items, events, and other shared types.</li> <li>Errors: <code>chatkit.errors</code> \u2013 structured error types your ChatKit integration can raise so ChatKit can emit consistent <code>ErrorEvent</code>s to the client.</li> <li>Widgets: <code>chatkit.widgets</code> \u2013 models and helpers such as <code>WidgetTemplate</code>, <code>DynamicWidgetRoot</code>, and <code>BasicRoot</code> for building rich UI responses.</li> </ul>"},{"location":"api/chatkit/agents/","title":"agents","text":""},{"location":"api/chatkit/agents/#chatkit.agents.ClientToolCall","title":"ClientToolCall","text":"<p>               Bases: <code>BaseModel</code></p> <p>Returned from tool methods to indicate a client-side tool call.</p> Source code in <code>chatkit/agents.py</code> <pre><code>class ClientToolCall(BaseModel):\n    \"\"\"\n    Returned from tool methods to indicate a client-side tool call.\n    \"\"\"\n\n    name: str\n    arguments: dict[str, Any]\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.AgentContext","title":"AgentContext","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[TContext]</code></p> Source code in <code>chatkit/agents.py</code> <pre><code>class AgentContext(BaseModel, Generic[TContext]):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    thread: ThreadMetadata\n    store: Annotated[Store[TContext], SkipValidation]\n    request_context: TContext\n    previous_response_id: str | None = None\n    client_tool_call: ClientToolCall | None = None\n    workflow_item: WorkflowItem | None = None\n    generated_image_item: GeneratedImageItem | None = None\n    _events: asyncio.Queue[ThreadStreamEvent | _QueueCompleteSentinel] = asyncio.Queue()\n\n    def generate_id(\n        self, type: StoreItemType, thread: ThreadMetadata | None = None\n    ) -&gt; str:\n        \"\"\"Generate a new store-backed id for the given item type.\"\"\"\n        if type == \"thread\":\n            return self.store.generate_thread_id(self.request_context)\n        return self.store.generate_item_id(\n            type, thread or self.thread, self.request_context\n        )\n\n    async def stream_widget(\n        self,\n        widget: WidgetRoot | AsyncGenerator[WidgetRoot, None],\n        copy_text: str | None = None,\n    ) -&gt; None:\n        \"\"\"Stream a widget into the thread by enqueueing widget events.\"\"\"\n        async for event in stream_widget(\n            self.thread,\n            widget,\n            copy_text,\n            lambda item_type: self.store.generate_item_id(\n                item_type, self.thread, self.request_context\n            ),\n        ):\n            await self._events.put(event)\n\n    async def end_workflow(\n        self, summary: WorkflowSummary | None = None, expanded: bool = False\n    ) -&gt; None:\n        \"\"\"Finalize the active workflow item, optionally attaching a summary.\"\"\"\n        if not self.workflow_item:\n            # No workflow to end\n            return\n\n        if summary is not None:\n            self.workflow_item.workflow.summary = summary\n        elif self.workflow_item.workflow.summary is None:\n            # If no summary was set or provided, set a basic work summary\n            delta = datetime.now() - self.workflow_item.created_at\n            duration = int(delta.total_seconds())\n            self.workflow_item.workflow.summary = DurationSummary(duration=duration)\n        self.workflow_item.workflow.expanded = expanded\n        await self.stream(ThreadItemDoneEvent(item=self.workflow_item))\n        self.workflow_item = None\n\n    async def start_workflow(self, workflow: Workflow) -&gt; None:\n        \"\"\"Begin streaming a new workflow item.\"\"\"\n        self.workflow_item = WorkflowItem(\n            id=self.generate_id(\"workflow\"),\n            created_at=datetime.now(),\n            workflow=workflow,\n            thread_id=self.thread.id,\n        )\n\n        if workflow.type != \"reasoning\" and len(workflow.tasks) == 0:\n            # Defer sending added event until we have tasks\n            return\n\n        await self.stream(ThreadItemAddedEvent(item=self.workflow_item))\n\n    async def update_workflow_task(self, task: Task, task_index: int) -&gt; None:\n        \"\"\"Update an existing workflow task and stream the delta.\"\"\"\n        if self.workflow_item is None:\n            raise ValueError(\"Workflow is not set\")\n        # ensure reference is updated in case task is a copy\n        self.workflow_item.workflow.tasks[task_index] = task\n        await self.stream(\n            ThreadItemUpdatedEvent(\n                item_id=self.workflow_item.id,\n                update=WorkflowTaskUpdated(\n                    task=task,\n                    task_index=task_index,\n                ),\n            )\n        )\n\n    async def add_workflow_task(self, task: Task) -&gt; None:\n        \"\"\"Append a workflow task and stream the appropriate event.\"\"\"\n        self.workflow_item = self.workflow_item or WorkflowItem(\n            id=self.generate_id(\"workflow\"),\n            created_at=datetime.now(),\n            workflow=Workflow(type=\"custom\", tasks=[]),\n            thread_id=self.thread.id,\n        )\n        workflow = self.workflow_item.workflow\n        workflow.tasks.append(task)\n\n        if workflow.type != \"reasoning\" and len(workflow.tasks) == 1:\n            await self.stream(ThreadItemAddedEvent(item=self.workflow_item))\n        else:\n            await self.stream(\n                ThreadItemUpdatedEvent(\n                    item_id=self.workflow_item.id,\n                    update=WorkflowTaskAdded(\n                        task=task,\n                        task_index=workflow.tasks.index(task),\n                    ),\n                )\n            )\n\n    async def stream(self, event: ThreadStreamEvent) -&gt; None:\n        \"\"\"Enqueue a ThreadStreamEvent for downstream processing.\"\"\"\n        await self._events.put(event)\n\n    def _complete(self):\n        self._events.put_nowait(_QueueCompleteSentinel())\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.AgentContext.generate_id","title":"generate_id","text":"<pre><code>generate_id(\n    type: StoreItemType,\n    thread: ThreadMetadata | None = None,\n) -&gt; str\n</code></pre> <p>Generate a new store-backed id for the given item type.</p> Source code in <code>chatkit/agents.py</code> <pre><code>def generate_id(\n    self, type: StoreItemType, thread: ThreadMetadata | None = None\n) -&gt; str:\n    \"\"\"Generate a new store-backed id for the given item type.\"\"\"\n    if type == \"thread\":\n        return self.store.generate_thread_id(self.request_context)\n    return self.store.generate_item_id(\n        type, thread or self.thread, self.request_context\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.AgentContext.stream_widget","title":"stream_widget  <code>async</code>","text":"<pre><code>stream_widget(\n    widget: WidgetRoot | AsyncGenerator[WidgetRoot, None],\n    copy_text: str | None = None,\n) -&gt; None\n</code></pre> <p>Stream a widget into the thread by enqueueing widget events.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def stream_widget(\n    self,\n    widget: WidgetRoot | AsyncGenerator[WidgetRoot, None],\n    copy_text: str | None = None,\n) -&gt; None:\n    \"\"\"Stream a widget into the thread by enqueueing widget events.\"\"\"\n    async for event in stream_widget(\n        self.thread,\n        widget,\n        copy_text,\n        lambda item_type: self.store.generate_item_id(\n            item_type, self.thread, self.request_context\n        ),\n    ):\n        await self._events.put(event)\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.AgentContext.end_workflow","title":"end_workflow  <code>async</code>","text":"<pre><code>end_workflow(\n    summary: WorkflowSummary | None = None,\n    expanded: bool = False,\n) -&gt; None\n</code></pre> <p>Finalize the active workflow item, optionally attaching a summary.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def end_workflow(\n    self, summary: WorkflowSummary | None = None, expanded: bool = False\n) -&gt; None:\n    \"\"\"Finalize the active workflow item, optionally attaching a summary.\"\"\"\n    if not self.workflow_item:\n        # No workflow to end\n        return\n\n    if summary is not None:\n        self.workflow_item.workflow.summary = summary\n    elif self.workflow_item.workflow.summary is None:\n        # If no summary was set or provided, set a basic work summary\n        delta = datetime.now() - self.workflow_item.created_at\n        duration = int(delta.total_seconds())\n        self.workflow_item.workflow.summary = DurationSummary(duration=duration)\n    self.workflow_item.workflow.expanded = expanded\n    await self.stream(ThreadItemDoneEvent(item=self.workflow_item))\n    self.workflow_item = None\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.AgentContext.start_workflow","title":"start_workflow  <code>async</code>","text":"<pre><code>start_workflow(workflow: Workflow) -&gt; None\n</code></pre> <p>Begin streaming a new workflow item.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def start_workflow(self, workflow: Workflow) -&gt; None:\n    \"\"\"Begin streaming a new workflow item.\"\"\"\n    self.workflow_item = WorkflowItem(\n        id=self.generate_id(\"workflow\"),\n        created_at=datetime.now(),\n        workflow=workflow,\n        thread_id=self.thread.id,\n    )\n\n    if workflow.type != \"reasoning\" and len(workflow.tasks) == 0:\n        # Defer sending added event until we have tasks\n        return\n\n    await self.stream(ThreadItemAddedEvent(item=self.workflow_item))\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.AgentContext.update_workflow_task","title":"update_workflow_task  <code>async</code>","text":"<pre><code>update_workflow_task(task: Task, task_index: int) -&gt; None\n</code></pre> <p>Update an existing workflow task and stream the delta.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def update_workflow_task(self, task: Task, task_index: int) -&gt; None:\n    \"\"\"Update an existing workflow task and stream the delta.\"\"\"\n    if self.workflow_item is None:\n        raise ValueError(\"Workflow is not set\")\n    # ensure reference is updated in case task is a copy\n    self.workflow_item.workflow.tasks[task_index] = task\n    await self.stream(\n        ThreadItemUpdatedEvent(\n            item_id=self.workflow_item.id,\n            update=WorkflowTaskUpdated(\n                task=task,\n                task_index=task_index,\n            ),\n        )\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.AgentContext.add_workflow_task","title":"add_workflow_task  <code>async</code>","text":"<pre><code>add_workflow_task(task: Task) -&gt; None\n</code></pre> <p>Append a workflow task and stream the appropriate event.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def add_workflow_task(self, task: Task) -&gt; None:\n    \"\"\"Append a workflow task and stream the appropriate event.\"\"\"\n    self.workflow_item = self.workflow_item or WorkflowItem(\n        id=self.generate_id(\"workflow\"),\n        created_at=datetime.now(),\n        workflow=Workflow(type=\"custom\", tasks=[]),\n        thread_id=self.thread.id,\n    )\n    workflow = self.workflow_item.workflow\n    workflow.tasks.append(task)\n\n    if workflow.type != \"reasoning\" and len(workflow.tasks) == 1:\n        await self.stream(ThreadItemAddedEvent(item=self.workflow_item))\n    else:\n        await self.stream(\n            ThreadItemUpdatedEvent(\n                item_id=self.workflow_item.id,\n                update=WorkflowTaskAdded(\n                    task=task,\n                    task_index=workflow.tasks.index(task),\n                ),\n            )\n        )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.AgentContext.stream","title":"stream  <code>async</code>","text":"<pre><code>stream(event: ThreadStreamEvent) -&gt; None\n</code></pre> <p>Enqueue a ThreadStreamEvent for downstream processing.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def stream(self, event: ThreadStreamEvent) -&gt; None:\n    \"\"\"Enqueue a ThreadStreamEvent for downstream processing.\"\"\"\n    await self._events.put(event)\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ResponseStreamConverter","title":"ResponseStreamConverter","text":"<p>Used by <code>stream_agent_response</code> to convert streamed Agents SDK output into values used by ChatKit thread items and thread stream events.</p> <p>Defines overridable methods for adapting streamed data (such as image generation results and partial updates) into the forms expected by ChatKit.</p> Source code in <code>chatkit/agents.py</code> <pre><code>class ResponseStreamConverter:\n    \"\"\"Used by `stream_agent_response` to convert streamed Agents SDK output\n    into values used by ChatKit thread items and thread stream events.\n\n    Defines overridable methods for adapting streamed data (such as image\n    generation results and partial updates) into the forms expected by ChatKit.\n    \"\"\"\n\n    partial_images: int | None = None\n    \"\"\"\n    The expected number of partial image updates for an image generation result.\n\n    When set, this value is used to normalize partial image indices into a\n    progress value in the range [0, 1]. If unset, all partial image updates are\n    assigned a progress value of 0.\n    \"\"\"\n\n    def __init__(self, *, partial_images: int | None = None):\n        \"\"\"\n        Args:\n            partial_images: The expected number of partial image updates for image\n                generation results, or None if no progress normalization should\n                be performed.\n        \"\"\"\n        self.partial_images = partial_images\n\n    async def base64_image_to_url(\n        self,\n        image_id: str,\n        base64_image: str,\n        partial_image_index: int | None = None,\n    ) -&gt; str:\n        \"\"\"\n        Convert a base64-encoded image into a URL.\n\n        This method is used to produce the URL stored on thread items for image\n        generation results.\n\n        Args:\n            image_id: The ID of the image generation call. This stays stable across partial image updates.\n            base64_image: The base64-encoded image.\n            partial_image_index: The index of the partial image update, starting from 0.\n\n        Returns:\n            A URL string.\n        \"\"\"\n        return f\"data:image/png;base64,{base64_image}\"\n\n    def partial_image_index_to_progress(self, partial_image_index: int) -&gt; float:\n        \"\"\"\n        Convert a partial image index into a normalized progress value.\n\n        Args:\n            partial_image_index: The index of the partial image update, starting from 0.\n\n        Returns:\n            A float between 0 and 1 representing progress for the image\n            generation result.\n        \"\"\"\n        if self.partial_images is None or self.partial_images &lt;= 0:\n            return 0.0\n\n        return min(1.0, partial_image_index / self.partial_images)\n\n    async def file_citation_to_annotation(\n        self, file_citation: AnnotationFileCitation\n    ) -&gt; Annotation | None:\n        \"\"\"Convert a Responses API file citation into an assistant message annotation.\"\"\"\n        filename = file_citation.filename\n        if not filename:\n            return None\n\n        return Annotation(\n            source=FileSource(filename=filename, title=filename),\n            index=file_citation.index,\n        )\n\n    async def container_file_citation_to_annotation(\n        self, container_file_citation: AnnotationContainerFileCitation\n    ) -&gt; Annotation | None:\n        \"\"\"Convert a Responses API container file citation into an assistant message annotation.\"\"\"\n        filename = container_file_citation.filename\n        if not filename:\n            return None\n\n        return Annotation(\n            source=FileSource(filename=filename, title=filename),\n            index=container_file_citation.end_index,\n        )\n\n    async def url_citation_to_annotation(\n        self, url_citation: AnnotationURLCitation\n    ) -&gt; Annotation | None:\n        \"\"\"Convert a Responses API URL citation into an assistant message annotation.\"\"\"\n        return Annotation(\n            source=URLSource(url=url_citation.url, title=url_citation.title),\n            index=url_citation.end_index,\n        )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ResponseStreamConverter.partial_images","title":"partial_images  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>partial_images: int | None = partial_images\n</code></pre> <p>The expected number of partial image updates for an image generation result.</p> <p>When set, this value is used to normalize partial image indices into a progress value in the range [0, 1]. If unset, all partial image updates are assigned a progress value of 0.</p>"},{"location":"api/chatkit/agents/#chatkit.agents.ResponseStreamConverter.base64_image_to_url","title":"base64_image_to_url  <code>async</code>","text":"<pre><code>base64_image_to_url(\n    image_id: str,\n    base64_image: str,\n    partial_image_index: int | None = None,\n) -&gt; str\n</code></pre> <p>Convert a base64-encoded image into a URL.</p> <p>This method is used to produce the URL stored on thread items for image generation results.</p> <p>Parameters:</p> Name Type Description Default <code>image_id</code> <code>str</code> <p>The ID of the image generation call. This stays stable across partial image updates.</p> required <code>base64_image</code> <code>str</code> <p>The base64-encoded image.</p> required <code>partial_image_index</code> <code>int | None</code> <p>The index of the partial image update, starting from 0.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A URL string.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def base64_image_to_url(\n    self,\n    image_id: str,\n    base64_image: str,\n    partial_image_index: int | None = None,\n) -&gt; str:\n    \"\"\"\n    Convert a base64-encoded image into a URL.\n\n    This method is used to produce the URL stored on thread items for image\n    generation results.\n\n    Args:\n        image_id: The ID of the image generation call. This stays stable across partial image updates.\n        base64_image: The base64-encoded image.\n        partial_image_index: The index of the partial image update, starting from 0.\n\n    Returns:\n        A URL string.\n    \"\"\"\n    return f\"data:image/png;base64,{base64_image}\"\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ResponseStreamConverter.partial_image_index_to_progress","title":"partial_image_index_to_progress","text":"<pre><code>partial_image_index_to_progress(\n    partial_image_index: int,\n) -&gt; float\n</code></pre> <p>Convert a partial image index into a normalized progress value.</p> <p>Parameters:</p> Name Type Description Default <code>partial_image_index</code> <code>int</code> <p>The index of the partial image update, starting from 0.</p> required <p>Returns:</p> Type Description <code>float</code> <p>A float between 0 and 1 representing progress for the image</p> <code>float</code> <p>generation result.</p> Source code in <code>chatkit/agents.py</code> <pre><code>def partial_image_index_to_progress(self, partial_image_index: int) -&gt; float:\n    \"\"\"\n    Convert a partial image index into a normalized progress value.\n\n    Args:\n        partial_image_index: The index of the partial image update, starting from 0.\n\n    Returns:\n        A float between 0 and 1 representing progress for the image\n        generation result.\n    \"\"\"\n    if self.partial_images is None or self.partial_images &lt;= 0:\n        return 0.0\n\n    return min(1.0, partial_image_index / self.partial_images)\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ResponseStreamConverter.file_citation_to_annotation","title":"file_citation_to_annotation  <code>async</code>","text":"<pre><code>file_citation_to_annotation(\n    file_citation: AnnotationFileCitation,\n) -&gt; Annotation | None\n</code></pre> <p>Convert a Responses API file citation into an assistant message annotation.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def file_citation_to_annotation(\n    self, file_citation: AnnotationFileCitation\n) -&gt; Annotation | None:\n    \"\"\"Convert a Responses API file citation into an assistant message annotation.\"\"\"\n    filename = file_citation.filename\n    if not filename:\n        return None\n\n    return Annotation(\n        source=FileSource(filename=filename, title=filename),\n        index=file_citation.index,\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ResponseStreamConverter.container_file_citation_to_annotation","title":"container_file_citation_to_annotation  <code>async</code>","text":"<pre><code>container_file_citation_to_annotation(\n    container_file_citation: AnnotationContainerFileCitation,\n) -&gt; Annotation | None\n</code></pre> <p>Convert a Responses API container file citation into an assistant message annotation.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def container_file_citation_to_annotation(\n    self, container_file_citation: AnnotationContainerFileCitation\n) -&gt; Annotation | None:\n    \"\"\"Convert a Responses API container file citation into an assistant message annotation.\"\"\"\n    filename = container_file_citation.filename\n    if not filename:\n        return None\n\n    return Annotation(\n        source=FileSource(filename=filename, title=filename),\n        index=container_file_citation.end_index,\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ResponseStreamConverter.url_citation_to_annotation","title":"url_citation_to_annotation  <code>async</code>","text":"<pre><code>url_citation_to_annotation(\n    url_citation: AnnotationURLCitation,\n) -&gt; Annotation | None\n</code></pre> <p>Convert a Responses API URL citation into an assistant message annotation.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def url_citation_to_annotation(\n    self, url_citation: AnnotationURLCitation\n) -&gt; Annotation | None:\n    \"\"\"Convert a Responses API URL citation into an assistant message annotation.\"\"\"\n    return Annotation(\n        source=URLSource(url=url_citation.url, title=url_citation.title),\n        index=url_citation.end_index,\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter","title":"ThreadItemConverter","text":"<p>Converts thread items to Agent SDK input items. Widgets, Tasks, and Workflows have default conversions but can be customized. Attachments, Tags, and HiddenContextItems require custom handling based on the use case. Other item types are converted automatically.</p> Source code in <code>chatkit/agents.py</code> <pre><code>class ThreadItemConverter:\n    \"\"\"\n    Converts thread items to Agent SDK input items.\n    Widgets, Tasks, and Workflows have default conversions but can be customized.\n    Attachments, Tags, and HiddenContextItems require custom handling based on the use case.\n    Other item types are converted automatically.\n    \"\"\"\n\n    async def attachment_to_message_content(\n        self, attachment: Attachment\n    ) -&gt; ResponseInputContentParam:\n        \"\"\"\n        Convert an attachment in a user message into a message content part to send to the model.\n        Required when attachments are enabled.\n        \"\"\"\n        raise NotImplementedError(\n            \"An Attachment was included in a UserMessageItem but Converter.attachment_to_message_content was not implemented\"\n        )\n\n    async def tag_to_message_content(\n        self, tag: UserMessageTagContent\n    ) -&gt; ResponseInputContentParam:\n        \"\"\"\n        Convert a tag in a user message into a message content part to send to the model as context.\n        Required when tags are used.\n        \"\"\"\n        raise NotImplementedError(\n            \"A Tag was included in a UserMessageItem but Converter.tag_to_message_content is not implemented\"\n        )\n\n    async def generated_image_to_input(\n        self, item: GeneratedImageItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        \"\"\"\n        Convert a GeneratedImageItem into input item(s) to send to the model.\n        Override this method to customize the conversion of generated images, such as when your\n        generated image url is not publicly reachable.\n        \"\"\"\n        if not item.image:\n            return None\n\n        return Message(\n            type=\"message\",\n            content=[\n                ResponseInputTextParam(\n                    type=\"input_text\",\n                    text=\"The following image was generated by the agent.\",\n                ),\n                ResponseInputImageParam(\n                    type=\"input_image\",\n                    detail=\"auto\",\n                    image_url=item.image.url,\n                ),\n            ],\n            role=\"user\",\n        )\n\n    async def hidden_context_to_input(\n        self, item: HiddenContextItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        \"\"\"\n        Convert a HiddenContextItem into input item(s) to send to the model.\n        Required to override when HiddenContextItems with non-string content are used.\n        \"\"\"\n        if not isinstance(item.content, str):\n            raise NotImplementedError(\n                \"HiddenContextItems with non-string content were present in a user message but a Converter.hidden_context_to_input was not implemented\"\n            )\n\n        text = (\n            \"Hidden context for the agent (not shown to the user):\\n\"\n            f\"&lt;HiddenContext&gt;\\n{item.content}\\n&lt;/HiddenContext&gt;\"\n        )\n        return Message(\n            type=\"message\",\n            content=[\n                ResponseInputTextParam(\n                    type=\"input_text\",\n                    text=text,\n                )\n            ],\n            role=\"user\",\n        )\n\n    async def sdk_hidden_context_to_input(\n        self, item: SDKHiddenContextItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        \"\"\"\n        Convert a SDKHiddenContextItem into input item to send to the model.\n        This is used by the ChatKit Python SDK for storing additional context\n        for internal operations.\n        Override if you want to wrap the content in a different format.\n        \"\"\"\n        text = (\n            \"Hidden context for the agent (not shown to the user):\\n\"\n            f\"&lt;HiddenContext&gt;\\n{item.content}\\n&lt;/HiddenContext&gt;\"\n        )\n        return Message(\n            type=\"message\",\n            content=[\n                ResponseInputTextParam(\n                    type=\"input_text\",\n                    text=text,\n                )\n            ],\n            role=\"user\",\n        )\n\n    async def task_to_input(\n        self, item: TaskItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        \"\"\"\n        Convert a TaskItem into input item(s) to send to the model.\n        \"\"\"\n        if item.task.type != \"custom\" or (\n            not item.task.title and not item.task.content\n        ):\n            return None\n        title = f\"{item.task.title}\" if item.task.title else \"\"\n        content = f\"{item.task.content}\" if item.task.content else \"\"\n        task_text = f\"{title}: {content}\" if title and content else title or content\n        text = f\"A message was displayed to the user that the following task was performed:\\n&lt;Task&gt;\\n{task_text}\\n&lt;/Task&gt;\"\n        return Message(\n            type=\"message\",\n            content=[\n                ResponseInputTextParam(\n                    type=\"input_text\",\n                    text=text,\n                )\n            ],\n            role=\"user\",\n        )\n\n    async def workflow_to_input(\n        self, item: WorkflowItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        \"\"\"\n        Convert a TaskItem into input item(s) to send to the model.\n        Returns WorkflowItem.response_items by default.\n        \"\"\"\n        messages = []\n        for task in item.workflow.tasks:\n            if task.type != \"custom\" or (not task.title and not task.content):\n                continue\n\n            title = f\"{task.title}\" if task.title else \"\"\n            content = f\"{task.content}\" if task.content else \"\"\n            task_text = f\"{title}: {content}\" if title and content else title or content\n            text = f\"A message was displayed to the user that the following task was performed:\\n&lt;Task&gt;\\n{task_text}\\n&lt;/Task&gt;\"\n            messages.append(\n                Message(\n                    type=\"message\",\n                    content=[\n                        ResponseInputTextParam(\n                            type=\"input_text\",\n                            text=text,\n                        )\n                    ],\n                    role=\"user\",\n                )\n            )\n        return messages\n\n    async def widget_to_input(\n        self, item: WidgetItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        \"\"\"\n        Convert a WidgetItem into input item(s) to send to the model.\n        By default, WidgetItems converted to a text description with a JSON representation of the widget.\n        \"\"\"\n        return Message(\n            type=\"message\",\n            content=[\n                ResponseInputTextParam(\n                    type=\"input_text\",\n                    text=f\"The following graphical UI widget (id: {item.id}) was displayed to the user:\"\n                    + item.widget.model_dump_json(\n                        exclude_unset=True, exclude_none=True\n                    ),\n                )\n            ],\n            role=\"user\",\n        )\n\n    async def user_message_to_input(\n        self, item: UserMessageItem, is_last_message: bool = True\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        # Build the user text exactly as typed, rendering tags as @key\n        message_text_parts: list[str] = []\n        # Track tags separately to add system context\n        raw_tags: list[UserMessageTagContent] = []\n\n        for part in item.content:\n            if isinstance(part, UserMessageTextContent):\n                message_text_parts.append(part.text)\n            elif isinstance(part, UserMessageTagContent):\n                message_text_parts.append(f\"@{part.text}\")\n                raw_tags.append(part)\n            else:\n                assert_never(part)\n\n        user_text_item = Message(\n            role=\"user\",\n            type=\"message\",\n            content=[\n                ResponseInputTextParam(\n                    type=\"input_text\", text=\"\".join(message_text_parts)\n                ),\n                *[\n                    await self.attachment_to_message_content(a)\n                    for a in item.attachments\n                ],\n            ],\n        )\n\n        # Build system items (prepend later): quoted text and @-mention context\n        context_items: list[TResponseInputItem] = []\n\n        if item.quoted_text and is_last_message:\n            context_items.append(\n                Message(\n                    role=\"user\",\n                    type=\"message\",\n                    content=[\n                        ResponseInputTextParam(\n                            type=\"input_text\",\n                            text=f\"The user is referring to this in particular: \\n{item.quoted_text}\",\n                        )\n                    ],\n                )\n            )\n\n        # Dedupe tags (preserve order) and resolve to message content\n        if raw_tags:\n            seen, uniq_tags = set(), []\n            for t in raw_tags:\n                if t.text not in seen:\n                    seen.add(t.text)\n                    uniq_tags.append(t)\n\n            tag_content: ResponseInputMessageContentListParam = [\n                # should return summarized text items\n                await self.tag_to_message_content(tag)\n                for tag in uniq_tags\n            ]\n\n            if tag_content:\n                context_items.append(\n                    Message(\n                        role=\"user\",\n                        type=\"message\",\n                        content=[\n                            ResponseInputTextParam(\n                                type=\"input_text\",\n                                text=cleandoc(\"\"\"\n                                    # User-provided context for @-mentions\n                                    - When referencing resolved entities, use their canonical names **without** '@'.\n                                    - The '@' form appears only in user text and should not be echoed.\n                                \"\"\").strip(),\n                            ),\n                            *tag_content,\n                        ],\n                    )\n                )\n\n        return [user_text_item, *context_items]\n\n    async def assistant_message_to_input(\n        self, item: AssistantMessageItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        return EasyInputMessageParam(\n            type=\"message\",\n            content=[\n                # content param doesn't support the assistant message content types\n                cast(\n                    ResponseInputContentParam,\n                    ResponseOutputText(\n                        type=\"output_text\",\n                        text=c.text,\n                        annotations=[],  # TODO: these should be sent back as well\n                    ).model_dump(),\n                )\n                for c in item.content\n            ],\n            role=\"assistant\",\n        )\n\n    async def client_tool_call_to_input(\n        self, item: ClientToolCallItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        if item.status == \"pending\":\n            # Filter out pending tool calls - they cannot be sent to the model\n            return None\n\n        return [\n            ResponseFunctionToolCallParam(\n                type=\"function_call\",\n                call_id=item.call_id,\n                name=item.name,\n                arguments=json.dumps(item.arguments),\n            ),\n            FunctionCallOutput(\n                type=\"function_call_output\",\n                call_id=item.call_id,\n                output=json.dumps(item.output),\n            ),\n        ]\n\n    async def end_of_turn_to_input(\n        self, item: EndOfTurnItem\n    ) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n        # Only used for UI hints - you shouldn't need to override this\n        return None\n\n    async def _thread_item_to_input_item(\n        self,\n        item: ThreadItem,\n        is_last_message: bool = True,\n    ) -&gt; list[TResponseInputItem]:\n        match item:\n            case UserMessageItem():\n                out = await self.user_message_to_input(item, is_last_message) or []\n                return out if isinstance(out, list) else [out]\n            case AssistantMessageItem():\n                out = await self.assistant_message_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case ClientToolCallItem():\n                out = await self.client_tool_call_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case EndOfTurnItem():\n                out = await self.end_of_turn_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case WidgetItem():\n                out = await self.widget_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case WorkflowItem():\n                out = await self.workflow_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case TaskItem():\n                out = await self.task_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case HiddenContextItem():\n                out = await self.hidden_context_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case SDKHiddenContextItem():\n                out = await self.sdk_hidden_context_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case GeneratedImageItem():\n                out = await self.generated_image_to_input(item) or []\n                return out if isinstance(out, list) else [out]\n            case _:\n                assert_never(item)\n\n    async def to_agent_input(\n        self,\n        thread_items: Sequence[ThreadItem] | ThreadItem,\n    ) -&gt; list[TResponseInputItem]:\n        if isinstance(thread_items, Sequence):\n            # shallow copy in case caller mutates the list while we're iterating\n            thread_items = thread_items[:]\n        else:\n            thread_items = [thread_items]\n        output: list[TResponseInputItem] = []\n        for item in thread_items:\n            output.extend(\n                await self._thread_item_to_input_item(\n                    item,\n                    is_last_message=item is thread_items[-1],\n                )\n            )\n        return output\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter.attachment_to_message_content","title":"attachment_to_message_content  <code>async</code>","text":"<pre><code>attachment_to_message_content(\n    attachment: Attachment,\n) -&gt; ResponseInputContentParam\n</code></pre> <p>Convert an attachment in a user message into a message content part to send to the model. Required when attachments are enabled.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def attachment_to_message_content(\n    self, attachment: Attachment\n) -&gt; ResponseInputContentParam:\n    \"\"\"\n    Convert an attachment in a user message into a message content part to send to the model.\n    Required when attachments are enabled.\n    \"\"\"\n    raise NotImplementedError(\n        \"An Attachment was included in a UserMessageItem but Converter.attachment_to_message_content was not implemented\"\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter.tag_to_message_content","title":"tag_to_message_content  <code>async</code>","text":"<pre><code>tag_to_message_content(\n    tag: UserMessageTagContent,\n) -&gt; ResponseInputContentParam\n</code></pre> <p>Convert a tag in a user message into a message content part to send to the model as context. Required when tags are used.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def tag_to_message_content(\n    self, tag: UserMessageTagContent\n) -&gt; ResponseInputContentParam:\n    \"\"\"\n    Convert a tag in a user message into a message content part to send to the model as context.\n    Required when tags are used.\n    \"\"\"\n    raise NotImplementedError(\n        \"A Tag was included in a UserMessageItem but Converter.tag_to_message_content is not implemented\"\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter.generated_image_to_input","title":"generated_image_to_input  <code>async</code>","text":"<pre><code>generated_image_to_input(\n    item: GeneratedImageItem,\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None\n</code></pre> <p>Convert a GeneratedImageItem into input item(s) to send to the model. Override this method to customize the conversion of generated images, such as when your generated image url is not publicly reachable.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def generated_image_to_input(\n    self, item: GeneratedImageItem\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n    \"\"\"\n    Convert a GeneratedImageItem into input item(s) to send to the model.\n    Override this method to customize the conversion of generated images, such as when your\n    generated image url is not publicly reachable.\n    \"\"\"\n    if not item.image:\n        return None\n\n    return Message(\n        type=\"message\",\n        content=[\n            ResponseInputTextParam(\n                type=\"input_text\",\n                text=\"The following image was generated by the agent.\",\n            ),\n            ResponseInputImageParam(\n                type=\"input_image\",\n                detail=\"auto\",\n                image_url=item.image.url,\n            ),\n        ],\n        role=\"user\",\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter.hidden_context_to_input","title":"hidden_context_to_input  <code>async</code>","text":"<pre><code>hidden_context_to_input(\n    item: HiddenContextItem,\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None\n</code></pre> <p>Convert a HiddenContextItem into input item(s) to send to the model. Required to override when HiddenContextItems with non-string content are used.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def hidden_context_to_input(\n    self, item: HiddenContextItem\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n    \"\"\"\n    Convert a HiddenContextItem into input item(s) to send to the model.\n    Required to override when HiddenContextItems with non-string content are used.\n    \"\"\"\n    if not isinstance(item.content, str):\n        raise NotImplementedError(\n            \"HiddenContextItems with non-string content were present in a user message but a Converter.hidden_context_to_input was not implemented\"\n        )\n\n    text = (\n        \"Hidden context for the agent (not shown to the user):\\n\"\n        f\"&lt;HiddenContext&gt;\\n{item.content}\\n&lt;/HiddenContext&gt;\"\n    )\n    return Message(\n        type=\"message\",\n        content=[\n            ResponseInputTextParam(\n                type=\"input_text\",\n                text=text,\n            )\n        ],\n        role=\"user\",\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter.sdk_hidden_context_to_input","title":"sdk_hidden_context_to_input  <code>async</code>","text":"<pre><code>sdk_hidden_context_to_input(\n    item: SDKHiddenContextItem,\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None\n</code></pre> <p>Convert a SDKHiddenContextItem into input item to send to the model. This is used by the ChatKit Python SDK for storing additional context for internal operations. Override if you want to wrap the content in a different format.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def sdk_hidden_context_to_input(\n    self, item: SDKHiddenContextItem\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n    \"\"\"\n    Convert a SDKHiddenContextItem into input item to send to the model.\n    This is used by the ChatKit Python SDK for storing additional context\n    for internal operations.\n    Override if you want to wrap the content in a different format.\n    \"\"\"\n    text = (\n        \"Hidden context for the agent (not shown to the user):\\n\"\n        f\"&lt;HiddenContext&gt;\\n{item.content}\\n&lt;/HiddenContext&gt;\"\n    )\n    return Message(\n        type=\"message\",\n        content=[\n            ResponseInputTextParam(\n                type=\"input_text\",\n                text=text,\n            )\n        ],\n        role=\"user\",\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter.task_to_input","title":"task_to_input  <code>async</code>","text":"<pre><code>task_to_input(\n    item: TaskItem,\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None\n</code></pre> <p>Convert a TaskItem into input item(s) to send to the model.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def task_to_input(\n    self, item: TaskItem\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n    \"\"\"\n    Convert a TaskItem into input item(s) to send to the model.\n    \"\"\"\n    if item.task.type != \"custom\" or (\n        not item.task.title and not item.task.content\n    ):\n        return None\n    title = f\"{item.task.title}\" if item.task.title else \"\"\n    content = f\"{item.task.content}\" if item.task.content else \"\"\n    task_text = f\"{title}: {content}\" if title and content else title or content\n    text = f\"A message was displayed to the user that the following task was performed:\\n&lt;Task&gt;\\n{task_text}\\n&lt;/Task&gt;\"\n    return Message(\n        type=\"message\",\n        content=[\n            ResponseInputTextParam(\n                type=\"input_text\",\n                text=text,\n            )\n        ],\n        role=\"user\",\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter.workflow_to_input","title":"workflow_to_input  <code>async</code>","text":"<pre><code>workflow_to_input(\n    item: WorkflowItem,\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None\n</code></pre> <p>Convert a TaskItem into input item(s) to send to the model. Returns WorkflowItem.response_items by default.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def workflow_to_input(\n    self, item: WorkflowItem\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n    \"\"\"\n    Convert a TaskItem into input item(s) to send to the model.\n    Returns WorkflowItem.response_items by default.\n    \"\"\"\n    messages = []\n    for task in item.workflow.tasks:\n        if task.type != \"custom\" or (not task.title and not task.content):\n            continue\n\n        title = f\"{task.title}\" if task.title else \"\"\n        content = f\"{task.content}\" if task.content else \"\"\n        task_text = f\"{title}: {content}\" if title and content else title or content\n        text = f\"A message was displayed to the user that the following task was performed:\\n&lt;Task&gt;\\n{task_text}\\n&lt;/Task&gt;\"\n        messages.append(\n            Message(\n                type=\"message\",\n                content=[\n                    ResponseInputTextParam(\n                        type=\"input_text\",\n                        text=text,\n                    )\n                ],\n                role=\"user\",\n            )\n        )\n    return messages\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.ThreadItemConverter.widget_to_input","title":"widget_to_input  <code>async</code>","text":"<pre><code>widget_to_input(\n    item: WidgetItem,\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None\n</code></pre> <p>Convert a WidgetItem into input item(s) to send to the model. By default, WidgetItems converted to a text description with a JSON representation of the widget.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def widget_to_input(\n    self, item: WidgetItem\n) -&gt; TResponseInputItem | list[TResponseInputItem] | None:\n    \"\"\"\n    Convert a WidgetItem into input item(s) to send to the model.\n    By default, WidgetItems converted to a text description with a JSON representation of the widget.\n    \"\"\"\n    return Message(\n        type=\"message\",\n        content=[\n            ResponseInputTextParam(\n                type=\"input_text\",\n                text=f\"The following graphical UI widget (id: {item.id}) was displayed to the user:\"\n                + item.widget.model_dump_json(\n                    exclude_unset=True, exclude_none=True\n                ),\n            )\n        ],\n        role=\"user\",\n    )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.stream_agent_response","title":"stream_agent_response  <code>async</code>","text":"<pre><code>stream_agent_response(\n    context: AgentContext,\n    result: RunResultStreaming,\n    *,\n    converter: ResponseStreamConverter = _DEFAULT_RESPONSE_STREAM_CONVERTER,\n) -&gt; AsyncIterator[ThreadStreamEvent]\n</code></pre> <p>Convert a streamed Agents SDK run into ChatKit thread stream events.</p> <p>This function consumes a streaming run result and yields <code>ThreadStreamEvent</code> objects as the run progresses.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>AgentContext</code> <p>The AgentContext to use for the stream.</p> required <code>result</code> <code>RunResultStreaming</code> <p>The RunResultStreaming to convert.</p> required <code>converter</code> <code>ResponseStreamConverter</code> <p>Defines overridable methods for adapting streamed data (such as image generation results and partial updates) into the forms expected by ChatKit.</p> <code>_DEFAULT_RESPONSE_STREAM_CONVERTER</code> <p>Returns:</p> Type Description <code>AsyncIterator[ThreadStreamEvent]</code> <p>An async iterator that yields thread stream events representing the run result.</p> Source code in <code>chatkit/agents.py</code> <pre><code>async def stream_agent_response(\n    context: AgentContext,\n    result: RunResultStreaming,\n    *,\n    converter: ResponseStreamConverter = _DEFAULT_RESPONSE_STREAM_CONVERTER,\n) -&gt; AsyncIterator[ThreadStreamEvent]:\n    \"\"\"\n    Convert a streamed Agents SDK run into ChatKit thread stream events.\n\n    This function consumes a streaming run result and yields `ThreadStreamEvent`\n    objects as the run progresses.\n\n    Args:\n        context: The AgentContext to use for the stream.\n        result: The RunResultStreaming to convert.\n        converter: Defines overridable methods for adapting streamed data (such as image\n            generation results and partial updates) into the forms expected by ChatKit.\n\n    Returns:\n        An async iterator that yields thread stream events representing the run result.\n    \"\"\"\n    current_item_id = None\n    current_tool_call = None\n    ctx = context\n    thread = context.thread\n    queue_iterator = _AsyncQueueIterator(context._events)\n    produced_items = set()\n    streaming_thought: None | StreamingThoughtTracker = None\n    # item_id -&gt; content_index -&gt; annotation count\n    item_annotation_count: defaultdict[str, defaultdict[int, int]] = defaultdict(\n        lambda: defaultdict(int)\n    )\n\n    # check if the last item in the thread was a workflow or a client tool call\n    # if it was a client tool call, check if the second last item was a workflow\n    # if either was, continue the workflow\n    items = await context.store.load_thread_items(\n        thread.id, None, 2, \"desc\", context.request_context\n    )\n    last_item = items.data[0] if len(items.data) &gt; 0 else None\n    second_last_item = items.data[1] if len(items.data) &gt; 1 else None\n\n    if last_item and last_item.type == \"workflow\":\n        ctx.workflow_item = last_item\n    elif (\n        last_item\n        and last_item.type == \"client_tool_call\"\n        and second_last_item\n        and second_last_item.type == \"workflow\"\n    ):\n        ctx.workflow_item = second_last_item\n\n    def end_workflow(item: WorkflowItem):\n        if item == ctx.workflow_item:\n            ctx.workflow_item = None\n        delta = datetime.now() - item.created_at\n        duration = int(delta.total_seconds())\n        if item.workflow.summary is None:\n            item.workflow.summary = DurationSummary(duration=duration)\n        # Default to closing all workflows\n        # To keep a workflow open on completion, close it explicitly with\n        # AgentContext.end_workflow(expanded=True)\n        item.workflow.expanded = False\n        return ThreadItemDoneEvent(item=item)\n\n    try:\n        async for event in _merge_generators(result.stream_events(), queue_iterator):\n            # Events emitted from agent context helpers\n            if isinstance(event, _EventWrapper):\n                event = event.event\n                if (\n                    event.type == \"thread.item.added\"\n                    or event.type == \"thread.item.done\"\n                ):\n                    # End the current workflow if visual item is added after it\n                    if (\n                        ctx.workflow_item\n                        and ctx.workflow_item.id != event.item.id\n                        and event.item.type != \"client_tool_call\"\n                        and event.item.type != \"hidden_context_item\"\n                    ):\n                        yield end_workflow(ctx.workflow_item)\n\n                    # track the current workflow if one is added\n                    if (\n                        event.type == \"thread.item.added\"\n                        and event.item.type == \"workflow\"\n                    ):\n                        ctx.workflow_item = event.item\n\n                    # track integration produced items so we can clean them up if\n                    # there is a guardrail tripwire\n                    produced_items.add(event.item.id)\n                yield event\n                continue\n\n            if event.type == \"run_item_stream_event\":\n                event = event.item\n                if (\n                    event.type == \"tool_call_item\"\n                    and event.raw_item.type == \"function_call\"\n                ):\n                    current_tool_call = event.raw_item.call_id\n                    current_item_id = event.raw_item.id\n                    assert current_item_id\n                    produced_items.add(current_item_id)\n                continue\n\n            if event.type != \"raw_response_event\":\n                # Ignore everything else that isn't a raw response event\n                continue\n\n            # Handle Responses events\n            event = event.data\n            if event.type == \"response.content_part.added\":\n                if event.part.type == \"reasoning_text\":\n                    continue\n                content = await _convert_content(event.part, converter)\n                yield ThreadItemUpdatedEvent(\n                    item_id=event.item_id,\n                    update=AssistantMessageContentPartAdded(\n                        content_index=event.content_index,\n                        content=content,\n                    ),\n                )\n            elif event.type == \"response.output_text.delta\":\n                yield ThreadItemUpdatedEvent(\n                    item_id=event.item_id,\n                    update=AssistantMessageContentPartTextDelta(\n                        content_index=event.content_index,\n                        delta=event.delta,\n                    ),\n                )\n            elif event.type == \"response.output_text.done\":\n                yield ThreadItemUpdatedEvent(\n                    item_id=event.item_id,\n                    update=AssistantMessageContentPartDone(\n                        content_index=event.content_index,\n                        content=AssistantMessageContent(\n                            text=event.text,\n                            annotations=[],\n                        ),\n                    ),\n                )\n            elif event.type == \"response.output_text.annotation.added\":\n                annotation = await _convert_annotation(event.annotation, converter)\n                if annotation:\n                    # Manually track annotation indices per content part in case we drop an annotation that\n                    # we can't convert to our internal representation (e.g. missing filename).\n                    annotation_index = item_annotation_count[event.item_id][\n                        event.content_index\n                    ]\n                    item_annotation_count[event.item_id][event.content_index] = (\n                        annotation_index + 1\n                    )\n                    yield ThreadItemUpdatedEvent(\n                        item_id=event.item_id,\n                        update=AssistantMessageContentPartAnnotationAdded(\n                            content_index=event.content_index,\n                            annotation_index=annotation_index,\n                            annotation=annotation,\n                        ),\n                    )\n                continue\n            elif event.type == \"response.output_item.added\":\n                item = event.item\n                if item.type == \"reasoning\" and not ctx.workflow_item:\n                    ctx.workflow_item = WorkflowItem(\n                        id=ctx.generate_id(\"workflow\"),\n                        created_at=datetime.now(),\n                        workflow=Workflow(type=\"reasoning\", tasks=[]),\n                        thread_id=thread.id,\n                    )\n                    produced_items.add(ctx.workflow_item.id)\n                    yield ThreadItemAddedEvent(item=ctx.workflow_item)\n                if item.type == \"message\":\n                    if ctx.workflow_item:\n                        yield end_workflow(ctx.workflow_item)\n                    produced_items.add(item.id)\n                    yield ThreadItemAddedEvent(\n                        item=AssistantMessageItem(\n                            # Reusing the Responses message ID\n                            id=item.id,\n                            thread_id=thread.id,\n                            content=[\n                                await _convert_content(c, converter)\n                                for c in item.content\n                            ],\n                            created_at=datetime.now(),\n                        ),\n                    )\n                elif item.type == \"image_generation_call\":\n                    ctx.generated_image_item = GeneratedImageItem(\n                        id=ctx.generate_id(\"message\"),\n                        thread_id=thread.id,\n                        created_at=datetime.now(),\n                        image=None,\n                    )\n                    produced_items.add(ctx.generated_image_item.id)\n                    yield ThreadItemAddedEvent(item=ctx.generated_image_item)\n            elif event.type == \"response.image_generation_call.partial_image\":\n                if not ctx.generated_image_item:\n                    continue\n\n                url = await converter.base64_image_to_url(\n                    image_id=event.item_id,\n                    base64_image=event.partial_image_b64,\n                    partial_image_index=event.partial_image_index,\n                )\n                progress = converter.partial_image_index_to_progress(\n                    event.partial_image_index\n                )\n\n                ctx.generated_image_item.image = GeneratedImage(\n                    id=event.item_id, url=url\n                )\n\n                yield ThreadItemUpdatedEvent(\n                    item_id=ctx.generated_image_item.id,\n                    update=GeneratedImageUpdated(\n                        image=ctx.generated_image_item.image, progress=progress\n                    ),\n                )\n            elif event.type == \"response.reasoning_summary_text.delta\":\n                if not ctx.workflow_item:\n                    continue\n\n                # stream the first thought in a new workflow so that we can show it earlier\n                if (\n                    ctx.workflow_item.workflow.type == \"reasoning\"\n                    and len(ctx.workflow_item.workflow.tasks) == 0\n                ):\n                    streaming_thought = StreamingThoughtTracker(\n                        item_id=event.item_id,\n                        index=event.summary_index,\n                        task=ThoughtTask(content=event.delta),\n                    )\n                    ctx.workflow_item.workflow.tasks.append(streaming_thought.task)\n                    yield ThreadItemUpdatedEvent(\n                        item_id=ctx.workflow_item.id,\n                        update=WorkflowTaskAdded(\n                            task=streaming_thought.task,\n                            task_index=0,\n                        ),\n                    )\n                elif (\n                    streaming_thought\n                    and streaming_thought.task in ctx.workflow_item.workflow.tasks\n                    and event.item_id == streaming_thought.item_id\n                    and event.summary_index == streaming_thought.index\n                ):\n                    streaming_thought.task.content += event.delta\n                    yield ThreadItemUpdatedEvent(\n                        item_id=ctx.workflow_item.id,\n                        update=WorkflowTaskUpdated(\n                            task=streaming_thought.task,\n                            task_index=ctx.workflow_item.workflow.tasks.index(\n                                streaming_thought.task\n                            ),\n                        ),\n                    )\n            elif event.type == \"response.reasoning_summary_text.done\":\n                if ctx.workflow_item:\n                    if (\n                        streaming_thought\n                        and streaming_thought.task in ctx.workflow_item.workflow.tasks\n                        and event.item_id == streaming_thought.item_id\n                        and event.summary_index == streaming_thought.index\n                    ):\n                        task = streaming_thought.task\n                        task.content = event.text\n                        streaming_thought = None\n                        update = WorkflowTaskUpdated(\n                            task=task,\n                            task_index=ctx.workflow_item.workflow.tasks.index(task),\n                        )\n                    else:\n                        task = ThoughtTask(content=event.text)\n                        ctx.workflow_item.workflow.tasks.append(task)\n                        update = WorkflowTaskAdded(\n                            task=task,\n                            task_index=ctx.workflow_item.workflow.tasks.index(task),\n                        )\n                    yield ThreadItemUpdatedEvent(\n                        item_id=ctx.workflow_item.id,\n                        update=update,\n                    )\n            elif event.type == \"response.output_item.done\":\n                item = event.item\n                if item.type == \"message\":\n                    produced_items.add(item.id)\n                    yield ThreadItemDoneEvent(\n                        item=AssistantMessageItem(\n                            # Reusing the Responses message ID\n                            id=item.id,\n                            thread_id=thread.id,\n                            content=[\n                                await _convert_content(c, converter)\n                                for c in item.content\n                            ],\n                            created_at=datetime.now(),\n                        ),\n                    )\n                elif item.type == \"image_generation_call\" and item.result:\n                    if not ctx.generated_image_item:\n                        continue\n\n                    url = await converter.base64_image_to_url(\n                        image_id=item.id,\n                        base64_image=item.result,\n                    )\n                    image = GeneratedImage(id=item.id, url=url)\n\n                    ctx.generated_image_item.image = image\n                    yield ThreadItemDoneEvent(item=ctx.generated_image_item)\n\n                    ctx.generated_image_item = None\n\n    except (InputGuardrailTripwireTriggered, OutputGuardrailTripwireTriggered):\n        for item_id in produced_items:\n            yield ThreadItemRemovedEvent(item_id=item_id)\n\n        # Drain remaining events without processing them\n        context._complete()\n        queue_iterator.drain_and_complete()\n\n        raise\n\n    context._complete()\n\n    # Drain remaining events\n    async for event in queue_iterator:\n        yield event.event\n\n    # If there is still an active workflow at the end of the run, store\n    # it's current state so that we can continue it in the next turn.\n    if ctx.workflow_item:\n        await ctx.store.add_thread_item(\n            thread.id, ctx.workflow_item, ctx.request_context\n        )\n\n    if context.client_tool_call:\n        yield ThreadItemDoneEvent(\n            item=ClientToolCallItem(\n                id=current_item_id\n                or context.store.generate_item_id(\n                    \"tool_call\", thread, context.request_context\n                ),\n                thread_id=thread.id,\n                name=context.client_tool_call.name,\n                arguments=context.client_tool_call.arguments,\n                created_at=datetime.now(),\n                call_id=current_tool_call\n                or context.store.generate_item_id(\n                    \"tool_call\", thread, context.request_context\n                ),\n            ),\n        )\n</code></pre>"},{"location":"api/chatkit/agents/#chatkit.agents.simple_to_agent_input","title":"simple_to_agent_input","text":"<pre><code>simple_to_agent_input(\n    thread_items: Sequence[ThreadItem] | ThreadItem,\n)\n</code></pre> <p>Helper that converts thread items using the default ThreadItemConverter.</p> Source code in <code>chatkit/agents.py</code> <pre><code>def simple_to_agent_input(thread_items: Sequence[ThreadItem] | ThreadItem):\n    \"\"\"Helper that converts thread items using the default ThreadItemConverter.\"\"\"\n    return _DEFAULT_CONVERTER.to_agent_input(thread_items)\n</code></pre>"},{"location":"api/chatkit/errors/","title":"errors","text":""},{"location":"api/chatkit/errors/#chatkit.errors.StreamError","title":"StreamError","text":"<p>               Bases: <code>BaseStreamError</code></p> <p>Error with a specific error code that maps to a localized user-facing error message.</p> Source code in <code>chatkit/errors.py</code> <pre><code>class StreamError(BaseStreamError):\n    \"\"\"\n    Error with a specific error code that maps to a localized user-facing\n    error message.\n    \"\"\"\n\n    code: ErrorCode\n\n    def __init__(\n        self,\n        code: ErrorCode,\n        *,\n        allow_retry: bool | None = None,\n    ):\n        self.code = code\n        self.status_code = DEFAULT_STATUS.get(code, 500)\n        if allow_retry is None:\n            self.allow_retry = DEFAULT_ALLOW_RETRY.get(code, False)\n        else:\n            self.allow_retry = allow_retry\n</code></pre>"},{"location":"api/chatkit/errors/#chatkit.errors.CustomStreamError","title":"CustomStreamError","text":"<p>               Bases: <code>BaseStreamError</code></p> <p>Error with a custom user-facing error message. The message should be localized as needed before raising the error.</p> Source code in <code>chatkit/errors.py</code> <pre><code>class CustomStreamError(BaseStreamError):\n    \"\"\"\n    Error with a custom user-facing error message. The message should be\n    localized as needed before raising the error.\n    \"\"\"\n\n    message: str\n    \"\"\"The user-facing error message to display.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        allow_retry: bool = False,\n    ):\n        self.message = message\n        self.allow_retry = allow_retry\n</code></pre>"},{"location":"api/chatkit/errors/#chatkit.errors.CustomStreamError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre> <p>The user-facing error message to display.</p>"},{"location":"api/chatkit/icons/","title":"icons","text":""},{"location":"api/chatkit/icons/#chatkit.icons.IconName","title":"IconName  <code>module-attribute</code>","text":"<pre><code>IconName = (\n    Literal[\n        \"agent\",\n        \"analytics\",\n        \"atom\",\n        \"batch\",\n        \"bolt\",\n        \"book-open\",\n        \"book-closed\",\n        \"book-clock\",\n        \"bug\",\n        \"calendar\",\n        \"chart\",\n        \"check\",\n        \"check-circle\",\n        \"check-circle-filled\",\n        \"chevron-left\",\n        \"chevron-right\",\n        \"circle-question\",\n        \"clock\",\n        \"compass\",\n        \"confetti\",\n        \"cube\",\n        \"desktop\",\n        \"document\",\n        \"dot\",\n        \"dots-horizontal\",\n        \"dots-vertical\",\n        \"empty-circle\",\n        \"external-link\",\n        \"globe\",\n        \"keys\",\n        \"lab\",\n        \"images\",\n        \"info\",\n        \"lifesaver\",\n        \"lightbulb\",\n        \"mail\",\n        \"map-pin\",\n        \"maps\",\n        \"mobile\",\n        \"name\",\n        \"notebook\",\n        \"notebook-pencil\",\n        \"page-blank\",\n        \"phone\",\n        \"play\",\n        \"plus\",\n        \"profile\",\n        \"profile-card\",\n        \"reload\",\n        \"star\",\n        \"star-filled\",\n        \"search\",\n        \"sparkle\",\n        \"sparkle-double\",\n        \"square-code\",\n        \"square-image\",\n        \"square-text\",\n        \"suitcase\",\n        \"settings-slider\",\n        \"user\",\n        \"wreath\",\n        \"write\",\n        \"write-alt\",\n        \"write-alt2\",\n    ]\n    | VendorIconName\n    | LucideIconName\n)\n</code></pre> <p>Allowed icon names.</p>"},{"location":"api/chatkit/server/","title":"server","text":""},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer","title":"ChatKitServer","text":"<p>               Bases: <code>ABC</code>, <code>Generic[TContext]</code></p> Source code in <code>chatkit/server.py</code> <pre><code>class ChatKitServer(ABC, Generic[TContext]):\n    def __init__(\n        self,\n        store: Store[TContext],\n        attachment_store: AttachmentStore[TContext] | None = None,\n    ):\n        \"\"\"Create a ChatKitServer with the backing Store and optional AttachmentStore.\"\"\"\n        self.store = store\n        self.attachment_store = attachment_store\n\n    def _get_attachment_store(self) -&gt; AttachmentStore[TContext]:\n        \"\"\"Return the configured AttachmentStore or raise if missing.\"\"\"\n        if self.attachment_store is None:\n            raise RuntimeError(\n                \"AttachmentStore is not configured. Provide a AttachmentStore to ChatKitServer to handle file operations.\"\n            )\n        return self.attachment_store\n\n    @abstractmethod\n    def respond(\n        self,\n        thread: ThreadMetadata,\n        input_user_message: UserMessageItem | None,\n        context: TContext,\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        \"\"\"Stream `ThreadStreamEvent` instances for a new user message.\n\n        Args:\n            thread: Metadata for the thread being processed.\n            input_user_message: The incoming message the server should respond to, if any.\n            context: Arbitrary per-request context provided by the caller.\n\n        Returns:\n            An async iterator that yields events representing the server's response.\n        \"\"\"\n        pass\n\n    async def add_feedback(  # noqa: B027\n        self,\n        thread_id: str,\n        item_ids: list[str],\n        feedback: FeedbackKind,\n        context: TContext,\n    ) -&gt; None:\n        \"\"\"Persist user feedback for one or more thread items.\"\"\"\n        pass\n\n    async def transcribe(  # noqa: B027\n        self, audio_input: AudioInput, context: TContext\n    ) -&gt; TranscriptionResult:\n        \"\"\"Transcribe speech audio to text (dictation).\n\n        Audio bytes are in `audio_input.data`. The raw MIME type is `audio_input.mime_type`; use\n        `audio_input.media_type` for the base media type (one of: `audio/webm`, `audio/ogg`, `audio/mp4`).\n\n        Args:\n            audio_input: Audio bytes plus MIME type metadata for transcription.\n            context: Arbitrary per-request context provided by the caller.\n\n        Returns:\n            A `TranscriptionResult` whose `text` is what should appear in the composer.\n        \"\"\"\n        raise NotImplementedError(\n            \"transcribe() must be overridden to support the input.transcribe request.\"\n        )\n\n    def action(\n        self,\n        thread: ThreadMetadata,\n        action: Action[str, Any],\n        sender: WidgetItem | None,\n        context: TContext,\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        \"\"\"Handle a widget or client-dispatched action and yield response events.\"\"\"\n        raise NotImplementedError(\n            \"The action() method must be overridden to react to actions. \"\n            \"See https://github.com/openai/chatkit-python/blob/main/docs/widgets.md#widget-actions\"\n        )\n\n    async def sync_action(\n        self,\n        thread: ThreadMetadata,\n        action: Action[str, Any],\n        sender: WidgetItem | None,\n        context: TContext,\n    ) -&gt; SyncCustomActionResponse:\n        \"\"\"Handle a widget or client-dispatched action and return a SyncCustomActionResponse.\"\"\"\n        raise NotImplementedError(\n            \"The sync_action() method must be overridden to react to sync actions. \"\n            \"See https://github.com/openai/chatkit-python/blob/main/docs/widgets.md#widget-actions\"\n        )\n\n    def get_stream_options(\n        self, thread: ThreadMetadata, context: TContext\n    ) -&gt; StreamOptions:\n        \"\"\"\n        Return stream-level runtime options. Allows the user to cancel the stream by default.\n        Override this method to customize behavior.\n        \"\"\"\n        return StreamOptions(allow_cancel=True)\n\n    async def handle_stream_cancelled(\n        self,\n        thread: ThreadMetadata,\n        pending_items: list[ThreadItem],\n        context: TContext,\n    ):\n        \"\"\"Perform custom cleanup / stop inference when a stream is cancelled.\n        Updates you make here will not be reflected in the UI until a reload.\n\n        The default implementation persists any non-empty pending assistant messages\n        to the thread but does not auto-save pending widget items or workflow items.\n\n        Args:\n            thread: The thread that was being processed.\n            pending_items: Items that were not done streaming at cancellation time.\n            context: Arbitrary per-request context provided by the caller.\n        \"\"\"\n        pending_assistant_message_items: list[AssistantMessageItem] = [\n            item for item in pending_items if isinstance(item, AssistantMessageItem)\n        ]\n        for item in pending_assistant_message_items:\n            is_empty = len(item.content) == 0 or all(\n                (not content.text.strip()) for content in item.content\n            )\n            if not is_empty:\n                await self.store.add_thread_item(thread.id, item, context=context)\n\n        # Add a hidden context item to the thread to indicate that the stream was cancelled.\n        # Otherwise, depending on the timing of the cancellation, subsequent responses may\n        # attempt to continue the cancelled response.\n        await self.store.add_thread_item(\n            thread.id,\n            SDKHiddenContextItem(\n                thread_id=thread.id,\n                created_at=datetime.now(),\n                id=self.store.generate_item_id(\"sdk_hidden_context\", thread, context),\n                content=\"The user cancelled the stream. Stop responding to the prior request.\",\n            ),\n            context=context,\n        )\n\n    async def process(\n        self, request: str | bytes | bytearray, context: TContext\n    ) -&gt; StreamingResult | NonStreamingResult:\n        \"\"\"Parse an incoming ChatKit request and route it to streaming or non-streaming handlers.\"\"\"\n        parsed_request = TypeAdapter[ChatKitReq](ChatKitReq).validate_json(request)\n        logger.info(f\"Received request op: {parsed_request.type}\")\n\n        if is_streaming_req(parsed_request):\n            return StreamingResult(self._process_streaming(parsed_request, context))\n        else:\n            return NonStreamingResult(\n                await self._process_non_streaming(parsed_request, context)\n            )\n\n    async def _process_non_streaming(\n        self, request: NonStreamingReq, context: TContext\n    ) -&gt; bytes:\n        match request:\n            case ThreadsGetByIdReq():\n                thread = await self._load_full_thread(\n                    request.params.thread_id, context=context\n                )\n                return self._serialize(self._to_thread_response(thread))\n            case ThreadsListReq():\n                params = request.params\n                threads = await self.store.load_threads(\n                    limit=params.limit or DEFAULT_PAGE_SIZE,\n                    after=params.after,\n                    order=params.order,\n                    context=context,\n                )\n                return self._serialize(\n                    Page(\n                        has_more=threads.has_more,\n                        after=threads.after,\n                        data=[\n                            self._to_thread_response(thread) for thread in threads.data\n                        ],\n                    )\n                )\n            case ItemsFeedbackReq():\n                await self.add_feedback(\n                    request.params.thread_id,\n                    request.params.item_ids,\n                    request.params.kind,\n                    context,\n                )\n                return b\"{}\"\n            case AttachmentsCreateReq():\n                attachment_store = self._get_attachment_store()\n                attachment = await attachment_store.create_attachment(\n                    request.params, context\n                )\n                await self.store.save_attachment(attachment, context=context)\n                return self._serialize(attachment)\n            case AttachmentsDeleteReq():\n                attachment_store = self._get_attachment_store()\n                await attachment_store.delete_attachment(\n                    request.params.attachment_id, context=context\n                )\n                await self.store.delete_attachment(\n                    request.params.attachment_id, context=context\n                )\n                return b\"{}\"\n            case InputTranscribeReq():\n                audio_bytes = base64.b64decode(request.params.audio_base64)\n                transcription_result = await self.transcribe(\n                    AudioInput(data=audio_bytes, mime_type=request.params.mime_type),\n                    context=context,\n                )\n                return self._serialize(transcription_result)\n            case ItemsListReq():\n                items_list_params = request.params\n                items = await self.store.load_thread_items(\n                    items_list_params.thread_id,\n                    limit=items_list_params.limit or DEFAULT_PAGE_SIZE,\n                    order=items_list_params.order,\n                    after=items_list_params.after,\n                    context=context,\n                )\n                # filter out hidden context items\n                items.data = [\n                    item\n                    for item in items.data\n                    if not isinstance(item, (HiddenContextItem, SDKHiddenContextItem))\n                ]\n                return self._serialize(items)\n            case ThreadsUpdateReq():\n                thread = await self.store.load_thread(\n                    request.params.thread_id, context=context\n                )\n                thread.title = request.params.title\n                await self.store.save_thread(thread, context=context)\n                return self._serialize(self._to_thread_response(thread))\n            case ThreadsDeleteReq():\n                await self.store.delete_thread(\n                    request.params.thread_id, context=context\n                )\n                return b\"{}\"\n            case ThreadsSyncCustomActionReq():\n                return await self._process_sync_custom_action(request, context)\n            case _:\n                assert_never(request)\n\n    async def _process_streaming(\n        self, request: StreamingReq, context: TContext\n    ) -&gt; AsyncGenerator[bytes, None]:\n        try:\n            async for event in self._process_streaming_impl(request, context):\n                b = self._serialize(event)\n                yield b\"data: \" + b + b\"\\n\\n\"\n        except asyncio.CancelledError:\n            # Let cancellation bubble up without logging as an error.\n            raise\n        except Exception:\n            logger.exception(\"Error while generating streamed response\")\n            raise\n\n    async def _process_streaming_impl(\n        self, request: StreamingReq, context: TContext\n    ) -&gt; AsyncGenerator[ThreadStreamEvent, None]:\n        match request:\n            case ThreadsCreateReq():\n                thread = Thread(\n                    id=self.store.generate_thread_id(context),\n                    created_at=datetime.now(),\n                    items=Page(),\n                )\n                await self.store.save_thread(\n                    ThreadMetadata(**thread.model_dump()),\n                    context=context,\n                )\n                yield ThreadCreatedEvent(thread=self._to_thread_response(thread))\n                user_message = await self._build_user_message_item(\n                    request.params.input, thread, context\n                )\n                async for event in self._process_new_thread_item_respond(\n                    thread,\n                    user_message,\n                    context,\n                ):\n                    yield event\n\n            case ThreadsAddUserMessageReq():\n                thread = await self.store.load_thread(\n                    request.params.thread_id, context=context\n                )\n                user_message = await self._build_user_message_item(\n                    request.params.input, thread, context\n                )\n                async for event in self._process_new_thread_item_respond(\n                    thread,\n                    user_message,\n                    context,\n                ):\n                    yield event\n\n            case ThreadsAddClientToolOutputReq():\n                thread = await self.store.load_thread(\n                    request.params.thread_id, context=context\n                )\n                items = await self.store.load_thread_items(\n                    thread.id, None, 1, \"desc\", context\n                )\n                tool_call = next(\n                    (\n                        item\n                        for item in items.data\n                        if isinstance(item, ClientToolCallItem)\n                        and item.status == \"pending\"\n                    ),\n                    None,\n                )\n                if not tool_call:\n                    raise ValueError(\n                        f\"Last thread item in {thread.id} was not a ClientToolCallItem\"\n                    )\n\n                tool_call.output = request.params.result\n                tool_call.status = \"completed\"\n\n                await self.store.save_item(thread.id, tool_call, context=context)\n\n                # Safety against dangling pending tool calls if there are\n                # multiple in a row, which should be impossible, and\n                # integrations should ultimately filter out pending tool calls\n                # when creating input response messages.\n                await self._cleanup_pending_client_tool_call(thread, context)\n\n                async for event in self._process_events(\n                    thread,\n                    context,\n                    lambda: self.respond(thread, None, context),\n                ):\n                    yield event\n\n            case ThreadsRetryAfterItemReq():\n                thread_metadata = await self.store.load_thread(\n                    request.params.thread_id, context=context\n                )\n\n                # Collect items to remove (all items after the user message)\n                items_to_remove: list[ThreadItem] = []\n                user_message_item = None\n\n                async for item in self._paginate_thread_items_reverse(\n                    request.params.thread_id, context\n                ):\n                    if item.id == request.params.item_id:\n                        if not isinstance(item, UserMessageItem):\n                            raise ValueError(\n                                f\"Item {request.params.item_id} is not a user message\"\n                            )\n                        user_message_item = item\n                        break\n                    items_to_remove.append(item)\n\n                if user_message_item:\n                    for item in items_to_remove:\n                        await self.store.delete_thread_item(\n                            request.params.thread_id, item.id, context=context\n                        )\n                    async for event in self._process_events(\n                        thread_metadata,\n                        context,\n                        lambda: self.respond(\n                            thread_metadata,\n                            user_message_item,\n                            context,\n                        ),\n                    ):\n                        yield event\n            case ThreadsCustomActionReq():\n                thread_metadata = await self.store.load_thread(\n                    request.params.thread_id, context=context\n                )\n\n                item: ThreadItem | None = None\n                if request.params.item_id:\n                    item = await self.store.load_item(\n                        request.params.thread_id,\n                        request.params.item_id,\n                        context=context,\n                    )\n\n                if item and not isinstance(item, WidgetItem):\n                    # shouldn't happen if the caller is using the API correctly.\n                    yield ErrorEvent(\n                        code=ErrorCode.STREAM_ERROR,\n                        allow_retry=False,\n                    )\n                    return\n\n                async for event in self._process_events(\n                    thread_metadata,\n                    context,\n                    lambda: self.action(\n                        thread_metadata,\n                        request.params.action,\n                        item,\n                        context,\n                    ),\n                ):\n                    yield event\n\n            case _:\n                assert_never(request)\n\n    async def _process_sync_custom_action(\n        self, request: ThreadsSyncCustomActionReq, context: TContext\n    ) -&gt; bytes:\n        thread_metadata = await self.store.load_thread(\n            request.params.thread_id, context=context\n        )\n\n        item: ThreadItem | None = None\n        if request.params.item_id:\n            item = await self.store.load_item(\n                request.params.thread_id,\n                request.params.item_id,\n                context=context,\n            )\n\n        if item and not isinstance(item, WidgetItem):\n            raise ValueError(\"threads.sync_custom_action requires a widget sender item\")\n\n        return self._serialize(\n            await self.sync_action(\n                thread_metadata,\n                request.params.action,\n                item,\n                context,\n            )\n        )\n\n    async def _cleanup_pending_client_tool_call(\n        self, thread: ThreadMetadata, context: TContext\n    ) -&gt; None:\n        items = await self.store.load_thread_items(\n            thread.id, None, DEFAULT_PAGE_SIZE, \"desc\", context\n        )\n        for tool_call in items.data:\n            if not isinstance(tool_call, ClientToolCallItem):\n                continue\n            if tool_call.status == \"pending\":\n                logger.warning(\n                    f\"Client tool call {tool_call.call_id} was not completed, ignoring\"\n                )\n                await self.store.delete_thread_item(\n                    thread.id, tool_call.id, context=context\n                )\n\n    async def _process_new_thread_item_respond(\n        self,\n        thread: ThreadMetadata,\n        item: UserMessageItem,\n        context: TContext,\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        # Store the updated attachments (now that they have a thread id).\n        for attachment in item.attachments:\n            await self.store.save_attachment(attachment, context=context)\n\n        await self.store.add_thread_item(thread.id, item, context=context)\n        yield ThreadItemDoneEvent(item=item)\n\n        async for event in self._process_events(\n            thread,\n            context,\n            lambda: self.respond(thread, item, context),\n        ):\n            yield event\n\n    async def _process_events(\n        self,\n        thread: ThreadMetadata,\n        context: TContext,\n        stream: Callable[[], AsyncIterator[ThreadStreamEvent]],\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        await asyncio.sleep(0)  # allow the response to start streaming\n\n        # Send initial stream options\n        yield StreamOptionsEvent(\n            stream_options=self.get_stream_options(thread, context)\n        )\n\n        last_thread = thread.model_copy(deep=True)\n\n        # Keep track of items that were streamed but not yet saved\n        # so that we can persist them when the stream is cancelled.\n        pending_items: dict[str, ThreadItem] = {}\n\n        try:\n            with agents_sdk_user_agent_override():\n                async for event in stream():\n                    if isinstance(event, ThreadItemAddedEvent):\n                        # Stash an isolated copy in case we need to persist unfinished items\n                        # on cancellation; downstream handlers keep using the original event.item.\n                        pending_items[event.item.id] = event.item.model_copy(deep=True)\n\n                    match event:\n                        case ThreadItemDoneEvent():\n                            await self.store.add_thread_item(\n                                thread.id, event.item, context=context\n                            )\n                            pending_items.pop(event.item.id, None)\n                        case ThreadItemRemovedEvent():\n                            await self.store.delete_thread_item(\n                                thread.id, event.item_id, context=context\n                            )\n                            pending_items.pop(event.item_id, None)\n                        case ThreadItemReplacedEvent():\n                            await self.store.save_item(\n                                thread.id, event.item, context=context\n                            )\n                            pending_items.pop(event.item.id, None)\n                        case ThreadItemUpdatedEvent():\n                            # Keep pending assistant message and workflow items up to date\n                            # so that we have a reference to the latest version of these pending items\n                            # when the stream is cancelled.\n                            self._update_pending_items(pending_items, event)\n\n                    # special case - don't send hidden context items back to the client\n                    should_swallow_event = isinstance(\n                        event, ThreadItemDoneEvent\n                    ) and isinstance(\n                        event.item, (HiddenContextItem, SDKHiddenContextItem)\n                    )\n\n                    if not should_swallow_event:\n                        yield event\n\n                    # in case user updated the thread while streaming\n                    if thread != last_thread:\n                        last_thread = thread.model_copy(deep=True)\n                        await self.store.save_thread(thread, context=context)\n                        yield ThreadUpdatedEvent(\n                            thread=self._to_thread_response(thread)\n                        )\n                # in case user updated the thread while streaming\n                if thread != last_thread:\n                    last_thread = thread.model_copy(deep=True)\n                    await self.store.save_thread(thread, context=context)\n                    yield ThreadUpdatedEvent(thread=self._to_thread_response(thread))\n        except asyncio.CancelledError:\n            await self.handle_stream_cancelled(\n                thread, list(pending_items.values()), context\n            )\n            raise\n        except CustomStreamError as e:\n            yield ErrorEvent(\n                code=\"custom\",\n                message=e.message,\n                allow_retry=e.allow_retry,\n            )\n        except StreamError as e:\n            yield ErrorEvent(\n                code=e.code,\n                allow_retry=e.allow_retry,\n            )\n        except Exception as e:\n            yield ErrorEvent(\n                code=ErrorCode.STREAM_ERROR,\n                allow_retry=True,\n            )\n            logger.exception(e)\n\n        if thread != last_thread:\n            # in case user updated the thread at the end of the stream\n            await self.store.save_thread(thread, context=context)\n            yield ThreadUpdatedEvent(thread=self._to_thread_response(thread))\n\n    def _apply_assistant_message_update(\n        self,\n        item: AssistantMessageItem,\n        update: AssistantMessageContentPartAdded\n        | AssistantMessageContentPartTextDelta\n        | AssistantMessageContentPartAnnotationAdded\n        | AssistantMessageContentPartDone,\n    ) -&gt; AssistantMessageItem:\n        # Pad the content list so the requested content_index exists before we write into it.\n        # (Streaming updates can arrive for an index that hasn\u2019t been created yet)\n        while len(item.content) &lt;= update.content_index:\n            item.content.append(AssistantMessageContent(text=\"\", annotations=[]))\n\n        match update:\n            case AssistantMessageContentPartAdded():\n                item.content[update.content_index] = update.content\n            case AssistantMessageContentPartTextDelta():\n                item.content[update.content_index].text += update.delta\n            case AssistantMessageContentPartAnnotationAdded():\n                annotations = item.content[update.content_index].annotations\n                if update.annotation_index &lt;= len(annotations):\n                    annotations.insert(update.annotation_index, update.annotation)\n                else:\n                    annotations.append(update.annotation)\n            case AssistantMessageContentPartDone():\n                item.content[update.content_index] = update.content\n        return item\n\n    def _update_pending_items(\n        self,\n        pending_items: dict[str, ThreadItem],\n        event: ThreadItemUpdatedEvent,\n    ):\n        updated_item = pending_items.get(event.item_id)\n        update = event.update\n        match updated_item:\n            case AssistantMessageItem():\n                if isinstance(\n                    update,\n                    (\n                        AssistantMessageContentPartAdded,\n                        AssistantMessageContentPartTextDelta,\n                        AssistantMessageContentPartAnnotationAdded,\n                        AssistantMessageContentPartDone,\n                    ),\n                ):\n                    pending_items[updated_item.id] = (\n                        self._apply_assistant_message_update(updated_item, update)\n                    )\n            case WorkflowItem():\n                if isinstance(update, (WorkflowTaskUpdated, WorkflowTaskAdded)):\n                    match update:\n                        case WorkflowTaskUpdated():\n                            updated_item.workflow.tasks[update.task_index] = update.task\n                        case WorkflowTaskAdded():\n                            updated_item.workflow.tasks.append(update.task)\n\n                    pending_items[updated_item.id] = updated_item\n            case _:\n                pass\n\n    async def _build_user_message_item(\n        self, input: UserMessageInput, thread: ThreadMetadata, context: TContext\n    ) -&gt; UserMessageItem:\n        return UserMessageItem(\n            id=self.store.generate_item_id(\"message\", thread, context),\n            content=input.content,\n            thread_id=thread.id,\n            attachments=[\n                (await self.store.load_attachment(attachment_id, context)).model_copy(\n                    update={\"thread_id\": thread.id}\n                )\n                for attachment_id in input.attachments\n            ],\n            quoted_text=input.quoted_text,\n            inference_options=input.inference_options,\n            created_at=datetime.now(),\n        )\n\n    async def _load_full_thread(self, thread_id: str, context: TContext) -&gt; Thread:\n        thread_meta = await self.store.load_thread(thread_id, context=context)\n        thread_items = await self.store.load_thread_items(\n            thread_id,\n            after=None,\n            limit=DEFAULT_PAGE_SIZE,\n            order=\"asc\",\n            context=context,\n        )\n        return Thread(**thread_meta.model_dump(), items=thread_items)\n\n    async def _paginate_thread_items_reverse(\n        self, thread_id: str, context: TContext\n    ) -&gt; AsyncIterator[ThreadItem]:\n        \"\"\"Paginate through thread items in reverse order (newest first).\"\"\"\n        after = None\n        while True:\n            items = await self.store.load_thread_items(\n                thread_id, after, DEFAULT_PAGE_SIZE, \"desc\", context\n            )\n            for item in items.data:\n                yield item\n\n            if not items.has_more:\n                break\n            after = items.after\n\n    def _serialize(self, obj: BaseModel) -&gt; bytes:\n        return obj.model_dump_json(\n            by_alias=True,\n            exclude_none=True,\n            context={\"exclude_metadata\": True},\n        ).encode(\"utf-8\")\n\n    def _to_thread_response(self, thread: ThreadMetadata | Thread) -&gt; Thread:\n        def is_hidden(item: ThreadItem) -&gt; bool:\n            return isinstance(item, (HiddenContextItem, SDKHiddenContextItem))\n\n        items = thread.items if isinstance(thread, Thread) else Page()\n        items.data = [item for item in items.data if not is_hidden(item)]\n\n        return Thread(\n            id=thread.id,\n            title=thread.title,\n            created_at=thread.created_at,\n            items=items,\n            status=thread.status,\n        )\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer.respond","title":"respond  <code>abstractmethod</code>","text":"<pre><code>respond(\n    thread: ThreadMetadata,\n    input_user_message: UserMessageItem | None,\n    context: TContext,\n) -&gt; AsyncIterator[ThreadStreamEvent]\n</code></pre> <p>Stream <code>ThreadStreamEvent</code> instances for a new user message.</p> <p>Parameters:</p> Name Type Description Default <code>thread</code> <code>ThreadMetadata</code> <p>Metadata for the thread being processed.</p> required <code>input_user_message</code> <code>UserMessageItem | None</code> <p>The incoming message the server should respond to, if any.</p> required <code>context</code> <code>TContext</code> <p>Arbitrary per-request context provided by the caller.</p> required <p>Returns:</p> Type Description <code>AsyncIterator[ThreadStreamEvent]</code> <p>An async iterator that yields events representing the server's response.</p> Source code in <code>chatkit/server.py</code> <pre><code>@abstractmethod\ndef respond(\n    self,\n    thread: ThreadMetadata,\n    input_user_message: UserMessageItem | None,\n    context: TContext,\n) -&gt; AsyncIterator[ThreadStreamEvent]:\n    \"\"\"Stream `ThreadStreamEvent` instances for a new user message.\n\n    Args:\n        thread: Metadata for the thread being processed.\n        input_user_message: The incoming message the server should respond to, if any.\n        context: Arbitrary per-request context provided by the caller.\n\n    Returns:\n        An async iterator that yields events representing the server's response.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer.add_feedback","title":"add_feedback  <code>async</code>","text":"<pre><code>add_feedback(\n    thread_id: str,\n    item_ids: list[str],\n    feedback: FeedbackKind,\n    context: TContext,\n) -&gt; None\n</code></pre> <p>Persist user feedback for one or more thread items.</p> Source code in <code>chatkit/server.py</code> <pre><code>async def add_feedback(  # noqa: B027\n    self,\n    thread_id: str,\n    item_ids: list[str],\n    feedback: FeedbackKind,\n    context: TContext,\n) -&gt; None:\n    \"\"\"Persist user feedback for one or more thread items.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer.transcribe","title":"transcribe  <code>async</code>","text":"<pre><code>transcribe(\n    audio_input: AudioInput, context: TContext\n) -&gt; TranscriptionResult\n</code></pre> <p>Transcribe speech audio to text (dictation).</p> <p>Audio bytes are in <code>audio_input.data</code>. The raw MIME type is <code>audio_input.mime_type</code>; use <code>audio_input.media_type</code> for the base media type (one of: <code>audio/webm</code>, <code>audio/ogg</code>, <code>audio/mp4</code>).</p> <p>Parameters:</p> Name Type Description Default <code>audio_input</code> <code>AudioInput</code> <p>Audio bytes plus MIME type metadata for transcription.</p> required <code>context</code> <code>TContext</code> <p>Arbitrary per-request context provided by the caller.</p> required <p>Returns:</p> Type Description <code>TranscriptionResult</code> <p>A <code>TranscriptionResult</code> whose <code>text</code> is what should appear in the composer.</p> Source code in <code>chatkit/server.py</code> <pre><code>async def transcribe(  # noqa: B027\n    self, audio_input: AudioInput, context: TContext\n) -&gt; TranscriptionResult:\n    \"\"\"Transcribe speech audio to text (dictation).\n\n    Audio bytes are in `audio_input.data`. The raw MIME type is `audio_input.mime_type`; use\n    `audio_input.media_type` for the base media type (one of: `audio/webm`, `audio/ogg`, `audio/mp4`).\n\n    Args:\n        audio_input: Audio bytes plus MIME type metadata for transcription.\n        context: Arbitrary per-request context provided by the caller.\n\n    Returns:\n        A `TranscriptionResult` whose `text` is what should appear in the composer.\n    \"\"\"\n    raise NotImplementedError(\n        \"transcribe() must be overridden to support the input.transcribe request.\"\n    )\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer.action","title":"action","text":"<pre><code>action(\n    thread: ThreadMetadata,\n    action: Action[str, Any],\n    sender: WidgetItem | None,\n    context: TContext,\n) -&gt; AsyncIterator[ThreadStreamEvent]\n</code></pre> <p>Handle a widget or client-dispatched action and yield response events.</p> Source code in <code>chatkit/server.py</code> <pre><code>def action(\n    self,\n    thread: ThreadMetadata,\n    action: Action[str, Any],\n    sender: WidgetItem | None,\n    context: TContext,\n) -&gt; AsyncIterator[ThreadStreamEvent]:\n    \"\"\"Handle a widget or client-dispatched action and yield response events.\"\"\"\n    raise NotImplementedError(\n        \"The action() method must be overridden to react to actions. \"\n        \"See https://github.com/openai/chatkit-python/blob/main/docs/widgets.md#widget-actions\"\n    )\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer.sync_action","title":"sync_action  <code>async</code>","text":"<pre><code>sync_action(\n    thread: ThreadMetadata,\n    action: Action[str, Any],\n    sender: WidgetItem | None,\n    context: TContext,\n) -&gt; SyncCustomActionResponse\n</code></pre> <p>Handle a widget or client-dispatched action and return a SyncCustomActionResponse.</p> Source code in <code>chatkit/server.py</code> <pre><code>async def sync_action(\n    self,\n    thread: ThreadMetadata,\n    action: Action[str, Any],\n    sender: WidgetItem | None,\n    context: TContext,\n) -&gt; SyncCustomActionResponse:\n    \"\"\"Handle a widget or client-dispatched action and return a SyncCustomActionResponse.\"\"\"\n    raise NotImplementedError(\n        \"The sync_action() method must be overridden to react to sync actions. \"\n        \"See https://github.com/openai/chatkit-python/blob/main/docs/widgets.md#widget-actions\"\n    )\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer.get_stream_options","title":"get_stream_options","text":"<pre><code>get_stream_options(\n    thread: ThreadMetadata, context: TContext\n) -&gt; StreamOptions\n</code></pre> <p>Return stream-level runtime options. Allows the user to cancel the stream by default. Override this method to customize behavior.</p> Source code in <code>chatkit/server.py</code> <pre><code>def get_stream_options(\n    self, thread: ThreadMetadata, context: TContext\n) -&gt; StreamOptions:\n    \"\"\"\n    Return stream-level runtime options. Allows the user to cancel the stream by default.\n    Override this method to customize behavior.\n    \"\"\"\n    return StreamOptions(allow_cancel=True)\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer.handle_stream_cancelled","title":"handle_stream_cancelled  <code>async</code>","text":"<pre><code>handle_stream_cancelled(\n    thread: ThreadMetadata,\n    pending_items: list[ThreadItem],\n    context: TContext,\n)\n</code></pre> <p>Perform custom cleanup / stop inference when a stream is cancelled. Updates you make here will not be reflected in the UI until a reload.</p> <p>The default implementation persists any non-empty pending assistant messages to the thread but does not auto-save pending widget items or workflow items.</p> <p>Parameters:</p> Name Type Description Default <code>thread</code> <code>ThreadMetadata</code> <p>The thread that was being processed.</p> required <code>pending_items</code> <code>list[ThreadItem]</code> <p>Items that were not done streaming at cancellation time.</p> required <code>context</code> <code>TContext</code> <p>Arbitrary per-request context provided by the caller.</p> required Source code in <code>chatkit/server.py</code> <pre><code>async def handle_stream_cancelled(\n    self,\n    thread: ThreadMetadata,\n    pending_items: list[ThreadItem],\n    context: TContext,\n):\n    \"\"\"Perform custom cleanup / stop inference when a stream is cancelled.\n    Updates you make here will not be reflected in the UI until a reload.\n\n    The default implementation persists any non-empty pending assistant messages\n    to the thread but does not auto-save pending widget items or workflow items.\n\n    Args:\n        thread: The thread that was being processed.\n        pending_items: Items that were not done streaming at cancellation time.\n        context: Arbitrary per-request context provided by the caller.\n    \"\"\"\n    pending_assistant_message_items: list[AssistantMessageItem] = [\n        item for item in pending_items if isinstance(item, AssistantMessageItem)\n    ]\n    for item in pending_assistant_message_items:\n        is_empty = len(item.content) == 0 or all(\n            (not content.text.strip()) for content in item.content\n        )\n        if not is_empty:\n            await self.store.add_thread_item(thread.id, item, context=context)\n\n    # Add a hidden context item to the thread to indicate that the stream was cancelled.\n    # Otherwise, depending on the timing of the cancellation, subsequent responses may\n    # attempt to continue the cancelled response.\n    await self.store.add_thread_item(\n        thread.id,\n        SDKHiddenContextItem(\n            thread_id=thread.id,\n            created_at=datetime.now(),\n            id=self.store.generate_item_id(\"sdk_hidden_context\", thread, context),\n            content=\"The user cancelled the stream. Stop responding to the prior request.\",\n        ),\n        context=context,\n    )\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.ChatKitServer.process","title":"process  <code>async</code>","text":"<pre><code>process(\n    request: str | bytes | bytearray, context: TContext\n) -&gt; StreamingResult | NonStreamingResult\n</code></pre> <p>Parse an incoming ChatKit request and route it to streaming or non-streaming handlers.</p> Source code in <code>chatkit/server.py</code> <pre><code>async def process(\n    self, request: str | bytes | bytearray, context: TContext\n) -&gt; StreamingResult | NonStreamingResult:\n    \"\"\"Parse an incoming ChatKit request and route it to streaming or non-streaming handlers.\"\"\"\n    parsed_request = TypeAdapter[ChatKitReq](ChatKitReq).validate_json(request)\n    logger.info(f\"Received request op: {parsed_request.type}\")\n\n    if is_streaming_req(parsed_request):\n        return StreamingResult(self._process_streaming(parsed_request, context))\n    else:\n        return NonStreamingResult(\n            await self._process_non_streaming(parsed_request, context)\n        )\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.diff_widget","title":"diff_widget","text":"<pre><code>diff_widget(\n    before: WidgetRoot, after: WidgetRoot\n) -&gt; list[\n    WidgetStreamingTextValueDelta\n    | WidgetRootUpdated\n    | WidgetComponentUpdated\n]\n</code></pre> <p>Compare two WidgetRoots and return a list of deltas.</p> Source code in <code>chatkit/server.py</code> <pre><code>def diff_widget(\n    before: WidgetRoot, after: WidgetRoot\n) -&gt; list[WidgetStreamingTextValueDelta | WidgetRootUpdated | WidgetComponentUpdated]:\n    \"\"\"\n    Compare two WidgetRoots and return a list of deltas.\n    \"\"\"\n\n    def is_streaming_text(component: WidgetComponentBase) -&gt; bool:\n        return getattr(component, \"type\", None) in {\"Markdown\", \"Text\"} and isinstance(\n            getattr(component, \"value\", None), str\n        )\n\n    def full_replace(before: WidgetComponentBase, after: WidgetComponentBase) -&gt; bool:\n        if (\n            before.type != after.type\n            or before.id != after.id\n            or before.key != after.key\n        ):\n            return True\n\n        def full_replace_value(before_value: Any, after_value: Any) -&gt; bool:\n            if isinstance(before_value, list) and isinstance(after_value, list):\n                if len(before_value) != len(after_value):\n                    return True\n                for nth_before_value, nth_after_value in zip(before_value, after_value):\n                    if full_replace_value(nth_before_value, nth_after_value):\n                        return True\n            elif before_value != after_value:\n                if isinstance(before_value, WidgetComponentBase) and isinstance(\n                    after_value, WidgetComponentBase\n                ):\n                    return full_replace(before_value, after_value)\n                else:\n                    return True\n            return False\n\n        for field in before.model_fields_set.union(after.model_fields_set):\n            if (\n                is_streaming_text(before)\n                and is_streaming_text(after)\n                and field == \"value\"\n                and getattr(after, \"value\", \"\").startswith(getattr(before, \"value\", \"\"))\n            ):\n                # Appends to the value prop of Markdown or Text do not trigger a full replace\n                continue\n            if full_replace_value(getattr(before, field), getattr(after, field)):\n                return True\n\n        return False\n\n    if full_replace(before, after):\n        return [WidgetRootUpdated(widget=after)]\n\n    deltas: list[\n        WidgetStreamingTextValueDelta | WidgetComponentUpdated | WidgetRootUpdated\n    ] = []\n\n    def find_all_streaming_text_components(\n        component: WidgetComponent | WidgetRoot,\n    ) -&gt; dict[str, WidgetComponentBase]:\n        components = {}\n\n        def recurse(component: WidgetComponent | WidgetRoot):\n            if is_streaming_text(component) and component.id:\n                components[component.id] = component\n\n            if hasattr(component, \"children\"):\n                children = getattr(component, \"children\", None) or []\n                for child in children:\n                    recurse(child)\n\n        recurse(component)\n        return components\n\n    before_nodes = find_all_streaming_text_components(before)\n    after_nodes = find_all_streaming_text_components(after)\n\n    for id, after_node in after_nodes.items():\n        before_node = before_nodes.get(id)\n        if before_node is None:\n            raise ValueError(\n                f\"Node {id} was not present when the widget was initially rendered. All nodes with ID must persist across all widget updates.\"\n            )\n\n        before_value = str(getattr(before_node, \"value\", None))\n        after_value = str(getattr(after_node, \"value\", None))\n\n        if before_value != after_value:\n            if not after_value.startswith(before_value):\n                raise ValueError(\n                    f\"Node {id} was updated with a new value that is not a prefix of the initial value. All widget updates must be cumulative.\"\n                )\n            done = not getattr(after_node, \"streaming\", False)\n            deltas.append(\n                WidgetStreamingTextValueDelta(\n                    component_id=id,\n                    delta=after_value[len(before_value) :],\n                    done=done,\n                )\n            )\n\n    return deltas\n</code></pre>"},{"location":"api/chatkit/server/#chatkit.server.stream_widget","title":"stream_widget  <code>async</code>","text":"<pre><code>stream_widget(\n    thread: ThreadMetadata,\n    widget: WidgetRoot | AsyncGenerator[WidgetRoot, None],\n    copy_text: str | None = None,\n    generate_id: Callable[\n        [StoreItemType], str\n    ] = default_generate_id,\n) -&gt; AsyncIterator[ThreadStreamEvent]\n</code></pre> <p>Stream a widget root (or async sequence of roots) as ThreadStreamEvents.</p> Source code in <code>chatkit/server.py</code> <pre><code>async def stream_widget(\n    thread: ThreadMetadata,\n    widget: WidgetRoot | AsyncGenerator[WidgetRoot, None],\n    copy_text: str | None = None,\n    generate_id: Callable[[StoreItemType], str] = default_generate_id,\n) -&gt; AsyncIterator[ThreadStreamEvent]:\n    \"\"\"Stream a widget root (or async sequence of roots) as ThreadStreamEvents.\"\"\"\n    item_id = generate_id(\"message\")\n\n    if not isinstance(widget, AsyncGenerator):\n        yield ThreadItemDoneEvent(\n            item=WidgetItem(\n                id=item_id,\n                thread_id=thread.id,\n                created_at=datetime.now(),\n                widget=widget,\n                copy_text=copy_text,\n            ),\n        )\n        return\n\n    initial_state = await widget.__anext__()\n\n    item = WidgetItem(\n        id=item_id,\n        created_at=datetime.now(),\n        widget=initial_state,\n        copy_text=copy_text,\n        thread_id=thread.id,\n    )\n\n    yield ThreadItemAddedEvent(item=item)\n\n    last_state = initial_state\n\n    while widget:\n        try:\n            new_state = await widget.__anext__()\n            for update in diff_widget(last_state, new_state):\n                yield ThreadItemUpdatedEvent(\n                    item_id=item_id,\n                    update=update,\n                )\n            last_state = new_state\n        except StopAsyncIteration:\n            break\n\n    yield ThreadItemDoneEvent(\n        item=item.model_copy(update={\"widget\": last_state}),\n    )\n</code></pre>"},{"location":"api/chatkit/store/","title":"store","text":""},{"location":"api/chatkit/store/#chatkit.store.AttachmentStore","title":"AttachmentStore","text":"<p>               Bases: <code>ABC</code>, <code>Generic[TContext]</code></p> Source code in <code>chatkit/store.py</code> <pre><code>class AttachmentStore(ABC, Generic[TContext]):\n    @abstractmethod\n    async def delete_attachment(self, attachment_id: str, context: TContext) -&gt; None:\n        \"\"\"Delete an attachment by id.\"\"\"\n        pass\n\n    async def create_attachment(\n        self, input: AttachmentCreateParams, context: TContext\n    ) -&gt; Attachment:\n        \"\"\"Create an attachment record from upload metadata.\"\"\"\n        raise NotImplementedError(\n            f\"{type(self).__name__} must override create_attachment() to support two-phase file upload\"\n        )\n\n    def generate_attachment_id(self, mime_type: str, context: TContext) -&gt; str:\n        \"\"\"Return a new identifier for a file. Override this method to customize file ID generation.\"\"\"\n\n        return default_generate_id(\"attachment\")\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.AttachmentStore.delete_attachment","title":"delete_attachment  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete_attachment(\n    attachment_id: str, context: TContext\n) -&gt; None\n</code></pre> <p>Delete an attachment by id.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def delete_attachment(self, attachment_id: str, context: TContext) -&gt; None:\n    \"\"\"Delete an attachment by id.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.AttachmentStore.create_attachment","title":"create_attachment  <code>async</code>","text":"<pre><code>create_attachment(\n    input: AttachmentCreateParams, context: TContext\n) -&gt; Attachment\n</code></pre> <p>Create an attachment record from upload metadata.</p> Source code in <code>chatkit/store.py</code> <pre><code>async def create_attachment(\n    self, input: AttachmentCreateParams, context: TContext\n) -&gt; Attachment:\n    \"\"\"Create an attachment record from upload metadata.\"\"\"\n    raise NotImplementedError(\n        f\"{type(self).__name__} must override create_attachment() to support two-phase file upload\"\n    )\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.AttachmentStore.generate_attachment_id","title":"generate_attachment_id","text":"<pre><code>generate_attachment_id(\n    mime_type: str, context: TContext\n) -&gt; str\n</code></pre> <p>Return a new identifier for a file. Override this method to customize file ID generation.</p> Source code in <code>chatkit/store.py</code> <pre><code>def generate_attachment_id(self, mime_type: str, context: TContext) -&gt; str:\n    \"\"\"Return a new identifier for a file. Override this method to customize file ID generation.\"\"\"\n\n    return default_generate_id(\"attachment\")\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store","title":"Store","text":"<p>               Bases: <code>ABC</code>, <code>Generic[TContext]</code></p> Source code in <code>chatkit/store.py</code> <pre><code>class Store(ABC, Generic[TContext]):\n    def generate_thread_id(self, context: TContext) -&gt; str:\n        \"\"\"Return a new identifier for a thread. Override this method to customize thread ID generation.\"\"\"\n\n        return default_generate_id(\"thread\")\n\n    def generate_item_id(\n        self, item_type: StoreItemType, thread: ThreadMetadata, context: TContext\n    ) -&gt; str:\n        \"\"\"Return a new identifier for a thread item. Override this method to customize item ID generation.\"\"\"\n\n        return default_generate_id(item_type)\n\n    @abstractmethod\n    async def load_thread(self, thread_id: str, context: TContext) -&gt; ThreadMetadata:\n        \"\"\"Load a thread's metadata by id.\"\"\"\n        pass\n\n    @abstractmethod\n    async def save_thread(self, thread: ThreadMetadata, context: TContext) -&gt; None:\n        \"\"\"Persist thread metadata (title, status, etc.).\"\"\"\n        pass\n\n    @abstractmethod\n    async def load_thread_items(\n        self,\n        thread_id: str,\n        after: str | None,\n        limit: int,\n        order: str,\n        context: TContext,\n    ) -&gt; Page[ThreadItem]:\n        \"\"\"Load a page of thread items with pagination controls.\"\"\"\n        pass\n\n    @abstractmethod\n    async def save_attachment(self, attachment: Attachment, context: TContext) -&gt; None:\n        \"\"\"Upsert attachment metadata.\"\"\"\n        pass\n\n    @abstractmethod\n    async def load_attachment(\n        self, attachment_id: str, context: TContext\n    ) -&gt; Attachment:\n        \"\"\"Load attachment metadata by id.\"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_attachment(self, attachment_id: str, context: TContext) -&gt; None:\n        \"\"\"Delete attachment metadata by id.\"\"\"\n        pass\n\n    @abstractmethod\n    async def load_threads(\n        self,\n        limit: int,\n        after: str | None,\n        order: str,\n        context: TContext,\n    ) -&gt; Page[ThreadMetadata]:\n        \"\"\"Load a page of threads with pagination controls.\"\"\"\n        pass\n\n    @abstractmethod\n    async def add_thread_item(\n        self, thread_id: str, item: ThreadItem, context: TContext\n    ) -&gt; None:\n        \"\"\"Persist a newly created thread item.\"\"\"\n        pass\n\n    @abstractmethod\n    async def save_item(\n        self, thread_id: str, item: ThreadItem, context: TContext\n    ) -&gt; None:\n        \"\"\"Upsert a thread item by id.\"\"\"\n        pass\n\n    @abstractmethod\n    async def load_item(\n        self, thread_id: str, item_id: str, context: TContext\n    ) -&gt; ThreadItem:\n        \"\"\"Load a thread item by id.\"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_thread(self, thread_id: str, context: TContext) -&gt; None:\n        \"\"\"Delete a thread and its items.\"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_thread_item(\n        self, thread_id: str, item_id: str, context: TContext\n    ) -&gt; None:\n        \"\"\"Delete a thread item by id.\"\"\"\n        pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.generate_thread_id","title":"generate_thread_id","text":"<pre><code>generate_thread_id(context: TContext) -&gt; str\n</code></pre> <p>Return a new identifier for a thread. Override this method to customize thread ID generation.</p> Source code in <code>chatkit/store.py</code> <pre><code>def generate_thread_id(self, context: TContext) -&gt; str:\n    \"\"\"Return a new identifier for a thread. Override this method to customize thread ID generation.\"\"\"\n\n    return default_generate_id(\"thread\")\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.generate_item_id","title":"generate_item_id","text":"<pre><code>generate_item_id(\n    item_type: StoreItemType,\n    thread: ThreadMetadata,\n    context: TContext,\n) -&gt; str\n</code></pre> <p>Return a new identifier for a thread item. Override this method to customize item ID generation.</p> Source code in <code>chatkit/store.py</code> <pre><code>def generate_item_id(\n    self, item_type: StoreItemType, thread: ThreadMetadata, context: TContext\n) -&gt; str:\n    \"\"\"Return a new identifier for a thread item. Override this method to customize item ID generation.\"\"\"\n\n    return default_generate_id(item_type)\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.load_thread","title":"load_thread  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_thread(\n    thread_id: str, context: TContext\n) -&gt; ThreadMetadata\n</code></pre> <p>Load a thread's metadata by id.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def load_thread(self, thread_id: str, context: TContext) -&gt; ThreadMetadata:\n    \"\"\"Load a thread's metadata by id.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.save_thread","title":"save_thread  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save_thread(\n    thread: ThreadMetadata, context: TContext\n) -&gt; None\n</code></pre> <p>Persist thread metadata (title, status, etc.).</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def save_thread(self, thread: ThreadMetadata, context: TContext) -&gt; None:\n    \"\"\"Persist thread metadata (title, status, etc.).\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.load_thread_items","title":"load_thread_items  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_thread_items(\n    thread_id: str,\n    after: str | None,\n    limit: int,\n    order: str,\n    context: TContext,\n) -&gt; Page[ThreadItem]\n</code></pre> <p>Load a page of thread items with pagination controls.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def load_thread_items(\n    self,\n    thread_id: str,\n    after: str | None,\n    limit: int,\n    order: str,\n    context: TContext,\n) -&gt; Page[ThreadItem]:\n    \"\"\"Load a page of thread items with pagination controls.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.save_attachment","title":"save_attachment  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save_attachment(\n    attachment: Attachment, context: TContext\n) -&gt; None\n</code></pre> <p>Upsert attachment metadata.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def save_attachment(self, attachment: Attachment, context: TContext) -&gt; None:\n    \"\"\"Upsert attachment metadata.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.load_attachment","title":"load_attachment  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_attachment(\n    attachment_id: str, context: TContext\n) -&gt; Attachment\n</code></pre> <p>Load attachment metadata by id.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def load_attachment(\n    self, attachment_id: str, context: TContext\n) -&gt; Attachment:\n    \"\"\"Load attachment metadata by id.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.delete_attachment","title":"delete_attachment  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete_attachment(\n    attachment_id: str, context: TContext\n) -&gt; None\n</code></pre> <p>Delete attachment metadata by id.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def delete_attachment(self, attachment_id: str, context: TContext) -&gt; None:\n    \"\"\"Delete attachment metadata by id.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.load_threads","title":"load_threads  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_threads(\n    limit: int,\n    after: str | None,\n    order: str,\n    context: TContext,\n) -&gt; Page[ThreadMetadata]\n</code></pre> <p>Load a page of threads with pagination controls.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def load_threads(\n    self,\n    limit: int,\n    after: str | None,\n    order: str,\n    context: TContext,\n) -&gt; Page[ThreadMetadata]:\n    \"\"\"Load a page of threads with pagination controls.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.add_thread_item","title":"add_thread_item  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>add_thread_item(\n    thread_id: str, item: ThreadItem, context: TContext\n) -&gt; None\n</code></pre> <p>Persist a newly created thread item.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def add_thread_item(\n    self, thread_id: str, item: ThreadItem, context: TContext\n) -&gt; None:\n    \"\"\"Persist a newly created thread item.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.save_item","title":"save_item  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save_item(\n    thread_id: str, item: ThreadItem, context: TContext\n) -&gt; None\n</code></pre> <p>Upsert a thread item by id.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def save_item(\n    self, thread_id: str, item: ThreadItem, context: TContext\n) -&gt; None:\n    \"\"\"Upsert a thread item by id.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.load_item","title":"load_item  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_item(\n    thread_id: str, item_id: str, context: TContext\n) -&gt; ThreadItem\n</code></pre> <p>Load a thread item by id.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def load_item(\n    self, thread_id: str, item_id: str, context: TContext\n) -&gt; ThreadItem:\n    \"\"\"Load a thread item by id.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.delete_thread","title":"delete_thread  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete_thread(thread_id: str, context: TContext) -&gt; None\n</code></pre> <p>Delete a thread and its items.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def delete_thread(self, thread_id: str, context: TContext) -&gt; None:\n    \"\"\"Delete a thread and its items.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/store/#chatkit.store.Store.delete_thread_item","title":"delete_thread_item  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete_thread_item(\n    thread_id: str, item_id: str, context: TContext\n) -&gt; None\n</code></pre> <p>Delete a thread item by id.</p> Source code in <code>chatkit/store.py</code> <pre><code>@abstractmethod\nasync def delete_thread_item(\n    self, thread_id: str, item_id: str, context: TContext\n) -&gt; None:\n    \"\"\"Delete a thread item by id.\"\"\"\n    pass\n</code></pre>"},{"location":"api/chatkit/types/","title":"types","text":""},{"location":"api/chatkit/types/#chatkit.types.StreamingReq","title":"StreamingReq  <code>module-attribute</code>","text":"<pre><code>StreamingReq = (\n    ThreadsCreateReq\n    | ThreadsAddUserMessageReq\n    | ThreadsAddClientToolOutputReq\n    | ThreadsRetryAfterItemReq\n    | ThreadsCustomActionReq\n)\n</code></pre> <p>Union of request types that produce streaming responses.</p>"},{"location":"api/chatkit/types/#chatkit.types.NonStreamingReq","title":"NonStreamingReq  <code>module-attribute</code>","text":"<pre><code>NonStreamingReq = (\n    ThreadsGetByIdReq\n    | ThreadsListReq\n    | ItemsListReq\n    | ItemsFeedbackReq\n    | AttachmentsCreateReq\n    | AttachmentsDeleteReq\n    | ThreadsUpdateReq\n    | ThreadsDeleteReq\n    | InputTranscribeReq\n    | ThreadsSyncCustomActionReq\n)\n</code></pre> <p>Union of request types that yield immediate responses.</p>"},{"location":"api/chatkit/types/#chatkit.types.ThreadStreamEvent","title":"ThreadStreamEvent  <code>module-attribute</code>","text":"<pre><code>ThreadStreamEvent = Annotated[\n    ThreadCreatedEvent\n    | ThreadUpdatedEvent\n    | ThreadItemDoneEvent\n    | ThreadItemAddedEvent\n    | ThreadItemUpdated\n    | ThreadItemRemovedEvent\n    | ThreadItemReplacedEvent\n    | StreamOptionsEvent\n    | ProgressUpdateEvent\n    | ClientEffectEvent\n    | ErrorEvent\n    | NoticeEvent,\n    Field(discriminator=\"type\"),\n]\n</code></pre> <p>Union of all streaming events emitted to clients.</p>"},{"location":"api/chatkit/types/#chatkit.types.ThreadItemUpdate","title":"ThreadItemUpdate  <code>module-attribute</code>","text":"<pre><code>ThreadItemUpdate = (\n    AssistantMessageContentPartAdded\n    | AssistantMessageContentPartTextDelta\n    | AssistantMessageContentPartAnnotationAdded\n    | AssistantMessageContentPartDone\n    | WidgetStreamingTextValueDelta\n    | WidgetComponentUpdated\n    | WidgetRootUpdated\n    | WorkflowTaskAdded\n    | WorkflowTaskUpdated\n    | GeneratedImageUpdated\n)\n</code></pre> <p>Union of possible updates applied to thread items.</p>"},{"location":"api/chatkit/types/#chatkit.types.ThreadStatus","title":"ThreadStatus  <code>module-attribute</code>","text":"<pre><code>ThreadStatus = Annotated[\n    ActiveStatus | LockedStatus | ClosedStatus,\n    Field(discriminator=\"type\"),\n]\n</code></pre> <p>Union of lifecycle states for a thread.</p>"},{"location":"api/chatkit/types/#chatkit.types.ThreadItem","title":"ThreadItem  <code>module-attribute</code>","text":"<pre><code>ThreadItem = Annotated[\n    UserMessageItem\n    | AssistantMessageItem\n    | ClientToolCallItem\n    | WidgetItem\n    | GeneratedImageItem\n    | WorkflowItem\n    | TaskItem\n    | HiddenContextItem\n    | SDKHiddenContextItem\n    | EndOfTurnItem,\n    Field(discriminator=\"type\"),\n]\n</code></pre> <p>Union of all thread item variants.</p>"},{"location":"api/chatkit/types/#chatkit.types.UserMessageContent","title":"UserMessageContent  <code>module-attribute</code>","text":"<pre><code>UserMessageContent = Annotated[\n    UserMessageTextContent | UserMessageTagContent,\n    Field(discriminator=\"type\"),\n]\n</code></pre> <p>Union of allowed user message content payloads.</p>"},{"location":"api/chatkit/types/#chatkit.types.Attachment","title":"Attachment  <code>module-attribute</code>","text":"<pre><code>Attachment = Annotated[\n    FileAttachment | ImageAttachment,\n    Field(discriminator=\"type\"),\n]\n</code></pre> <p>Union of supported attachment types.</p>"},{"location":"api/chatkit/types/#chatkit.types.WorkflowSummary","title":"WorkflowSummary  <code>module-attribute</code>","text":"<pre><code>WorkflowSummary = CustomSummary | DurationSummary\n</code></pre> <p>Summary variants available for workflows.</p>"},{"location":"api/chatkit/types/#chatkit.types.Task","title":"Task  <code>module-attribute</code>","text":"<pre><code>Task = Annotated[\n    CustomTask\n    | SearchTask\n    | ThoughtTask\n    | FileTask\n    | ImageTask,\n    Field(discriminator=\"type\"),\n]\n</code></pre> <p>Union of workflow task variants.</p>"},{"location":"api/chatkit/types/#chatkit.types.Source","title":"Source  <code>module-attribute</code>","text":"<pre><code>Source = Annotated[\n    URLSource | FileSource | EntitySource,\n    Field(discriminator=\"type\"),\n]\n</code></pre> <p>Union of supported source types.</p>"},{"location":"api/chatkit/types/#chatkit.types.FeedbackKind","title":"FeedbackKind  <code>module-attribute</code>","text":"<pre><code>FeedbackKind = Literal['positive', 'negative']\n</code></pre> <p>Literal type for feedback sentiment.</p>"},{"location":"api/chatkit/types/#chatkit.types.Page","title":"Page","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code></p> <p>Paginated collection of records returned from the API.</p> Source code in <code>chatkit/types.py</code> <pre><code>class Page(BaseModel, Generic[T]):\n    \"\"\"Paginated collection of records returned from the API.\"\"\"\n\n    data: list[T] = []\n    has_more: bool = False\n    after: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.BaseReq","title":"BaseReq","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for all request payloads.</p> Source code in <code>chatkit/types.py</code> <pre><code>class BaseReq(BaseModel):\n    \"\"\"Base class for all request payloads.\"\"\"\n\n    metadata: dict[str, Any] = Field(default_factory=dict)\n    \"\"\"Arbitrary integration-specific metadata.\"\"\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.BaseReq.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any] = Field(default_factory=dict)\n</code></pre> <p>Arbitrary integration-specific metadata.</p>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsGetByIdReq","title":"ThreadsGetByIdReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to fetch a single thread by its identifier.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsGetByIdReq(BaseReq):\n    \"\"\"Request to fetch a single thread by its identifier.\"\"\"\n\n    type: Literal[\"threads.get_by_id\"] = \"threads.get_by_id\"\n    params: ThreadGetByIdParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadGetByIdParams","title":"ThreadGetByIdParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters for retrieving a thread by id.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadGetByIdParams(BaseModel):\n    \"\"\"Parameters for retrieving a thread by id.\"\"\"\n\n    thread_id: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsCreateReq","title":"ThreadsCreateReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to create a new thread from a user message.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsCreateReq(BaseReq):\n    \"\"\"Request to create a new thread from a user message.\"\"\"\n\n    type: Literal[\"threads.create\"] = \"threads.create\"\n    params: ThreadCreateParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadCreateParams","title":"ThreadCreateParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>User input required to create a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadCreateParams(BaseModel):\n    \"\"\"User input required to create a thread.\"\"\"\n\n    input: UserMessageInput\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadListParams","title":"ThreadListParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pagination parameters for listing threads.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadListParams(BaseModel):\n    \"\"\"Pagination parameters for listing threads.\"\"\"\n\n    limit: int | None = None\n    order: Literal[\"asc\", \"desc\"] = \"desc\"\n    after: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsListReq","title":"ThreadsListReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to list threads.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsListReq(BaseReq):\n    \"\"\"Request to list threads.\"\"\"\n\n    type: Literal[\"threads.list\"] = \"threads.list\"\n    params: ThreadListParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsAddUserMessageReq","title":"ThreadsAddUserMessageReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to append a user message to a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsAddUserMessageReq(BaseReq):\n    \"\"\"Request to append a user message to a thread.\"\"\"\n\n    type: Literal[\"threads.add_user_message\"] = \"threads.add_user_message\"\n    params: ThreadAddUserMessageParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadAddUserMessageParams","title":"ThreadAddUserMessageParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters for adding a user message to a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadAddUserMessageParams(BaseModel):\n    \"\"\"Parameters for adding a user message to a thread.\"\"\"\n\n    input: UserMessageInput\n    thread_id: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsAddClientToolOutputReq","title":"ThreadsAddClientToolOutputReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to add a client tool's output to a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsAddClientToolOutputReq(BaseReq):\n    \"\"\"Request to add a client tool's output to a thread.\"\"\"\n\n    type: Literal[\"threads.add_client_tool_output\"] = \"threads.add_client_tool_output\"\n    params: ThreadAddClientToolOutputParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadAddClientToolOutputParams","title":"ThreadAddClientToolOutputParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters for recording tool output in a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadAddClientToolOutputParams(BaseModel):\n    \"\"\"Parameters for recording tool output in a thread.\"\"\"\n\n    thread_id: str\n    result: Any\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsCustomActionReq","title":"ThreadsCustomActionReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to execute a custom action within a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsCustomActionReq(BaseReq):\n    \"\"\"Request to execute a custom action within a thread.\"\"\"\n\n    type: Literal[\"threads.custom_action\"] = \"threads.custom_action\"\n    params: ThreadCustomActionParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsSyncCustomActionReq","title":"ThreadsSyncCustomActionReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to execute a custom action and return a single item update.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsSyncCustomActionReq(BaseReq):\n    \"\"\"Request to execute a custom action and return a single item update.\"\"\"\n\n    type: Literal[\"threads.sync_custom_action\"] = \"threads.sync_custom_action\"\n    params: ThreadCustomActionParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadCustomActionParams","title":"ThreadCustomActionParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters describing the custom action to execute.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadCustomActionParams(BaseModel):\n    \"\"\"Parameters describing the custom action to execute.\"\"\"\n\n    thread_id: str\n    item_id: str | None = None\n    action: Action[str, Any]\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsRetryAfterItemReq","title":"ThreadsRetryAfterItemReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to retry processing after a specific thread item.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsRetryAfterItemReq(BaseReq):\n    \"\"\"Request to retry processing after a specific thread item.\"\"\"\n\n    type: Literal[\"threads.retry_after_item\"] = \"threads.retry_after_item\"\n    params: ThreadRetryAfterItemParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadRetryAfterItemParams","title":"ThreadRetryAfterItemParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters specifying which item to retry.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadRetryAfterItemParams(BaseModel):\n    \"\"\"Parameters specifying which item to retry.\"\"\"\n\n    thread_id: str\n    item_id: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ItemsFeedbackReq","title":"ItemsFeedbackReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to submit feedback on specific items.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ItemsFeedbackReq(BaseReq):\n    \"\"\"Request to submit feedback on specific items.\"\"\"\n\n    type: Literal[\"items.feedback\"] = \"items.feedback\"\n    params: ItemFeedbackParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ItemFeedbackParams","title":"ItemFeedbackParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters describing feedback targets and sentiment.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ItemFeedbackParams(BaseModel):\n    \"\"\"Parameters describing feedback targets and sentiment.\"\"\"\n\n    thread_id: str\n    item_ids: list[str]\n    kind: FeedbackKind\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentsDeleteReq","title":"AttachmentsDeleteReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to remove an attachment.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AttachmentsDeleteReq(BaseReq):\n    \"\"\"Request to remove an attachment.\"\"\"\n\n    type: Literal[\"attachments.delete\"] = \"attachments.delete\"\n    params: AttachmentDeleteParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentDeleteParams","title":"AttachmentDeleteParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters identifying an attachment to delete.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AttachmentDeleteParams(BaseModel):\n    \"\"\"Parameters identifying an attachment to delete.\"\"\"\n\n    attachment_id: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentsCreateReq","title":"AttachmentsCreateReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to register a new attachment.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AttachmentsCreateReq(BaseReq):\n    \"\"\"Request to register a new attachment.\"\"\"\n\n    type: Literal[\"attachments.create\"] = \"attachments.create\"\n    params: AttachmentCreateParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentCreateParams","title":"AttachmentCreateParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata needed to initialize an attachment.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AttachmentCreateParams(BaseModel):\n    \"\"\"Metadata needed to initialize an attachment.\"\"\"\n\n    name: str\n    size: int\n    mime_type: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.InputTranscribeReq","title":"InputTranscribeReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to transcribe an audio payload into text.</p> Source code in <code>chatkit/types.py</code> <pre><code>class InputTranscribeReq(BaseReq):\n    \"\"\"Request to transcribe an audio payload into text.\"\"\"\n\n    type: Literal[\"input.transcribe\"] = \"input.transcribe\"\n    params: InputTranscribeParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.InputTranscribeParams","title":"InputTranscribeParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters for speech transcription.</p> Source code in <code>chatkit/types.py</code> <pre><code>class InputTranscribeParams(BaseModel):\n    \"\"\"Parameters for speech transcription.\"\"\"\n\n    audio_base64: str\n    \"\"\"Base64-encoded audio bytes.\"\"\"\n\n    mime_type: str\n    \"\"\"Raw MIME type for the audio payload, e.g. \"audio/webm;codecs=opus\".\"\"\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.InputTranscribeParams.audio_base64","title":"audio_base64  <code>instance-attribute</code>","text":"<pre><code>audio_base64: str\n</code></pre> <p>Base64-encoded audio bytes.</p>"},{"location":"api/chatkit/types/#chatkit.types.InputTranscribeParams.mime_type","title":"mime_type  <code>instance-attribute</code>","text":"<pre><code>mime_type: str\n</code></pre> <p>Raw MIME type for the audio payload, e.g. \"audio/webm;codecs=opus\".</p>"},{"location":"api/chatkit/types/#chatkit.types.AudioInput","title":"AudioInput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Audio input data for transcription.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AudioInput(BaseModel):\n    \"\"\"Audio input data for transcription.\"\"\"\n\n    data: bytes\n    \"\"\"Audio data bytes.\"\"\"\n\n    mime_type: str\n    \"\"\"Raw MIME type for the audio payload, e.g. \"audio/webm;codecs=opus\".\"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"Media type for the audio payload, e.g. \"audio/webm\".\"\"\"\n        return self.mime_type.split(\";\", 1)[0]\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AudioInput.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: bytes\n</code></pre> <p>Audio data bytes.</p>"},{"location":"api/chatkit/types/#chatkit.types.AudioInput.mime_type","title":"mime_type  <code>instance-attribute</code>","text":"<pre><code>mime_type: str\n</code></pre> <p>Raw MIME type for the audio payload, e.g. \"audio/webm;codecs=opus\".</p>"},{"location":"api/chatkit/types/#chatkit.types.AudioInput.media_type","title":"media_type  <code>property</code>","text":"<pre><code>media_type: str\n</code></pre> <p>Media type for the audio payload, e.g. \"audio/webm\".</p>"},{"location":"api/chatkit/types/#chatkit.types.TranscriptionResult","title":"TranscriptionResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input speech transcription result.</p> Source code in <code>chatkit/types.py</code> <pre><code>class TranscriptionResult(BaseModel):\n    \"\"\"Input speech transcription result.\"\"\"\n\n    text: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ItemsListReq","title":"ItemsListReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to list items inside a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ItemsListReq(BaseReq):\n    \"\"\"Request to list items inside a thread.\"\"\"\n\n    type: Literal[\"items.list\"] = \"items.list\"\n    params: ItemsListParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ItemsListParams","title":"ItemsListParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pagination parameters for listing thread items.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ItemsListParams(BaseModel):\n    \"\"\"Pagination parameters for listing thread items.\"\"\"\n\n    thread_id: str\n    limit: int | None = None\n    order: Literal[\"asc\", \"desc\"] = \"desc\"\n    after: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsUpdateReq","title":"ThreadsUpdateReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to update thread metadata.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsUpdateReq(BaseReq):\n    \"\"\"Request to update thread metadata.\"\"\"\n\n    type: Literal[\"threads.update\"] = \"threads.update\"\n    params: ThreadUpdateParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadUpdateParams","title":"ThreadUpdateParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters for updating a thread's properties.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadUpdateParams(BaseModel):\n    \"\"\"Parameters for updating a thread's properties.\"\"\"\n\n    thread_id: str\n    title: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadsDeleteReq","title":"ThreadsDeleteReq","text":"<p>               Bases: <code>BaseReq</code></p> <p>Request to delete a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadsDeleteReq(BaseReq):\n    \"\"\"Request to delete a thread.\"\"\"\n\n    type: Literal[\"threads.delete\"] = \"threads.delete\"\n    params: ThreadDeleteParams\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadDeleteParams","title":"ThreadDeleteParams","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters identifying a thread to delete.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadDeleteParams(BaseModel):\n    \"\"\"Parameters identifying a thread to delete.\"\"\"\n\n    thread_id: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadCreatedEvent","title":"ThreadCreatedEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a thread is created.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadCreatedEvent(BaseModel):\n    \"\"\"Event emitted when a thread is created.\"\"\"\n\n    type: Literal[\"thread.created\"] = \"thread.created\"\n    thread: Thread\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadUpdatedEvent","title":"ThreadUpdatedEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a thread is updated.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadUpdatedEvent(BaseModel):\n    \"\"\"Event emitted when a thread is updated.\"\"\"\n\n    type: Literal[\"thread.updated\"] = \"thread.updated\"\n    thread: Thread\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadItemAddedEvent","title":"ThreadItemAddedEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a new item is added to a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadItemAddedEvent(BaseModel):\n    \"\"\"Event emitted when a new item is added to a thread.\"\"\"\n\n    type: Literal[\"thread.item.added\"] = \"thread.item.added\"\n    item: ThreadItem\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadItemUpdatedEvent","title":"ThreadItemUpdatedEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event describing an update to an existing thread item.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadItemUpdatedEvent(BaseModel):\n    \"\"\"Event describing an update to an existing thread item.\"\"\"\n\n    type: Literal[\"thread.item.updated\"] = \"thread.item.updated\"\n    item_id: str\n    update: ThreadItemUpdate\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadItemDoneEvent","title":"ThreadItemDoneEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a thread item is marked complete.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadItemDoneEvent(BaseModel):\n    \"\"\"Event emitted when a thread item is marked complete.\"\"\"\n\n    type: Literal[\"thread.item.done\"] = \"thread.item.done\"\n    item: ThreadItem\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadItemRemovedEvent","title":"ThreadItemRemovedEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a thread item is removed.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadItemRemovedEvent(BaseModel):\n    \"\"\"Event emitted when a thread item is removed.\"\"\"\n\n    type: Literal[\"thread.item.removed\"] = \"thread.item.removed\"\n    item_id: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadItemReplacedEvent","title":"ThreadItemReplacedEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a thread item is replaced.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadItemReplacedEvent(BaseModel):\n    \"\"\"Event emitted when a thread item is replaced.\"\"\"\n\n    type: Literal[\"thread.item.replaced\"] = \"thread.item.replaced\"\n    item: ThreadItem\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.StreamOptions","title":"StreamOptions","text":"<p>               Bases: <code>BaseModel</code></p> <p>Settings that control runtime stream behavior.</p> Source code in <code>chatkit/types.py</code> <pre><code>class StreamOptions(BaseModel):\n    \"\"\"Settings that control runtime stream behavior.\"\"\"\n\n    allow_cancel: bool\n    \"\"\"Allow the client to request cancellation mid-stream.\"\"\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.StreamOptions.allow_cancel","title":"allow_cancel  <code>instance-attribute</code>","text":"<pre><code>allow_cancel: bool\n</code></pre> <p>Allow the client to request cancellation mid-stream.</p>"},{"location":"api/chatkit/types/#chatkit.types.StreamOptionsEvent","title":"StreamOptionsEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted to set stream options at runtime.</p> Source code in <code>chatkit/types.py</code> <pre><code>class StreamOptionsEvent(BaseModel):\n    \"\"\"Event emitted to set stream options at runtime.\"\"\"\n\n    type: Literal[\"stream_options\"] = \"stream_options\"\n    stream_options: StreamOptions\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ProgressUpdateEvent","title":"ProgressUpdateEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event providing incremental progress from the assistant.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ProgressUpdateEvent(BaseModel):\n    \"\"\"Event providing incremental progress from the assistant.\"\"\"\n\n    type: Literal[\"progress_update\"] = \"progress_update\"\n    icon: IconName | None = None\n    text: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ClientEffectEvent","title":"ClientEffectEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted to trigger a client side-effect.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ClientEffectEvent(BaseModel):\n    \"\"\"Event emitted to trigger a client side-effect.\"\"\"\n\n    type: Literal[\"client_effect\"] = \"client_effect\"\n    name: str\n    data: dict[str, Any] = Field(default_factory=dict)\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ErrorEvent","title":"ErrorEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event indicating an error occurred while processing a thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ErrorEvent(BaseModel):\n    \"\"\"Event indicating an error occurred while processing a thread.\"\"\"\n\n    type: Literal[\"error\"] = \"error\"\n    code: ErrorCode | Literal[\"custom\"] = Field(default=\"custom\")\n    message: str | None = None\n    allow_retry: bool = Field(default=False)\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.NoticeEvent","title":"NoticeEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event conveying a user-facing notice.</p> Source code in <code>chatkit/types.py</code> <pre><code>class NoticeEvent(BaseModel):\n    \"\"\"Event conveying a user-facing notice.\"\"\"\n\n    type: Literal[\"notice\"] = \"notice\"\n    level: Literal[\"info\", \"warning\", \"danger\"]\n    message: str\n    \"\"\"\n    Supports markdown e.g. \"You've reached your limit of 100 messages. [Upgrade](https://...) to a paid plan.\"\n    \"\"\"\n    title: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.NoticeEvent.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str\n</code></pre> <p>Supports markdown e.g. \"You've reached your limit of 100 messages. Upgrade to a paid plan.\"</p>"},{"location":"api/chatkit/types/#chatkit.types.AssistantMessageContentPartAdded","title":"AssistantMessageContentPartAdded","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when new assistant content is appended.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AssistantMessageContentPartAdded(BaseModel):\n    \"\"\"Event emitted when new assistant content is appended.\"\"\"\n\n    type: Literal[\"assistant_message.content_part.added\"] = (\n        \"assistant_message.content_part.added\"\n    )\n    content_index: int\n    content: AssistantMessageContent\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AssistantMessageContentPartTextDelta","title":"AssistantMessageContentPartTextDelta","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event carrying incremental assistant text output.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AssistantMessageContentPartTextDelta(BaseModel):\n    \"\"\"Event carrying incremental assistant text output.\"\"\"\n\n    type: Literal[\"assistant_message.content_part.text_delta\"] = (\n        \"assistant_message.content_part.text_delta\"\n    )\n    content_index: int\n    delta: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AssistantMessageContentPartAnnotationAdded","title":"AssistantMessageContentPartAnnotationAdded","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event announcing a new annotation on assistant content.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AssistantMessageContentPartAnnotationAdded(BaseModel):\n    \"\"\"Event announcing a new annotation on assistant content.\"\"\"\n\n    type: Literal[\"assistant_message.content_part.annotation_added\"] = (\n        \"assistant_message.content_part.annotation_added\"\n    )\n    content_index: int\n    annotation_index: int\n    annotation: Annotation\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AssistantMessageContentPartDone","title":"AssistantMessageContentPartDone","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event indicating an assistant content part is finalized.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AssistantMessageContentPartDone(BaseModel):\n    \"\"\"Event indicating an assistant content part is finalized.\"\"\"\n\n    type: Literal[\"assistant_message.content_part.done\"] = (\n        \"assistant_message.content_part.done\"\n    )\n    content_index: int\n    content: AssistantMessageContent\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.WidgetStreamingTextValueDelta","title":"WidgetStreamingTextValueDelta","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event streaming widget text deltas.</p> Source code in <code>chatkit/types.py</code> <pre><code>class WidgetStreamingTextValueDelta(BaseModel):\n    \"\"\"Event streaming widget text deltas.\"\"\"\n\n    type: Literal[\"widget.streaming_text.value_delta\"] = (\n        \"widget.streaming_text.value_delta\"\n    )\n    component_id: str\n    delta: str\n    done: bool\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.WidgetRootUpdated","title":"WidgetRootUpdated","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event published when the widget root changes.</p> Source code in <code>chatkit/types.py</code> <pre><code>class WidgetRootUpdated(BaseModel):\n    \"\"\"Event published when the widget root changes.\"\"\"\n\n    type: Literal[\"widget.root.updated\"] = \"widget.root.updated\"\n    widget: WidgetRoot\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.WidgetComponentUpdated","title":"WidgetComponentUpdated","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a widget component updates.</p> Source code in <code>chatkit/types.py</code> <pre><code>class WidgetComponentUpdated(BaseModel):\n    \"\"\"Event emitted when a widget component updates.\"\"\"\n\n    type: Literal[\"widget.component.updated\"] = \"widget.component.updated\"\n    component_id: str\n    component: WidgetComponent\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.WorkflowTaskAdded","title":"WorkflowTaskAdded","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a workflow task is added.</p> Source code in <code>chatkit/types.py</code> <pre><code>class WorkflowTaskAdded(BaseModel):\n    \"\"\"Event emitted when a workflow task is added.\"\"\"\n\n    type: Literal[\"workflow.task.added\"] = \"workflow.task.added\"\n    task_index: int\n    task: Task\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.WorkflowTaskUpdated","title":"WorkflowTaskUpdated","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a workflow task is updated.</p> Source code in <code>chatkit/types.py</code> <pre><code>class WorkflowTaskUpdated(BaseModel):\n    \"\"\"Event emitted when a workflow task is updated.\"\"\"\n\n    type: Literal[\"workflow.task.updated\"] = \"workflow.task.updated\"\n    task_index: int\n    task: Task\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.GeneratedImageUpdated","title":"GeneratedImageUpdated","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event emitted when a generated image is updated.</p> Source code in <code>chatkit/types.py</code> <pre><code>class GeneratedImageUpdated(BaseModel):\n    \"\"\"Event emitted when a generated image is updated.\"\"\"\n\n    type: Literal[\"generated_image.updated\"] = \"generated_image.updated\"\n    image: GeneratedImage\n    progress: float | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.SyncCustomActionResponse","title":"SyncCustomActionResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single thread item update returned by a sync custom action.</p> Source code in <code>chatkit/types.py</code> <pre><code>class SyncCustomActionResponse(BaseModel):\n    \"\"\"Single thread item update returned by a sync custom action.\"\"\"\n    updated_item: ThreadItem | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadMetadata","title":"ThreadMetadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata describing a thread without its items.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadMetadata(BaseModel):\n    \"\"\"Metadata describing a thread without its items.\"\"\"\n\n    title: str | None = None\n    id: str\n    created_at: datetime\n    status: ThreadStatus = Field(default_factory=lambda: ActiveStatus())\n    # TODO - make not client rendered\n    metadata: dict[str, Any] = Field(default_factory=dict)\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ActiveStatus","title":"ActiveStatus","text":"<p>               Bases: <code>BaseModel</code></p> <p>Status indicating the thread is active.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ActiveStatus(BaseModel):\n    \"\"\"Status indicating the thread is active.\"\"\"\n\n    type: Literal[\"active\"] = Field(default=\"active\", frozen=True)\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.LockedStatus","title":"LockedStatus","text":"<p>               Bases: <code>BaseModel</code></p> <p>Status indicating the thread is locked.</p> Source code in <code>chatkit/types.py</code> <pre><code>class LockedStatus(BaseModel):\n    \"\"\"Status indicating the thread is locked.\"\"\"\n\n    type: Literal[\"locked\"] = Field(default=\"locked\", frozen=True)\n    reason: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ClosedStatus","title":"ClosedStatus","text":"<p>               Bases: <code>BaseModel</code></p> <p>Status indicating the thread is closed.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ClosedStatus(BaseModel):\n    \"\"\"Status indicating the thread is closed.\"\"\"\n\n    type: Literal[\"closed\"] = Field(default=\"closed\", frozen=True)\n    reason: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.Thread","title":"Thread","text":"<p>               Bases: <code>ThreadMetadata</code></p> <p>Thread with its paginated items.</p> Source code in <code>chatkit/types.py</code> <pre><code>class Thread(ThreadMetadata):\n    \"\"\"Thread with its paginated items.\"\"\"\n\n    items: Page[ThreadItem]\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThreadItemBase","title":"ThreadItemBase","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base fields shared by all thread items.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThreadItemBase(BaseModel):\n    \"\"\"Base fields shared by all thread items.\"\"\"\n\n    id: str\n    thread_id: str\n    created_at: datetime\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.UserMessageItem","title":"UserMessageItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Thread item representing a user message.</p> Source code in <code>chatkit/types.py</code> <pre><code>class UserMessageItem(ThreadItemBase):\n    \"\"\"Thread item representing a user message.\"\"\"\n\n    type: Literal[\"user_message\"] = \"user_message\"\n    content: list[UserMessageContent]\n    attachments: list[Attachment] = Field(default_factory=list)\n    quoted_text: str | None = None\n    inference_options: InferenceOptions\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AssistantMessageItem","title":"AssistantMessageItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Thread item representing an assistant message.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AssistantMessageItem(ThreadItemBase):\n    \"\"\"Thread item representing an assistant message.\"\"\"\n\n    type: Literal[\"assistant_message\"] = \"assistant_message\"\n    content: list[AssistantMessageContent]\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ClientToolCallItem","title":"ClientToolCallItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Thread item capturing a client tool call.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ClientToolCallItem(ThreadItemBase):\n    \"\"\"Thread item capturing a client tool call.\"\"\"\n\n    type: Literal[\"client_tool_call\"] = \"client_tool_call\"\n    status: Literal[\"pending\", \"completed\"] = \"pending\"\n    call_id: str\n    name: str\n    arguments: dict[str, Any]\n    output: Any | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.WidgetItem","title":"WidgetItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Thread item containing widget content.</p> Source code in <code>chatkit/types.py</code> <pre><code>class WidgetItem(ThreadItemBase):\n    \"\"\"Thread item containing widget content.\"\"\"\n\n    type: Literal[\"widget\"] = \"widget\"\n    widget: WidgetRoot\n    copy_text: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.GeneratedImage","title":"GeneratedImage","text":"<p>               Bases: <code>BaseModel</code></p> <p>Generated image.</p> Source code in <code>chatkit/types.py</code> <pre><code>class GeneratedImage(BaseModel):\n    \"\"\"Generated image.\"\"\"\n\n    id: str\n    url: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.GeneratedImageItem","title":"GeneratedImageItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Thread item containing a generated image.</p> Source code in <code>chatkit/types.py</code> <pre><code>class GeneratedImageItem(ThreadItemBase):\n    \"\"\"Thread item containing a generated image.\"\"\"\n\n    type: Literal[\"generated_image\"] = \"generated_image\"\n    image: GeneratedImage | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.TaskItem","title":"TaskItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Thread item containing a task.</p> Source code in <code>chatkit/types.py</code> <pre><code>class TaskItem(ThreadItemBase):\n    \"\"\"Thread item containing a task.\"\"\"\n\n    type: Literal[\"task\"] = \"task\"\n    task: Task\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.WorkflowItem","title":"WorkflowItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Thread item representing a workflow.</p> Source code in <code>chatkit/types.py</code> <pre><code>class WorkflowItem(ThreadItemBase):\n    \"\"\"Thread item representing a workflow.\"\"\"\n\n    type: Literal[\"workflow\"] = \"workflow\"\n    workflow: Workflow\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.EndOfTurnItem","title":"EndOfTurnItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Marker item indicating the assistant ends its turn.</p> Source code in <code>chatkit/types.py</code> <pre><code>class EndOfTurnItem(ThreadItemBase):\n    \"\"\"Marker item indicating the assistant ends its turn.\"\"\"\n\n    type: Literal[\"end_of_turn\"] = \"end_of_turn\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.HiddenContextItem","title":"HiddenContextItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>HiddenContext is never sent to the client. It's not officially part of ChatKit.js. It is only used internally to store additional context in a specific place in the thread.</p> Source code in <code>chatkit/types.py</code> <pre><code>class HiddenContextItem(ThreadItemBase):\n    \"\"\"\n    HiddenContext is never sent to the client. It's not officially part of ChatKit.js.\n    It is only used internally to store additional context in a specific place in the thread.\n    \"\"\"\n\n    type: Literal[\"hidden_context_item\"] = \"hidden_context_item\"\n    content: Any\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.SDKHiddenContextItem","title":"SDKHiddenContextItem","text":"<p>               Bases: <code>ThreadItemBase</code></p> <p>Hidden context that is used by the ChatKit Python SDK for storing additional context for internal operations.</p> Source code in <code>chatkit/types.py</code> <pre><code>class SDKHiddenContextItem(ThreadItemBase):\n    \"\"\"\n    Hidden context that is used by the ChatKit Python SDK for storing additional context\n    for internal operations.\n    \"\"\"\n\n    type: Literal[\"sdk_hidden_context\"] = \"sdk_hidden_context\"\n    content: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AssistantMessageContent","title":"AssistantMessageContent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Assistant message content consisting of text and annotations.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AssistantMessageContent(BaseModel):\n    \"\"\"Assistant message content consisting of text and annotations.\"\"\"\n\n    annotations: list[Annotation] = Field(default_factory=list)\n    text: str\n    type: Literal[\"output_text\"] = \"output_text\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.Annotation","title":"Annotation","text":"<p>               Bases: <code>BaseModel</code></p> <p>Reference to supporting context attached to assistant output.</p> Source code in <code>chatkit/types.py</code> <pre><code>class Annotation(BaseModel):\n    \"\"\"Reference to supporting context attached to assistant output.\"\"\"\n\n    type: Literal[\"annotation\"] = \"annotation\"\n    source: URLSource | FileSource | EntitySource\n    index: int | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.UserMessageInput","title":"UserMessageInput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Payload describing a user message submission.</p> Source code in <code>chatkit/types.py</code> <pre><code>class UserMessageInput(BaseModel):\n    \"\"\"Payload describing a user message submission.\"\"\"\n\n    content: list[UserMessageContent]\n    attachments: list[str]\n    quoted_text: str | None = None\n    inference_options: InferenceOptions\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.UserMessageTextContent","title":"UserMessageTextContent","text":"<p>               Bases: <code>BaseModel</code></p> <p>User message content containing plaintext.</p> Source code in <code>chatkit/types.py</code> <pre><code>class UserMessageTextContent(BaseModel):\n    \"\"\"User message content containing plaintext.\"\"\"\n\n    type: Literal[\"input_text\"] = \"input_text\"\n    text: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.UserMessageTagContent","title":"UserMessageTagContent","text":"<p>               Bases: <code>BaseModel</code></p> <p>User message content representing an interactive tag.</p> Source code in <code>chatkit/types.py</code> <pre><code>class UserMessageTagContent(BaseModel):\n    \"\"\"User message content representing an interactive tag.\"\"\"\n\n    type: Literal[\"input_tag\"] = \"input_tag\"\n    id: str\n    text: str\n    data: dict[str, Any]\n    group: str | None = None\n    interactive: bool = False\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.InferenceOptions","title":"InferenceOptions","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model and tool configuration for message processing.</p> Source code in <code>chatkit/types.py</code> <pre><code>class InferenceOptions(BaseModel):\n    \"\"\"Model and tool configuration for message processing.\"\"\"\n\n    tool_choice: ToolChoice | None = None\n    model: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ToolChoice","title":"ToolChoice","text":"<p>               Bases: <code>BaseModel</code></p> <p>Explicit tool selection for the assistant to invoke.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ToolChoice(BaseModel):\n    \"\"\"Explicit tool selection for the assistant to invoke.\"\"\"\n\n    id: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentUploadDescriptor","title":"AttachmentUploadDescriptor","text":"<p>               Bases: <code>BaseModel</code></p> <p>Two-phase upload instructions.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AttachmentUploadDescriptor(BaseModel):\n    \"\"\"Two-phase upload instructions.\"\"\"\n\n    url: AnyUrl\n    method: Literal[\"POST\", \"PUT\"]\n    \"\"\"The HTTP method to use when uploading the file for two-phase upload.\"\"\"\n    headers: dict[str, str] = Field(default_factory=dict)\n    \"\"\"Optional headers to include in the upload request.\"\"\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentUploadDescriptor.method","title":"method  <code>instance-attribute</code>","text":"<pre><code>method: Literal['POST', 'PUT']\n</code></pre> <p>The HTTP method to use when uploading the file for two-phase upload.</p>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentUploadDescriptor.headers","title":"headers  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>headers: dict[str, str] = Field(default_factory=dict)\n</code></pre> <p>Optional headers to include in the upload request.</p>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentBase","title":"AttachmentBase","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base metadata shared by all attachments.</p> Source code in <code>chatkit/types.py</code> <pre><code>class AttachmentBase(BaseModel):\n    \"\"\"Base metadata shared by all attachments.\"\"\"\n\n    id: str\n    name: str\n    mime_type: str\n    upload_descriptor: AttachmentUploadDescriptor | None = None\n    \"\"\"\n    Two-phase upload instructions.\n    Should be set to None after upload is complete or when using direct upload\n    where uploading happens when creating the attachment object.\n    \"\"\"\n    thread_id: str | None = None\n    \"\"\"\n    The thread the attachment belongs to, if any.\n    Added when the user message that contains the attachment is saved to store.\n    \"\"\"\n    metadata: dict[str, Any] | None = None\n    \"\"\"\n    Integration-only metadata stored with the attachment. Ignored by ChatKit and not\n    returned in ChatKitServer responses. If you serialize attachments from a custom\n    direct-upload endpoint and want to omit this field, pass context={\"exclude_metadata\": True}.\n    \"\"\"\n\n    @model_serializer(mode=\"wrap\")\n    def _serialize(self, serializer, info: SerializationInfo):\n        data = serializer(self)\n        if isinstance(data, dict) and (info.context or {}).get(\"exclude_metadata\"):\n            data.pop(\"metadata\", None)\n        return data\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentBase.upload_descriptor","title":"upload_descriptor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>upload_descriptor: AttachmentUploadDescriptor | None = None\n</code></pre> <p>Two-phase upload instructions. Should be set to None after upload is complete or when using direct upload where uploading happens when creating the attachment object.</p>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentBase.thread_id","title":"thread_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>thread_id: str | None = None\n</code></pre> <p>The thread the attachment belongs to, if any. Added when the user message that contains the attachment is saved to store.</p>"},{"location":"api/chatkit/types/#chatkit.types.AttachmentBase.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any] | None = None\n</code></pre> <p>Integration-only metadata stored with the attachment. Ignored by ChatKit and not returned in ChatKitServer responses. If you serialize attachments from a custom direct-upload endpoint and want to omit this field, pass context={\"exclude_metadata\": True}.</p>"},{"location":"api/chatkit/types/#chatkit.types.FileAttachment","title":"FileAttachment","text":"<p>               Bases: <code>AttachmentBase</code></p> <p>Attachment representing a generic file.</p> Source code in <code>chatkit/types.py</code> <pre><code>class FileAttachment(AttachmentBase):\n    \"\"\"Attachment representing a generic file.\"\"\"\n\n    type: Literal[\"file\"] = \"file\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ImageAttachment","title":"ImageAttachment","text":"<p>               Bases: <code>AttachmentBase</code></p> <p>Attachment representing an image resource.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ImageAttachment(AttachmentBase):\n    \"\"\"Attachment representing an image resource.\"\"\"\n\n    type: Literal[\"image\"] = \"image\"\n    preview_url: AnyUrl\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.Workflow","title":"Workflow","text":"<p>               Bases: <code>BaseModel</code></p> <p>Workflow attached to a thread with optional summary.</p> Source code in <code>chatkit/types.py</code> <pre><code>class Workflow(BaseModel):\n    \"\"\"Workflow attached to a thread with optional summary.\"\"\"\n\n    type: Literal[\"custom\", \"reasoning\"]\n    tasks: list[Task]\n    summary: WorkflowSummary | None = None\n    expanded: bool = False\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.CustomSummary","title":"CustomSummary","text":"<p>               Bases: <code>BaseModel</code></p> <p>Custom summary for a workflow.</p> Source code in <code>chatkit/types.py</code> <pre><code>class CustomSummary(BaseModel):\n    \"\"\"Custom summary for a workflow.\"\"\"\n\n    title: str\n    icon: IconName | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.DurationSummary","title":"DurationSummary","text":"<p>               Bases: <code>BaseModel</code></p> <p>Summary providing total workflow duration.</p> Source code in <code>chatkit/types.py</code> <pre><code>class DurationSummary(BaseModel):\n    \"\"\"Summary providing total workflow duration.\"\"\"\n\n    duration: int\n    \"\"\"The duration of the workflow in seconds\"\"\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.DurationSummary.duration","title":"duration  <code>instance-attribute</code>","text":"<pre><code>duration: int\n</code></pre> <p>The duration of the workflow in seconds</p>"},{"location":"api/chatkit/types/#chatkit.types.BaseTask","title":"BaseTask","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base fields common to all workflow tasks.</p> Source code in <code>chatkit/types.py</code> <pre><code>class BaseTask(BaseModel):\n    \"\"\"Base fields common to all workflow tasks.\"\"\"\n\n    status_indicator: Literal[\"none\", \"loading\", \"complete\"] = \"none\"\n    \"\"\"Only used when rendering the task as part of a workflow. Indicates the status of the task.\"\"\"\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.BaseTask.status_indicator","title":"status_indicator  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_indicator: Literal[\"none\", \"loading\", \"complete\"] = (\n    \"none\"\n)\n</code></pre> <p>Only used when rendering the task as part of a workflow. Indicates the status of the task.</p>"},{"location":"api/chatkit/types/#chatkit.types.CustomTask","title":"CustomTask","text":"<p>               Bases: <code>BaseTask</code></p> <p>Workflow task displaying custom content.</p> Source code in <code>chatkit/types.py</code> <pre><code>class CustomTask(BaseTask):\n    \"\"\"Workflow task displaying custom content.\"\"\"\n\n    type: Literal[\"custom\"] = \"custom\"\n    title: str | None = None\n    icon: IconName | None = None\n    content: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.SearchTask","title":"SearchTask","text":"<p>               Bases: <code>BaseTask</code></p> <p>Workflow task representing a web search.</p> Source code in <code>chatkit/types.py</code> <pre><code>class SearchTask(BaseTask):\n    \"\"\"Workflow task representing a web search.\"\"\"\n\n    type: Literal[\"web_search\"] = \"web_search\"\n    title: str | None = None\n    title_query: str | None = None\n    queries: list[str] = Field(default_factory=list)\n    sources: list[URLSource] = Field(default_factory=list)\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ThoughtTask","title":"ThoughtTask","text":"<p>               Bases: <code>BaseTask</code></p> <p>Workflow task capturing assistant reasoning.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ThoughtTask(BaseTask):\n    \"\"\"Workflow task capturing assistant reasoning.\"\"\"\n\n    type: Literal[\"thought\"] = \"thought\"\n    title: str | None = None\n    content: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.FileTask","title":"FileTask","text":"<p>               Bases: <code>BaseTask</code></p> <p>Workflow task referencing file sources.</p> Source code in <code>chatkit/types.py</code> <pre><code>class FileTask(BaseTask):\n    \"\"\"Workflow task referencing file sources.\"\"\"\n\n    type: Literal[\"file\"] = \"file\"\n    title: str | None = None\n    sources: list[FileSource] = Field(default_factory=list)\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.ImageTask","title":"ImageTask","text":"<p>               Bases: <code>BaseTask</code></p> <p>Workflow task rendering image content.</p> Source code in <code>chatkit/types.py</code> <pre><code>class ImageTask(BaseTask):\n    \"\"\"Workflow task rendering image content.\"\"\"\n\n    type: Literal[\"image\"] = \"image\"\n    title: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.SourceBase","title":"SourceBase","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for sources displayed to users.</p> Source code in <code>chatkit/types.py</code> <pre><code>class SourceBase(BaseModel):\n    \"\"\"Base class for sources displayed to users.\"\"\"\n\n    title: str\n    description: str | None = None\n    timestamp: str | None = None\n    group: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.FileSource","title":"FileSource","text":"<p>               Bases: <code>SourceBase</code></p> <p>Source metadata for file-based references.</p> Source code in <code>chatkit/types.py</code> <pre><code>class FileSource(SourceBase):\n    \"\"\"Source metadata for file-based references.\"\"\"\n\n    type: Literal[\"file\"] = \"file\"\n    filename: str\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.URLSource","title":"URLSource","text":"<p>               Bases: <code>SourceBase</code></p> <p>Source metadata for external URLs.</p> Source code in <code>chatkit/types.py</code> <pre><code>class URLSource(SourceBase):\n    \"\"\"Source metadata for external URLs.\"\"\"\n\n    type: Literal[\"url\"] = \"url\"\n    url: str\n    attribution: str | None = None\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.EntitySource","title":"EntitySource","text":"<p>               Bases: <code>SourceBase</code></p> <p>Source metadata for entity references.</p> Source code in <code>chatkit/types.py</code> <pre><code>class EntitySource(SourceBase):\n    \"\"\"Source metadata for entity references.\"\"\"\n\n    type: Literal[\"entity\"] = \"entity\"\n    id: str\n    icon: IconName | None = None\n    label: str | None = None\n    \"\"\"Optional label shown with the icon in the default entity hover header\n    when no preview callback is provided.\n    \"\"\"\n    inline_label: str | None = None\n    \"\"\"Optional label for the inline annotation view. When not provided, the icon is used instead.\"\"\"\n    interactive: bool = False\n    \"\"\"Per-entity toggle to wire client callbacks and render this entity as interactive.\"\"\"\n    data: dict[str, Any] = Field(default_factory=dict)\n    \"\"\"Additional data for the entity source that is passed to client entity callbacks.\"\"\"\n\n    preview: Literal[\"lazy\"] | None = Field(\n        default=None,\n        deprecated=True,\n        description=\"This field is ignored. Please use the entities.onRequestPreview ChatKit.js option instead.\",\n    )\n</code></pre>"},{"location":"api/chatkit/types/#chatkit.types.EntitySource.label","title":"label  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>label: str | None = None\n</code></pre> <p>Optional label shown with the icon in the default entity hover header when no preview callback is provided.</p>"},{"location":"api/chatkit/types/#chatkit.types.EntitySource.inline_label","title":"inline_label  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>inline_label: str | None = None\n</code></pre> <p>Optional label for the inline annotation view. When not provided, the icon is used instead.</p>"},{"location":"api/chatkit/types/#chatkit.types.EntitySource.interactive","title":"interactive  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>interactive: bool = False\n</code></pre> <p>Per-entity toggle to wire client callbacks and render this entity as interactive.</p>"},{"location":"api/chatkit/types/#chatkit.types.EntitySource.data","title":"data  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>data: dict[str, Any] = Field(default_factory=dict)\n</code></pre> <p>Additional data for the entity source that is passed to client entity callbacks.</p>"},{"location":"api/chatkit/types/#chatkit.types.is_streaming_req","title":"is_streaming_req","text":"<pre><code>is_streaming_req(\n    request: ChatKitReq,\n) -&gt; TypeIs[StreamingReq]\n</code></pre> <p>Return True if the given request should be processed as streaming.</p> Source code in <code>chatkit/types.py</code> <pre><code>def is_streaming_req(request: ChatKitReq) -&gt; TypeIs[StreamingReq]:\n    \"\"\"Return True if the given request should be processed as streaming.\"\"\"\n    return isinstance(\n        request,\n        (\n            ThreadsCreateReq,\n            ThreadsAddUserMessageReq,\n            ThreadsRetryAfterItemReq,\n            ThreadsAddClientToolOutputReq,\n            ThreadsCustomActionReq,\n        ),\n    )\n</code></pre>"},{"location":"api/chatkit/widgets/","title":"widgets","text":""},{"location":"api/chatkit/widgets/#chatkit.widgets.WidgetTemplate","title":"WidgetTemplate","text":"<p>Utility for loading and building widgets from a .widget file.</p> <p>Example using .widget file on disc: <pre><code>template = WidgetTemplate.from_file(\"path/to/my_widget.widget\")\nwidget = template.build({\"name\": \"Harry Potter\"})\n</code></pre></p> <p>Example using already parsed widget definition: <pre><code>template = WidgetTemplate(definition={\"version\": \"1.0\", \"name\": \"...\", \"template\": Template(...), \"jsonSchema\": {...}})\nwidget = template.build({\"name\": \"Harry Potter\"})\n</code></pre></p> Source code in <code>chatkit/widgets.py</code> <pre><code>class WidgetTemplate:\n    \"\"\"\n    Utility for loading and building widgets from a .widget file.\n\n    Example using .widget file on disc:\n    ```python\n    template = WidgetTemplate.from_file(\"path/to/my_widget.widget\")\n    widget = template.build({\"name\": \"Harry Potter\"})\n    ```\n\n    Example using already parsed widget definition:\n    ```python\n    template = WidgetTemplate(definition={\"version\": \"1.0\", \"name\": \"...\", \"template\": Template(...), \"jsonSchema\": {...}})\n    widget = template.build({\"name\": \"Harry Potter\"})\n    ```\n    \"\"\"\n\n    def __init__(self, definition: dict[str, Any]):\n        self.version = definition[\"version\"]\n        if self.version != \"1.0\":\n            raise ValueError(f\"Unsupported widget spec version: {self.version}\")\n\n        self.name = definition[\"name\"]\n        template = definition[\"template\"]\n        if isinstance(template, Template):\n            self.template = template\n        else:\n            self.template = _jinja_env.from_string(template)\n        self.data_schema = definition.get(\"jsonSchema\", {})\n\n    @classmethod\n    def from_file(cls, file_path: str) -&gt; WidgetTemplate:\n        path = Path(file_path)\n        if not path.is_absolute():\n            caller_frame = inspect.stack()[1]\n            caller_path = Path(caller_frame.filename).resolve()\n            path = caller_path.parent / path\n\n        with path.open(\"r\", encoding=\"utf-8\") as file:\n            payload = json.load(file)\n\n        return cls(payload)\n\n    def build(\n        self, data: dict[str, Any] | BaseModel | None = None\n    ) -&gt; DynamicWidgetRoot:\n        \"\"\"Render the widget template with the given data and return a DynamicWidgetRoot instance.\"\"\"\n        rendered = self.template.render(**self._normalize_data(data))\n        widget_dict = json.loads(rendered)\n        return DynamicWidgetRoot.model_validate(widget_dict)\n\n    @deprecated(\"WidgetTemplate.build_basic is deprecated. Use WidgetTemplate.build instead.\")\n    def build_basic(self, data: dict[str, Any] | BaseModel | None = None) -&gt; BasicRoot:\n        \"\"\"Deprecated alias for building Basic root widgets.\"\"\"\n        rendered = self.template.render(**self._normalize_data(data))\n        widget_dict = json.loads(rendered)\n        return BasicRoot.model_validate(widget_dict)\n\n    def _normalize_data(\n        self, data: dict[str, Any] | BaseModel | None\n    ) -&gt; dict[str, Any]:\n        if data is None:\n            return {}\n        return data.model_dump() if isinstance(data, BaseModel) else data\n</code></pre>"},{"location":"api/chatkit/widgets/#chatkit.widgets.WidgetTemplate.build","title":"build","text":"<pre><code>build(\n    data: dict[str, Any] | BaseModel | None = None,\n) -&gt; DynamicWidgetRoot\n</code></pre> <p>Render the widget template with the given data and return a DynamicWidgetRoot instance.</p> Source code in <code>chatkit/widgets.py</code> <pre><code>def build(\n    self, data: dict[str, Any] | BaseModel | None = None\n) -&gt; DynamicWidgetRoot:\n    \"\"\"Render the widget template with the given data and return a DynamicWidgetRoot instance.\"\"\"\n    rendered = self.template.render(**self._normalize_data(data))\n    widget_dict = json.loads(rendered)\n    return DynamicWidgetRoot.model_validate(widget_dict)\n</code></pre>"},{"location":"api/chatkit/widgets/#chatkit.widgets.WidgetTemplate.build_basic","title":"build_basic","text":"<pre><code>build_basic(\n    data: dict[str, Any] | BaseModel | None = None,\n) -&gt; BasicRoot\n</code></pre> <p>Deprecated alias for building Basic root widgets.</p> Source code in <code>chatkit/widgets.py</code> <pre><code>@deprecated(\"WidgetTemplate.build_basic is deprecated. Use WidgetTemplate.build instead.\")\ndef build_basic(self, data: dict[str, Any] | BaseModel | None = None) -&gt; BasicRoot:\n    \"\"\"Deprecated alias for building Basic root widgets.\"\"\"\n    rendered = self.template.render(**self._normalize_data(data))\n    widget_dict = json.loads(rendered)\n    return BasicRoot.model_validate(widget_dict)\n</code></pre>"},{"location":"api/chatkit/widgets/#chatkit.widgets.DynamicWidgetRoot","title":"DynamicWidgetRoot","text":"<p>               Bases: <code>DynamicWidgetComponent</code></p> <p>Dynamic root widget restricted to root types.</p> Source code in <code>chatkit/widgets.py</code> <pre><code>class DynamicWidgetRoot(DynamicWidgetComponent):\n    \"\"\"Dynamic root widget restricted to root types.\"\"\"\n\n    type: Literal[\"Card\", \"ListView\", \"Basic\"]  # pyright: ignore\n</code></pre>"},{"location":"api/chatkit/widgets/#chatkit.widgets.BasicRoot","title":"BasicRoot","text":"<p>               Bases: <code>DynamicWidgetComponent</code></p> <p>Layout root capable of nesting components or other roots.</p> Source code in <code>chatkit/widgets.py</code> <pre><code>class BasicRoot(DynamicWidgetComponent):\n    \"\"\"Layout root capable of nesting components or other roots.\"\"\"\n\n    type: Literal[\"Basic\"] = Field(default=\"Basic\", frozen=True)  # pyright: ignore\n</code></pre>"},{"location":"api/chatkit/widgets/#chatkit.widgets.DynamicWidgetComponent","title":"DynamicWidgetComponent","text":"<p>               Bases: <code>WidgetComponentBase</code></p> <p>A widget component with a statically defined base shape but dynamically defined additional fields loaded from a widget template or JSON schema.</p> Source code in <code>chatkit/widgets.py</code> <pre><code>class DynamicWidgetComponent(WidgetComponentBase):\n    \"\"\"\n    A widget component with a statically defined base shape but dynamically\n    defined additional fields loaded from a widget template or JSON schema.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n    children: DynamicWidgetComponent | list[DynamicWidgetComponent] | None = None\n</code></pre>"},{"location":"concepts/actions/","title":"Actions","text":"<p>ChatKit actions are interaction events triggered by widgets or client code that let the client and server run logic or start a model response independently of user messages.</p>"},{"location":"concepts/actions/#widget-actions","title":"Widget actions","text":"<p>Widget actions are specified in the widget definition itself (for example, <code>Button.onClickAction</code>), so every interaction carries a typed action payload plus the widget item that fired it. By default actions are routed to the server, but you can set <code>handler: \"client\"</code> when you want to intercept the action in the browser first.</p>"},{"location":"concepts/actions/#server-handled-actions","title":"Server-handled actions","text":"<p>If you leave the handler unset, the action is delivered to <code>ChatKitServer.action(thread, action, sender, context)</code>, where <code>sender</code> is the widget item that triggered it when that item is available. Server handling is the right choice when you need to mutate thread state, stream widget or message updates, or start an agent response without a new user message. Record important interactions as hidden context so the model can react on the next turn (for example, \u201cuser clicked confirm\u201d), and treat <code>action.payload</code> as untrusted input that must be validated and authorized before you persist anything.</p>"},{"location":"concepts/actions/#client-handled-actions","title":"Client-handled actions","text":"<p>When you set <code>handler: \"client\"</code>, the action flows into the client SDK\u2019s <code>widgets.onAction</code> callback so you can do immediate UI work such as opening dialogs, navigating, or running local validation. Client handlers can still forward a follow-up action to the server with <code>chatkit.sendCustomAction()</code> after local logic finishes. The server thread stays unchanged unless you explicitly send that follow-up action or a message.</p>"},{"location":"concepts/actions/#sync-server-handled-actions","title":"Sync server-handled actions","text":"<p>Normally, widget actions are blocked while a thread is streaming a response. This prevents race conditions, but it can be limiting when a widget action is only going to update itself or trigger side effects outside the thread. To get around this limitation, set <code>streaming: \"false\"</code>, which delivers the action to <code>ChatKitServer.sync_action(thread, action, sender, context)</code>. Use this handler to run any side effects and update the widget's UI as needed.</p>"},{"location":"concepts/actions/#client-sent-actions-using-the-chatkitsendcustomaction-command","title":"Client-sent actions using the chatkit.sendCustomAction() command","text":"<p>Your client integration can also initiate actions directly with <code>chatkit.sendCustomAction(action, itemId?)</code>, optionally namespaced to a specific widget item. The server receives these in <code>ChatKitServer.action</code> just like a widget-triggered action and can stream widgets, messages, or client effects in response. This pattern is useful when a flow starts outside a widget\u2014or after a client-handled action\u2014but you still want the server to persist results or involve the model.</p>"},{"location":"concepts/actions/#related-guides","title":"Related guides","text":"<ul> <li>Build interactive responses with widgets</li> </ul>"},{"location":"concepts/entities/","title":"Entities","text":"<p>Entities are structured pieces of information your system can recognize during a conversation, such as names, dates, IDs, or product-specific objects.</p> <p>They represent meaningful objects in your app\u2019s domain. For example:</p> <ul> <li>In a notes app, entities might be documents.</li> <li>In a news site, they might be articles.</li> <li>In an online store, they might be products.</li> </ul> <p>When referenced, entities can link messages to real data and power richer actions and previews.</p>"},{"location":"concepts/entities/#entity-sources-for-assistant-messages","title":"Entity sources for assistant messages","text":"<p>Entities can be used as cited sources in assistant responses.</p> <p>References:</p> <ul> <li>The EntitySource Pydantic model definition</li> <li>Add annotations in assistant messages.</li> </ul>"},{"location":"concepts/entities/#entity-tags-as-mentions-in-user-messages","title":"Entity tags as @-mentions in user messages","text":"<p>Users can tag your entities in the composer using @-mentions.</p> <p>References:</p> <ul> <li>The Entity TypeScript type definition</li> <li>The UserMessageTagContent Pydantic model definition</li> <li>Accept rich user input.</li> </ul>"},{"location":"concepts/thread-stream-events/","title":"Thread stream events","text":"<p><code>ThreadStreamEvent</code>s are the Server-Sent Event (SSE) payloads streamed by ChatKitServer while responding to a user message or action. They keep the client UI in sync with server-side processing and drive persistence in your store.</p>"},{"location":"concepts/thread-stream-events/#thread-metadata-updates","title":"Thread metadata updates","text":"<p>ChatKitServer emits these after it creates a thread or notices metadata changes (title, status, etc.) so the UI stays in sync.</p> <ul> <li><code>ThreadCreatedEvent</code>: introduce a new thread</li> <li><code>ThreadUpdatedEvent</code>: update the current thread metadata such as title or status</li> </ul>"},{"location":"concepts/thread-stream-events/#thread-item-events","title":"Thread item events","text":"<p>Thread item events drive the conversation state. ChatKitServer processes these events to persist conversation state before streaming them back to the client.</p> <ul> <li><code>ThreadItemAddedEvent</code>: introduce a new item (message, tool call, workflow, widget, etc).</li> <li><code>ThreadItemUpdatedEvent</code>: mutate a pending item (e.g., stream text deltas, workflow task updates).</li> <li><code>ThreadItemDoneEvent</code>: mark an item complete and persist it.</li> <li><code>ThreadItemRemovedEvent</code>: delete an item by id.</li> <li><code>ThreadItemReplacedEvent</code>: swap an item in place.</li> </ul> <p>Note: <code>ThreadItemAddedEvent</code> does not persist the item. <code>ChatKitServer</code> saves on <code>ThreadItemDoneEvent</code>/<code>ThreadItemReplacedEvent</code>, tracks pending items in between, and handles store writes for all <code>ThreadItem*Event</code>s.</p>"},{"location":"concepts/thread-stream-events/#errors","title":"Errors","text":"<p>Stream <code>ErrorEvent</code>s for user-facing errors in the chat UI. You can configure a custom message and whether a retry button is shown to the user.</p>"},{"location":"concepts/thread-stream-events/#progress-updates","title":"Progress updates","text":"<p>Stream <code>ProgressUpdateEvent</code>s to show the user transient status while work is in flight.</p> <p>See Show progress while tools run for more info.</p>"},{"location":"concepts/thread-stream-events/#client-effects","title":"Client effects","text":"<p>Use <code>ClientEffectEvent</code> to trigger fire-and-forget behavior on the client such as opening a dialog or pushing updates.</p> <p>See Trigger client-side effects without blocking for more info.</p>"},{"location":"concepts/thread-stream-events/#stream-options","title":"Stream options","text":"<p><code>StreamOptionsEvent</code> configures runtime stream behavior (for example, allowing user cancellation). <code>ChatKitServer</code> emits one at the start of every stream using <code>get_stream_options</code>; override that method to change defaults such as <code>allow_cancel</code>.</p>"},{"location":"concepts/thread-stream-events/#related-guides","title":"Related guides","text":"<ul> <li>Respond to a user message</li> </ul>"},{"location":"concepts/threads/","title":"Threads and items","text":"<p>In ChatKit, a thread represents a single conversation. It is the unit that ties together everything that happens in that conversation: messages, widgets, actions, system signals, and metadata. A thread is stored as an ordered history of thread items, which ChatKit loads, paginates, and renders as needed.</p>"},{"location":"concepts/threads/#what-is-a-thread","title":"What is a thread?","text":"<p>A thread is an ordered timeline that contains:</p> <ul> <li>Conversation history (user and assistant messages)</li> <li>Structured content such as widgets and workflows</li> <li>Internal signals that guide processing or model behavior</li> <li>Metadata like titles or status flags</li> </ul> <p>Threads are persisted by your store implementation and can be updated, continued, or made read-only according to your application\u2019s needs.</p>"},{"location":"concepts/threads/#what-are-thread-items","title":"What are thread items?","text":"<p>Thread items are the individual records that make up a thread. Each item represents one meaningful unit in the conversation history, such as:</p> <ul> <li>A user message</li> <li>An assistant response</li> <li>A widget rendered by the assistant</li> <li>A non-visible signal used only for model input</li> </ul> <p>ChatKit maintains the order of items, streams new ones as they are produced, and paginates them when history is loaded.</p>"},{"location":"concepts/threads/#how-threads-are-created-and-updated","title":"How threads are created and updated","text":"<p>A typical thread lifecycle looks like this:</p> <ul> <li>Thread creation: When a user submits a message and no thread exists yet, ChatKitServer creates one and persists it by calling your store\u2019s <code>save_thread</code>.</li> <li>Appending items: As the server streams a response, ChatKit persists thread items automatically as each item completes. Streaming events directly drive what gets stored.</li> <li>Updating metadata: During respond, you can freely mutate the thread object (for example, to set or refine the title). ChatKit automatically persists these updates when the response completes. You can also call store.save_thread explicitly if needed.</li> <li>Loading history: When history is enabled client-side, ChatKit retrieves past threads and their items. Users can continue an existing thread by default.</li> <li>Closing or archiving: Threads can be marked read-only (for example, by disabling new messages) or deleted entirely if they should no longer be discoverable.</li> </ul>"},{"location":"concepts/threads/#how-thread-items-are-used","title":"How thread items are used","text":"<p>Thread items serve two primary purposes in ChatKit:</p>"},{"location":"concepts/threads/#model-input","title":"Model input","text":"<p>Your server's <code>respond</code> logic reads thread items to construct input for the model input. This ensures the model sees the full conversational context both during an active response and when a user resumes a past thread. </p> <p>See Respond to a user message for a full walkthrough.</p>"},{"location":"concepts/threads/#ui-rendering","title":"UI rendering","text":"<p>On the client, ChatKit.js renders items incrementally as they stream in for the active thread. When a past thread is loaded, the same persisted items are re-rendered to reconstruct the conversation UI.</p>"},{"location":"concepts/threads/#core-item-types","title":"Core item types","text":""},{"location":"concepts/threads/#user-messages","title":"User messages","text":"<p><code>UserMessageItem</code>s represent end-user input. They may include:</p> <ul> <li>Plain text entered by the user</li> <li>Optional <code>quoted_text</code> for reply-style UIs</li> <li>Attachment metadata</li> </ul> <p>User text is not Markdown-rendered, but it may contain @-mentions if your integration enables them.</p>"},{"location":"concepts/threads/#assistant-messages","title":"Assistant messages","text":"<p><code>AssistantMessageItem</code>s represent assistant output. Their content can include:</p> <ul> <li>Markdown-rendered text</li> <li>Tool call outputs</li> <li>Widgets and structured UI elements</li> <li>Inline annotations</li> </ul> <p>Assistant text supports rich Markdown and is rendered progressively as it streams.</p>"},{"location":"concepts/threads/#markdown-support","title":"Markdown support","text":"<p>Assistant messages support:</p> <ul> <li>GitHub-flavored Markdown (headings, lists, code blocks, links, blockquotes)</li> <li>Stable list rendering during streaming (Safari-safe, no reflow)</li> <li>Optional single-newline line breaks</li> <li>Syntax-highlighted, copyable code blocks</li> <li>LaTeX math (inline and block)</li> <li>Tables with automatic sizing and horizontal scrolling</li> <li>Inline annotations that create interactive affordances in the UI</li> </ul>"},{"location":"concepts/threads/#hidden-context-items","title":"Hidden context items","text":"<p>Hidden context items are included in model input but are not rendered in the chat UI. They allow the model to react to what happened in the interface, not just what the user typed.</p> <p>Typical use cases include recording widget actions, selection state, or system signals.</p> <ul> <li> <p><code>HiddenContextItem</code>: Integration-defined hidden context. You control its schema and how it is converted for the model.</p> </li> <li> <p><code>SDKHiddenContextItem</code>: Hidden context inserted by the ChatKit Python SDK for its own internal operations. Most applications do not need to modify this unless overriding conversion behavior.</p> </li> </ul>"},{"location":"concepts/threads/#thread-item-actions","title":"Thread item actions","text":"<p>Thread item actions are quick action buttons associated with an assistant turn. They let users act on the output\u2014such as retrying a response, copying content, or submitting feedback.</p> <p>Actions are configured client-side using the threadItemActions option.</p>"},{"location":"concepts/threads/#converting-items-to-model-input","title":"Converting items to model input","text":"<p><code>ThreadItemConverter</code> translates stored thread items into model-ready input items. The default converter understands common ChatKit item types such as messages, widgets, workflows, and tasks.</p> <p>You can override the converter when you need custom behavior. For example:</p> <ul> <li>Formatting attachments for the model</li> <li>Translating tags or mentions into structured input</li> <li>Summarizing rich widgets into text the model can consume</li> </ul> <p>Custom conversion is typically paired with prompting so the model receives a coherent representation of the conversation.</p>"},{"location":"concepts/threads/#related-guides","title":"Related guides","text":"<ul> <li>Respond to a user message</li> <li>Pass extra app context to your model</li> <li>Add annotations in assistant messages</li> <li>Accept rich user input</li> <li>Handle feedback</li> <li>Let users browse past threads</li> </ul>"},{"location":"concepts/tools/","title":"Tools","text":"<p>Tools let the assistant call into your application logic during a turn\u2014for example to search data, run a workflow, or fetch the user\u2019s current context\u2014then feed the results back into the model.</p> <p>At a high level:</p> <ul> <li>Server tools run on your backend. The assistant calls them through your inference pipeline, and you stream their results back into the conversation.</li> <li>Client tools run in the browser or host app. ChatKit surfaces a tool call as a streamed thread item, lets the client handle it, then resumes the conversation with the tool\u2019s output.</li> </ul>"},{"location":"concepts/tools/#server-tools","title":"Server tools","text":"<p>Server tools are ordinary Python functions you register with your inference setup (for example, as tools on an agent or as explicit steps in your pipeline). During inference, the model can decide to call them; ChatKit serializes the call, runs your function, and feeds the output back to the model.</p> <p>Use server tools to:</p> <ul> <li>Look up data in your own APIs or databases.</li> <li>Kick off long-running jobs while streaming progress updates.</li> <li>Update your own domain state (tickets, orders, files, etc.) in response to a turn.</li> </ul> <p>From the model\u2019s perspective, tools are structured, named capabilities it can invoke instead of guessing from free text.</p>"},{"location":"concepts/tools/#client-tools","title":"Client tools","text":"<p>Some operations can only run on the client\u2014for example:</p> <ul> <li>Reading the current selection in a canvas or document.</li> <li>Inspecting local application state that never leaves the browser.</li> <li>Calling into the host app (for example, a design tool or IDE) via its own APIs.</li> </ul> <p>Client tools let the model request that kind of data mid-turn:</p> <ul> <li>On the server, you instruct your inference pipeline to stop when a specific tool is called (for example, by using <code>StopAtTools</code> around that tool).</li> <li>ChatKit turns the tool call into a streamed thread item.</li> <li>On the client, <code>onClientTool</code> receives that item, runs your callback, and returns a JSON result.</li> <li>ChatKit sends the result back to the server, which starts a new stream to continue the run with the tool output included as model input.</li> </ul> <p>Use client tools when the model needs fresh, local context it cannot safely obtain from server-side state alone.</p>"},{"location":"concepts/widgets/","title":"Widgets","text":"<p>Widgets are structured UI elements the assistant can stream into the conversation. They let you render forms, cards, lists, or other interactive components instead of plain text.</p>"},{"location":"concepts/widgets/#representation-and-delivery","title":"Representation and delivery","text":"<p>Here\u2019s how a widget is represented from design time through runtime streaming.</p> Stage What it contains Working definition Widget UI language plus a schema (Zod/JSON) and example data you author in https://widgets.chatkit.studio. Published definition The exported <code>.widget</code> file bundling the layout, schema, and sample data. Server runtime (definition only) <code>WidgetTemplate</code> instance loaded from the <code>.widget</code> file. Server runtime (hydrated) <code>DynamicWidgetRoot</code> or <code>BasicRoot</code> Pydantic model instance built from the template and real data. Streamed to the client The hydrated root serialized to JSON and included inside a <code>WidgetItem</code> streamed by <code>ChatKitServer</code>. Rendered by the client ChatKit.js deserializes the JSON into typed widget objects (for example, <code>Card</code> or <code>ListView</code>) and renders them; entity previews use <code>BasicRoot</code> returned from <code>entities.onRequestPreview</code>. Sent as model input A Responses API <code>Message</code> produced from a <code>WidgetItem</code> via <code>ThreadItemConverter.widget_to_input</code>."},{"location":"concepts/widgets/#widget-ui-language","title":"Widget UI language","text":"<p>Widget layouts use a strict, simplified JSX dialect that only allows specific components and props. Explore the available components and their props in https://widgets.chatkit.studio/components to see what the renderer supports.</p>"},{"location":"concepts/widgets/#containers","title":"Containers","text":"<p>Every widget must be wrapped in a root-level container element. For single, self-contained content such as a summary, confirmation, or form, use <code>&lt;Card&gt;</code>. For a set of options (for example, restaurants or files), use <code>&lt;ListView&gt;</code>. Reserve <code>&lt;Basic&gt;</code> for entity previews.</p> <ul> <li><code>&lt;Card&gt;</code>: Simple card with a light border and plain background; supports confirm and cancel actions.</li> <li><code>&lt;ListView&gt;</code>: Scroll-friendly list with built-in \u201cshow more\u201d mechanics. Children must be <code>&lt;ListViewItem&gt;</code>, and <code>&lt;ListViewItem&gt;</code> must only appear as a direct child of <code>&lt;ListView&gt;</code>; it has a constrained prop set for row-like layout (<code>children</code>, <code>gap</code>, <code>align</code>, <code>onClickAction</code>).</li> <li><code>&lt;Basic&gt;</code>: Minimal container only used for entity previews.</li> </ul>"},{"location":"concepts/widgets/#widget-files","title":".widget files","text":"<p>Exported <code>.widget</code> files are JSON blobs that include the widget template, the expected data schema, and supporting metadata. You can load them server-side and render widgets dynamically with <code>WidgetTemplate</code>; see Build widgets with <code>WidgetTemplate</code> for examples.</p>"},{"location":"concepts/widgets/#widgetitem","title":"WidgetItem","text":"<p><code>WidgetItem</code> represents a widget rendered as a thread item in the chat UI. In addition to a reference to the widget instance, it contains a <code>copy_text</code> field that represents the text value copied to the clipboard when the user clicks the copy button below the response.</p>"},{"location":"concepts/widgets/#entity-previews","title":"Entity previews","text":"<p>The <code>entities.onRequestPreview</code> ChatKit option returns a preview typed as <code>BasicRoot</code>.</p>"},{"location":"concepts/widgets/#when-to-use","title":"When to use","text":"<ul> <li>Collect structured input (forms) or present rich results (tables, cards, charts) that text alone cannot convey.</li> <li>Present the user with multiple choice options.</li> <li>Pair with actions to let users submit selections, confirm steps, or trigger server-side work.</li> <li>Mix with text to provide explanation plus an interactive control.</li> </ul>"},{"location":"concepts/widgets/#related-guides","title":"Related guides","text":"<ul> <li>Build interactive responses with widgets</li> </ul>"},{"location":"guides/accept-rich-user-input/","title":"Accept rich user input","text":"<p>This guide explains how a ChatKit server accepts user input beyond plain text\u2014such as attachments and @-mentions\u2014and makes it available to your inference pipeline.</p> <p>At a high level:</p> <ul> <li>Attachments let users upload files that your model can read.</li> <li>@-mentions let users tag entities so the model does not have to guess from free text.</li> </ul>"},{"location":"guides/accept-rich-user-input/#attachments-let-users-upload-files","title":"Attachments: let users upload files","text":"<p>Let users attach files/images by turning on client support, choosing an upload strategy, wiring the upload endpoints, and converting attachments to model inputs.</p>"},{"location":"guides/accept-rich-user-input/#enable-attachments-in-the-client","title":"Enable attachments in the client","text":"<p>Turn on attachments in the composer and configure client-side limits:</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  composer: {\n    attachments: {\n      enabled: true,\n      // configure accepted MIME types, count, and size limits here\n    },\n  },\n});\n</code></pre> <p>Under the hood this maps to <code>ChatKitOptions.composer.attachments</code>; see the <code>composer.attachments</code> docs for all available options.</p>"},{"location":"guides/accept-rich-user-input/#configure-an-upload-strategy","title":"Configure an upload strategy","text":"<p>Set <code>ChatKitOptions.api.uploadStrategy</code> to:</p> <ul> <li>Direct: your backend exposes a single upload URL that accepts the bytes and writes attachment metadata to your <code>Store</code>. Simpler and faster when you control uploads directly from the app server.</li> <li>Two-phase: the client makes a ChatKit API request to create an attachment metadata record (which forwards the request to <code>AttachmentStore</code>), you return an <code>upload_url</code> as part of the created attachment metadata, and the client uploads bytes in a second step. Prefer this when you front object storage with presigned/temporary URLs or want to offload upload bandwidth (for example, to a third-party blob storage).</li> </ul> <p>Both strategies still require an <code>AttachmentStore</code> for delete cleanup. Choose direct for simplicity on the same origin; choose two-phase for cloud storage and larger files.</p>"},{"location":"guides/accept-rich-user-input/#enforce-attachment-access-control","title":"Enforce attachment access control","text":"<p>Neither attachment metadata nor file bytes are protected by ChatKit. Use the <code>context</code> passed into your <code>AttachmentStore</code> methods to authorize every create/read/delete. Only return IDs, bytes, or signed URLs when the caller owns the attachment, and prefer short-lived download URLs. Skipping these checks can leak customer data.</p>"},{"location":"guides/accept-rich-user-input/#direct-upload","title":"Direct upload","text":"<p>Add the upload endpoint referenced in <code>uploadStrategy</code>. It must:</p> <ul> <li>accept <code>multipart/form-data</code> with a <code>file</code> field,</li> <li>store the bytes wherever you like,</li> <li>create <code>Attachment</code> metadata, persist it via <code>Store.save_attachment</code>, and</li> <li>return the <code>Attachment</code> JSON.</li> </ul> <p>Implement <code>AttachmentStore.delete_attachment</code> to delete the stored bytes; <code>ChatKitServer</code> will then call <code>Store.delete_attachment</code> to drop metadata.</p> <p>Example client configuration:</p> <pre><code>{\n  type: \"direct\",\n  uploadUrl: \"/files\",\n}\n</code></pre> <p>Example FastAPI direct upload endpoint:</p> <pre><code>@app.post(\"/files\")\nasync def upload_file(request: Request):\n    form_data = await request.form()\n    file = form_data.get(\"file\")\n\n    # Your blob store upload\n    attachment = await upload_to_blob_store(file)\n\n    return Response(content=attachment.model_dump_json(), media_type=\"application/json\")\n</code></pre>"},{"location":"guides/accept-rich-user-input/#two-phase-upload","title":"Two-phase upload","text":"<p>Implement <code>AttachmentStore.create_attachment</code> to:</p> <ul> <li>build an <code>upload_url</code> that accepts <code>multipart/form-data</code> with a <code>file</code> field (direct PUTs are currently not supported),</li> <li>build the <code>Attachment</code> model,</li> <li>persist it via <code>Store.save_attachment</code>, and</li> <li>return it.</li> </ul> <p>Implement <code>AttachmentStore.delete_attachment</code> to delete the stored bytes; <code>ChatKitServer</code> will call <code>Store.delete_attachment</code> afterward.</p> <ul> <li>The client POSTs the bytes to <code>upload_url</code> after it receives the created attachment metadata in the response.</li> </ul> <p>Client configuration:</p> <pre><code>{\n  type: \"two_phase\",\n}\n</code></pre> <p>Example two-phase store issuing a multipart upload URL:</p> <pre><code>attachment_store = BlobAttachmentStore()\nserver = MyChatKitServer(store=data_store, attachment_store=attachment_store)\n\n\nclass BlobAttachmentStore(AttachmentStore[RequestContext]):\n    def generate_attachment_id(self, mime_type: str, context: RequestContext) -&gt; str:\n        return f\\\"att_{uuid4().hex}\\\"\n\n    async def create_attachment(\n        self, input: AttachmentCreateParams, context: RequestContext\n    ) -&gt; Attachment:\n        att_id = self.generate_attachment_id(input.mime_type, context)\n        upload_url = issue_multipart_upload_url(att_id, input.mime_type)  # your blob store\n        attachment = Attachment(\n            id=att_id,\n            mime_type=input.mime_type,\n            name=input.name,\n            upload_url=upload_url,\n        )\n        await data_store.save_attachment(attachment, context=context)\n        return attachment\n\n    async def delete_attachment(self, attachment_id: str, context: RequestContext) -&gt; None:\n        await delete_blob(att_id=attachment_id)  # your blob store\n</code></pre>"},{"location":"guides/accept-rich-user-input/#convert-attachments-to-model-input","title":"Convert attachments to model input","text":"<p>Attachments arrive on <code>input_user_message.attachments</code> in <code>ChatKitServer.respond</code>. The default <code>ThreadItemConverter</code> does not handle them, so subclass and implement <code>attachment_to_message_content</code> to return a <code>ResponseInputContentParam</code> before calling <code>Runner.run_streamed</code>.</p> <p>Example using a blob fetch helper:</p> <pre><code>from chatkit.agents import ThreadItemConverter\nfrom chatkit.types import ImageAttachment\nfrom openai.types.responses import ResponseInputFileParam, ResponseInputImageParam\n\n\nasync def read_bytes(attachment_id: str) -&gt; bytes:\n    ...  # fetch from your blob store\n\n\ndef as_data_url(mime: str, content: bytes) -&gt; str:\n    return \"data:\" + mime + \";base64,\" + base64.b64encode(content).decode(\"utf-8\")\n\n\nclass MyConverter(ThreadItemConverter):\n    async def attachment_to_message_content(self, attachment):\n        content = await read_bytes(attachment.id)\n        if isinstance(attachment, ImageAttachment):\n            return ResponseInputImageParam(\n                type=\"input_image\",\n                detail=\"auto\",\n                image_url=as_data_url(attachment.mime_type, content),\n            )\n        if attachment.mime_type == \"application/pdf\":\n            return ResponseInputFileParam(\n                type=\"input_file\",\n                file_data=as_data_url(attachment.mime_type, content),\n                filename=attachment.name or \"unknown\",\n            )\n        # For other text formats, check for API support first before\n        # sending as a ResponseInputFileParam.\n</code></pre>"},{"location":"guides/accept-rich-user-input/#show-image-attachment-previews-in-thread","title":"Show image attachment previews in thread","text":"<p>Set <code>ImageAttachment.preview_url</code> to allow the client to render thumbnails.</p> <ul> <li>If your preview URLs are permanent/public, set <code>preview_url</code> once when creating the attachment and persist it.</li> <li>If your storage uses expiring URLs, generate a fresh <code>preview_url</code> when returning attachment metadata (for example, in <code>Store.load_thread_items</code> and <code>Store.load_attachment</code>) rather than persisting a long-lived URL. In this case, returning a short-lived signed URL directly is the simplest approach. Alternatively, you may return a redirect that resolves to a temporary signed URL, as long as the final URL serves image bytes with appropriate CORS headers.</li> </ul>"},{"location":"guides/accept-rich-user-input/#dictation-speech-to-text-input","title":"Dictation: speech-to-text input","text":"<p>Enable dictation so users can record audio and have it transcribed into text before sending.</p>"},{"location":"guides/accept-rich-user-input/#enable-dictation-in-the-client","title":"Enable dictation in the client","text":"<p>Turn on dictation in the composer:</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  composer: {\n    dictation: {\n      enabled: true,\n    },\n  },\n});\n</code></pre> <p>This maps to <code>ChatKitOptions.composer.dictation</code>.</p>"},{"location":"guides/accept-rich-user-input/#implement-chatkitservertranscribe","title":"Implement <code>ChatKitServer.transcribe</code>","text":"<p>When dictation is enabled, the client records audio and sends it to your backend for transcription. Implement <code>ChatKitServer.transcribe</code> to accept audio input and return a transcription result.</p> <p>The client sends one of:</p> <ul> <li><code>\"audio/webm;codecs=opus\"</code> (preferred for Chrome/Firefox/Safari 18.4+)</li> <li><code>\"audio/mp4\"</code> (fallback for older Safari/iOS)</li> <li><code>\"audio/ogg;codecs=opus\"</code> (alternative for some environments)</li> </ul> <p>The raw value is available as <code>audio_input.mime_type</code>. Use <code>audio_input.media_type</code> when you only need the base media type (<code>\"audio/webm\"</code>, <code>\"audio/ogg\"</code>, or <code>\"audio/mp4\"</code>).</p> <p>Example transcription method using the OpenAI Audio API:</p> <pre><code>async def transcribe(self, audio_input: AudioInput, context: RequestContext) -&gt; TranscriptionResult:\n  ext = {\n      \"audio/webm\": \"webm\",\n      \"audio/mp4\": \"m4a\",\n      \"audio/ogg\": \"ogg\",\n  }.get(audio_input.media_type)\n  if not ext:\n      raise HTTPException(status_code=400, detail=\"Unexpected audio format\")\n\n  audio_file = io.BytesIO(audio_input.data)\n  audio_file.name = f\"audio.{ext}\"\n  transcription = client.audio.transcriptions.create(\n      model=\"gpt-4o-transcribe\",\n      file=audio_file\n  )\n  return TranscriptionResult(text=transcription.text)\n</code></pre> <p>Return a <code>TranscriptionResult</code> that includes the final <code>text</code> that should appear in the composer.</p>"},{"location":"guides/accept-rich-user-input/#-mentions-tag-entities-in-user-messages","title":"@-mentions: tag entities in user messages","text":"<p>Enable @-mentions so users can tag entities (like documents, tickets, or users) instead of pasting raw identifiers. Mentions travel through ChatKit as structured tags so the model can resolve entities instead of guessing from free text.</p>"},{"location":"guides/accept-rich-user-input/#enable-as-you-type-entity-lookup-in-the-composer","title":"Enable as-you-type entity lookup in the composer","text":"<p>To enable entity tagging as @-mentions in the composer, configure <code>entities.onTagSearch</code> as a ChatKit.js option.</p> <p>It should return a list of Entity objects that match the query string.</p> <p>If you want to hint that @-mentions are available, enable the composer <code>@</code> button by setting <code>entities.showComposerMenu</code>. When clicked, it inserts <code>@</code> into the composer and opens the tag search menu automatically.</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  entities: {\n    onTagSearch: async (query: string) =&gt; {\n      return [\n        {\n          id: \"article_123\",\n          title: \"The Future of AI\",\n          group: \"Trending\",\n          icon: \"globe\",\n          data: { type: \"article\" }\n        },\n        {\n          id: \"article_124\",\n          title: \"One weird trick to improve your sleep\",\n          group: \"Trending\",\n          icon: \"globe\",\n          data: { type: \"article\" }\n        },\n      ]\n    },\n    // Optional: show the \"@\" button in the composer for added discoverability.\n    showComposerMenu: true,\n  },\n})\n</code></pre>"},{"location":"guides/accept-rich-user-input/#convert-tags-into-model-input-in-your-server","title":"Convert tags into model input in your server","text":"<p>Mentions arrive server-side as structured tags. Override <code>ThreadItemConverter.tag_to_message_content</code> to describe what each tag refers to and translate it into model-readable content.</p> <p>Example converter method that wraps the tagged entity details in custom markup:</p> <pre><code>from chatkit.agents import ThreadItemConverter\nfrom chatkit.types import UserMessageTagContent\nfrom openai.types.responses import ResponseInputTextParam\n\n\nclass MyThreadItemConverter(ThreadItemConverter):\n    async def tag_to_message_content(\n        self, tag: UserMessageTagContent\n    ) -&gt; ResponseInputTextParam:\n        if tag.type == \"article\":\n            # Load or unpack the entity the tag refers to\n            summary = await fetch_article_summary(tag.id)\n            return ResponseInputTextParam(\n                type=\"input_text\",\n                text=(\n                    \"&lt;ARTICLE_TAG&gt;\\n\"\n                    f\"ID: {tag.id}\\n\"\n                    f\"Title: {tag.text}\\n\"\n                    f\"Summary: {summary}\\n\"\n                    \"&lt;/ARTICLE_TAG&gt;\"\n                ),\n            )\n</code></pre>"},{"location":"guides/accept-rich-user-input/#pair-mentions-with-retrieval-tool-calls","title":"Pair mentions with retrieval tool calls","text":"<p>When the referenced content is too large to inline, keep the tag lean (id + short summary) and let the model fetch details via a tool. In your system prompt, tell the assistant to call the retrieval tool when it sees an <code>ARTICLE_TAG</code>.</p> <p>Example tool paired with the converter above:</p> <pre><code>from agents import Agent, StopAtTools, RunContextWrapper, function_tool\nfrom chatkit.agents import AgentContext\n\n\n@function_tool(description_override=\"Fetch full article content by id.\")\nasync def fetch_article(ctx: RunContextWrapper[AgentContext], article_id: str):\n    article = await load_article_content(article_id)\n    return {\n        \"title\": article.title,\n        \"content\": article.body,\n        \"url\": article.url,\n    }\n\n\nassistant = Agent[AgentContext](\n    ...,\n    tools=[fetch_article],\n)\n</code></pre> <p>In <code>tag_to_message_content</code>, include the id the tool expects (for example, <code>tag.id</code> or <code>tag.data[\"article_id\"]</code>). The model can then decide to call <code>fetch_article</code> to pull the full text instead of relying solely on the brief summary in the tag.</p>"},{"location":"guides/accept-rich-user-input/#prompt-the-model-about-mentions","title":"Prompt the model about mentions","text":"<p>Add short system guidance to help the assistant understand the input item that adds details about the @-mention.</p> <p>For example:</p> <pre><code>- &lt;ARTICLE_TAG&gt;...&lt;/ARTICLE_TAG&gt; is a summary of an article the user referenced.\n- Use it as trusted context when answering questions about that article.\n- Do not restate the summary verbatim; answer the user\u2019s question concisely.\n- Call the `fetch_article` tool with the article id from the tag when more\n  detail is needed or the user asks for specifics not in the summary.\n</code></pre> <p>Combined with the converter above, the model receives explicit, disambiguated entity context while users keep a rich mention UI.</p>"},{"location":"guides/accept-rich-user-input/#handle-clicks-and-previews","title":"Handle clicks and previews","text":"<p>Clicks and hover previews apply to the tagged entities shown in past user messages. Mark an entity as interactive when you return it from <code>onTagSearch</code> so the client knows to wire these callbacks:</p> <pre><code>{\n  id: \"article_123\",\n  title: \"The Future of AI\",\n  group: \"Trending\",\n  icon: \"globe\",\n  interactive: true, // clickable/previewable\n  data: { type: \"article\" }\n}\n</code></pre> <ul> <li><code>entities.onClick</code> fires when a user clicks a tag in the transcript. Handle navigation or open a detail view. See the onClick option.</li> <li><code>entities.onRequestPreview</code> runs when the user hovers or taps a tag that has <code>interactive: true</code>. Return a <code>BasicRoot</code> widget; you can build one with <code>WidgetTemplate.build_basic(...)</code> if you are building the preview widgets server-side. See the onRequestPreview option.</li> </ul>"},{"location":"guides/add-annotations/","title":"Add annotations in assistant messages","text":"<p>ChatKit renders clickable inline citations when assistant text includes <code>annotations</code> and rolls every reference into a collapsed Sources list beneath each message. You can let the model emit annotations directly or attach sources yourself before streaming the message.</p>"},{"location":"guides/add-annotations/#use-model-emitted-citations","title":"Use model-emitted citations","text":"<p>When you stream a Responses run through <code>stream_agent_response</code>, ChatKit automatically converts any <code>file_citation</code>, <code>container_file_citation</code>, and <code>url_citation</code> annotations returned by the OpenAI API into ChatKit <code>Annotation</code> objects and attaches them to streamed message content.</p> <p>Provide the model with citable evidence via tools to receive citation annotations, most commonly:</p> <ul> <li><code>FileSearchTool</code> for uploaded documents (emits <code>file_citation</code> / <code>container_file_citation</code>)</li> <li><code>WebSearchTool</code> for live URLs (emits <code>url_citation</code>)</li> </ul> <p>No additional server-side wiring is required beyond calling <code>stream_agent_response</code>. If the model emits citation annotations from tool usage, ChatKit will forward them automatically as <code>Annotation</code> objects on the corresponding content parts.</p>"},{"location":"guides/add-annotations/#customize-how-citations-are-converted","title":"Customize how citations are converted","text":"<p>Sometimes the default rendering for model-emitted citations is not very helpful. For example, file citations may not include enough metadata for ChatKit to show a meaningful default title or description. You can pass a custom <code>ResponseStreamConverter</code> and override:</p> <ul> <li><code>file_citation_to_annotation</code></li> <li><code>container_file_citation_to_annotation</code></li> <li><code>url_citation_to_annotation</code></li> </ul> <p>Here is a minimal example that enriches file citations with a more helpful title/description using an internal mapping:</p> <pre><code>from chatkit.agents import ResponseStreamConverter, stream_agent_response\nfrom chatkit.types import Annotation, FileSource\n\n\nclass MyResponseStreamConverter(ResponseStreamConverter):\n    def __init__(self, file_lookup: dict[str, dict[str, str]]):\n        super().__init__()\n        self._file_lookup = file_lookup\n\n    async def file_citation_to_annotation(self, citation):\n        info = self._file_lookup.get(citation.file_id, {})\n        return Annotation(\n            source=FileSource(\n                filename=info.get(\"filename\", citation.file_id),\n                title=info.get(\"title\"),\n                description=info.get(\"description\"),\n            ),\n            index=citation.index,\n        )\n\n\nconverter = MyResponseStreamConverter(\n    file_lookup={\n        \"file_123\": {\n            \"filename\": \"q1_report.pdf\",\n            \"title\": \"Q1 Report\",\n            \"description\": \"Quarterly performance summary\",\n        }\n    }\n)\n\nstream_agent_response(..., converter=converter)\n</code></pre> <p>You can also return an <code>EntitySource</code> instead of a <code>FileSource</code> to control the inline label, handle clicks, and customize the popover preview. For more on entity annotations (including <code>interactive</code> click/preview hooks), see Annotating with custom entities below.</p>"},{"location":"guides/add-annotations/#attach-sources-manually","title":"Attach sources manually","text":"<p>If you build assistant messages yourself, include annotations on each <code>AssistantMessageContent</code> item.</p> <pre><code>from datetime import datetime\nfrom chatkit.types import (\n    Annotation,\n    AssistantMessageContent,\n    AssistantMessageItem,\n    FileSource,\n    ThreadItemDoneEvent,\n    URLSource,\n)\n\ntext = \"Quarterly revenue grew 12% year over year.\"\nannotations = [\n    Annotation(\n        source=FileSource(filename=\"q1_report.pdf\", title=\"Q1 Report\"),\n        index=len(text) - 1,  # attach near the end of the sentence\n    ),\n    Annotation(\n        source=URLSource(\n            url=\"https://example.com/press-release\",\n            title=\"Press release\",\n        ),\n        index=len(text) - 1,\n    ),\n]\n\nyield ThreadItemDoneEvent(\n    item=AssistantMessageItem(\n        id=self.store.generate_item_id(\"message\", thread, context),\n        thread_id=thread.id,\n        created_at=datetime.now(),\n        content=[AssistantMessageContent(text=text, annotations=annotations)],\n    )\n)\n</code></pre> <p><code>index</code> is the character position to place the footnote marker; re-use the same index when multiple citations support the same claim so the footnote numbers stay grouped.</p>"},{"location":"guides/add-annotations/#annotating-with-custom-entities","title":"Annotating with custom entities","text":"<p>You can attach <code>EntitySource</code> items as annotations to show entity references inline in assistant text and in the Sources list below the message.</p> <p>Entity annotations support a few UI-focused fields:</p> <ul> <li><code>icon</code>: Controls the icon shown for the entity in the default inline/hover UI.</li> <li><code>label</code>: Customizes what's shown in the default entity hover header (when you are not rendering a custom preview).</li> <li><code>inline_label</code>: Shows a label inline instead of an icon.</li> <li><code>interactive=True</code>: Wires the annotation to client-side callbacks (<code>ChatKitOptions.entities.onClick</code> and <code>ChatKitOptions.entities.onRequestPreview</code>).</li> </ul> <pre><code>from datetime import datetime\nfrom chatkit.types import (\n    Annotation,\n    AssistantMessageContent,\n    AssistantMessageItem,\n    EntitySource,\n    ThreadItemDoneEvent,\n)\n\ntext = \"Here are the ACME account details for reference.\"\n\nannotations = [\n    Annotation(\n        source=EntitySource(\n            id=\"customer_123\",\n            title=\"ACME Corp\",\n            description=\"Enterprise plan \u00b7 500 seats\",\n            icon=\"suitcase\",\n            label=\"Customer\",\n            interactive=True,\n            # Free-form data object passed to your client-side entity callbacks\n            data={\"href\": \"https://crm.example.com/customers/123\"},\n        ),\n        # `index` controls where the inline marker is placed in the text.\n        index=text.index(\"ACME\") + len(\"ACME\"),\n    )\n]\n\nyield ThreadItemDoneEvent(\n    item=AssistantMessageItem(\n        id=self.store.generate_item_id(\"message\", thread, context),\n        thread_id=thread.id,\n        created_at=datetime.now(),\n        content=[\n            AssistantMessageContent(\n                text=text,\n                annotations=annotations,\n            )\n        ],\n    )\n)\n</code></pre> <p>Provide richer previews and navigation by handling <code>entities.onRequestPreview</code> and <code>entities.onClick</code> in ChatKit.js. These callbacks are only invoked for entity annotations with <code>interactive=True</code>; use the <code>data</code> payload to pass entity information and deep link into your app.</p>"},{"location":"guides/browse-past-threads/","title":"Let users browse past threads","text":"<p>Let users return to previous conversations, see readable titles in a history list, and decide which threads can be continued.</p>"},{"location":"guides/browse-past-threads/#enable-thread-history-in-the-client","title":"Enable thread history in the client","text":"<p>The ChatKit React hooks support a built-in history view that lists past threads. History is enabled by default, but you can configure it explicitly when you create your ChatKit controller:</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  history: {\n    enabled: true,\n    showDelete: true,\n    showRename: true,\n  },\n});\n</code></pre> <p>With <code>history.enabled: true</code>, ChatKit.js will:</p> <ul> <li>Fetch threads from your ChatKit server.</li> <li>Show them in a history list using <code>thread.title</code> when available.</li> <li>Let users click a past thread to load its items and continue the conversation.</li> <li>Let users delete and rename threads.</li> </ul> <p>Set <code>history.enabled: false</code> if you want a single-thread, stateless chat experience with no history UI.</p>"},{"location":"guides/browse-past-threads/#show-readable-titles-in-history","title":"Show readable titles in history","text":"<p>Threads start untitled. Give them short, descriptive titles so the history list is easy to scan.</p>"},{"location":"guides/browse-past-threads/#set-a-title-directly","title":"Set a title directly","text":"<p>Set <code>thread.title</code> on the server and persist it with your store:</p> <pre><code>from chatkit.server import ChatKitServer\n\n\nclass MyChatKitServer(ChatKitServer[RequestContext]):\n    async def respond(...):\n        ...\n        if not thread.title:\n            thread.title = \"Order #1234\"\n            await self.store.save_thread(thread, context=context)\n</code></pre> <p>ChatKit will emit a <code>ThreadUpdatedEvent</code> so connected clients update the title in their history views.</p>"},{"location":"guides/browse-past-threads/#auto-generate-a-title-after-the-first-turn","title":"Auto-generate a title after the first turn","text":"<p>Generate a concise title after the first assistant turn once you have enough context. Skip if the thread already has a title or if there isn\u2019t enough content to summarize.</p> <pre><code>class MyChatKitServer(ChatKitServer[RequestContext]):\n    async def respond(...):\n        updating_thread_title = asyncio.create_task(\n            self._maybe_update_thread_title(thread, context)\n        )\n\n        # Stream your main response\n        async for event in stream_agent_response(agent_context, result):\n            yield event\n\n        # Await so the title update streams back as a ThreadUpdatedEvent\n        await updating_thread_title\n\n    async def _maybe_update_thread_title(\n        self, thread: ThreadMetadata, context: RequestContext\n    ) -&gt; None:\n        if thread.title is not None:\n            return\n        items = await self.store.load_thread_items(\n            thread.id,\n            after=None,\n            limit=6,\n            order=\"desc\",\n            context=context,\n        )\n        thread.title = await generate_short_title(items.data)  # your model call\n        await self.store.save_thread(thread, context=context)\n</code></pre> <p>Use any model call you like for <code>generate_short_title</code>: run a tiny Agent, a simple completion, or your own heuristic. Keep titles brief (for example, 3\u20136 words).</p>"},{"location":"guides/browse-past-threads/#decide-which-threads-can-be-continued","title":"Decide which threads can be continued","text":"<p>By default, users can continue any past thread: selecting it in the history view loads its items and reuses the same thread when they send a new message.</p> <p>Use <code>thread.status</code> to mark conversations that should no longer accept new messages. Locked and closed threads still appear in history, but the composer UI changes.</p> <p>There are two ways to stop new user messages: temporarily lock a thread or permanently close it when the conversation is finished.</p> State When to use Input UI What the user sees Locked Temporary pause for moderation or admin action Composer stays on screen but is disabled; the placeholder shows the lock reason. The reason for the lock in the disabled composer. Closed Final state when the conversation is done The input UI is replaced with an informational banner. A static default message or a custom reason, if provided."},{"location":"guides/browse-past-threads/#update-thread-status-lock-close-or-re-open","title":"Update thread status (lock, close, or re-open)","text":"<pre><code>from chatkit.types import ActiveStatus, LockedStatus, ClosedStatus\n\n# lock (temporary pause)\nthread.status = LockedStatus(reason=\"Escalated to support.\")\nawait store.save_thread(thread, context=context)\n\n# close (final state)\nthread.status = ClosedStatus(reason=\"Resolved.\")\nawait store.save_thread(thread, context=context)\n\n# re-open\nthread.status = ActiveStatus()\nawait store.save_thread(thread, context=context)\n</code></pre> <p>When you persist a new status during <code>respond</code>, ChatKit emits a <code>ThreadUpdatedEvent</code> so all viewers see the updated state.</p> <p>You can also update the thread status from a custom client-facing endpoint that updates the store directly (outside of the ChatKit server request flow). If the user is currently viewing the thread, have the client call <code>chatkit.fetchUpdates()</code> after the status is persisted so the UI picks up the latest thread state.</p>"},{"location":"guides/browse-past-threads/#block-server-side-work-when-locked-or-closed","title":"Block server-side work when locked or closed","text":"<p>Thread status only affects the composer UI; <code>ChatKitServer</code> does not automatically reject actions, tool calls, or imperative message adds. Your integration should short-circuit handlers when a thread is disabled:</p> <pre><code>class MyChatKitServer(...):\n    async def respond(thread, input_user_message, context):\n        if thread.status.type in {\"locked\", \"closed\"}:\n            return\n        # normal processing\n\n    async def action(thread, action, sender, context):\n        if thread.status.type in {\"locked\", \"closed\"}:\n            return\n        # normal processing\n</code></pre>"},{"location":"guides/build-interactive-responses-with-widgets/","title":"Build interactive responses with widgets","text":"<p>Use widgets to turn assistant responses into rich, interactive UIs. Design widgets visually, hydrate them with data on the server, stream them into the conversation, and wire actions and forms so users can click, edit, and submit without writing long free-text prompts.</p> <p>This guide covers:</p> <ul> <li>Designing and loading widget templates</li> <li>Streaming widgets from <code>respond</code> and from tools</li> <li>Handling widget actions on the server and client</li> <li>Building editable forms with widgets</li> </ul>"},{"location":"guides/build-interactive-responses-with-widgets/#design-widgets-in-chatkit-studio","title":"Design widgets in ChatKit Studio","text":"<p>Use https://widgets.chatkit.studio to visually design cards, lists, forms, charts, and other widget components. Populate the Data panel with sample values to preview how the widget renders with real inputs.</p> <p>When the layout and bindings look correct, click Export to download the generated <code>.widget</code> file. Commit this file alongside the server code that builds and renders the widget.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#build-widgets-with-widgettemplate","title":"Build widgets with <code>WidgetTemplate</code>","text":"<p>Load the <code>.widget</code> file with <code>WidgetTemplate.from_file</code> and hydrate it with runtime data. Placeholders inside the <code>.widget</code> template (Jinja-style <code>{{ }}</code> expressions) are rendered before the widget is streamed.</p> <pre><code>from chatkit.widgets import WidgetTemplate\n\nmessage_template = WidgetTemplate.from_file(\"widgets/channel_message.widget\")\n\n\ndef build_message_widget(user_name: str, message: str):\n    # Replace this helper with whatever your integration uses to build widgets.\n    return message_template.build(\n        {\n            \"user_name\": user_name,\n            \"message\": message,\n        }\n    )\n</code></pre> <p><code>WidgetTemplate.build</code> accepts plain dicts or Pydantic models. Use <code>.build_basic</code> if you're working with a <code>BasicRoot</code> widget outside of streaming.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#stream-widgets-from-respond","title":"Stream widgets from <code>respond</code>","text":"<p>Use <code>stream_widget</code> to emit a one-off widget or stream updates from an async generator.</p> <pre><code>from chatkit.server import stream_widget\n\n\nasync def respond(...):\n    user_name = \"Harry Potter\"\n    message = \"Yer a wizard, Harry\"\n    message_widget = build_message_widget(user_name=user_name, message=message)\n    async for event in stream_widget(\n        thread,\n        message_widget,\n        copy_text=f\"Message to {user_name}: {message}\",\n        generate_id=lambda item_type: self.store.generate_item_id(\n            item_type, thread, context\n        ),\n    ):\n        yield event\n</code></pre> <p>To stream gradual updates, yield successive widget states from an async generator; <code>stream_widget</code> diffs and emits <code>ThreadItemUpdatedEvent</code>s for you.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#stream-widgets-from-tools","title":"Stream widgets from tools","text":"<p>Tools can enqueue widgets via <code>AgentContext.stream_widget</code>; <code>stream_agent_response</code> forwards them to the client.</p> <pre><code>from agents import RunContextWrapper, function_tool\nfrom chatkit.agents import AgentContext\n\n\n@function_tool(description_override=\"Display a sample widget to the user.\")\nasync def sample_widget(ctx: RunContextWrapper[AgentContext]):\n    message_widget = build_message_widget(...)\n    await ctx.context.stream_widget(message_widget)\n</code></pre>"},{"location":"guides/build-interactive-responses-with-widgets/#stream-widget-updates-while-text-streams","title":"Stream widget updates while text streams","text":"<p>The examples above return a fully completed static widget. You can also stream an updating widget by yielding new versions of the widget from a generator function. The ChatKit framework will send updates for the parts of the widget that have changed.</p> <p>!!! note \"Text streaming support\"     Currently, only <code>&lt;Text&gt;</code> and <code>&lt;Markdown&gt;</code> components marked with an <code>id</code> have their text updates streamed. Other diffs will forgo the streaming UI and replace and rerender parts of the widget client-side.</p> <pre><code>from typing import AsyncGenerator\n\nfrom agents import RunContextWrapper, function_tool\nfrom chatkit.agents import AgentContext, Runner\nfrom chatkit.widgets import WidgetRoot\n\n\n@function_tool\nasync def draft_message_to_harry(ctx: RunContextWrapper[AgentContext]):\n    # message_generator is your model/tool function that streams text\n    message_result = Runner.run_streamed(\n        message_generator, \"Draft a message to Harry.\"\n    )\n\n    async def widget_generator() -&gt; AsyncGenerator[WidgetRoot, None]:\n        message = \"\"\n        async for event in message_result.stream_events():\n            if (\n                event.type == \"raw_response_event\"\n                and event.data.type == \"response.output_text.delta\"\n            ):\n                message += event.data.delta\n                yield build_message_widget(\n                    user_name=\"Harry Potter\",\n                    message=message,\n                )\n\n        # Final render after streaming completes.\n        yield build_message_widget(\n            user_name=\"Harry Potter\",\n            message=message,\n        )\n\n    await ctx.context.stream_widget(widget_generator())\n</code></pre> <p>The inner generator collects the streamed text events and rebuilds the widget with the latest message so the UI updates incrementally.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#handle-widget-actions","title":"Handle widget actions","text":"<p>Actions let widget interactions trigger server or client logic without posting a chat message.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#define-actions-in-your-widget","title":"Define actions in your widget","text":"<p>Configure actions as part of the widget definition while you design it in https://widgets.chatkit.studio. Add an action to any action-capable component such as <code>Button.onClickAction</code>; explore supported components on the components page.</p> <pre><code>&lt;Button\n  label=\"Send message\"\n  onClickAction={{\n    type: \"send_message\",\n    payload: { text: \"Ping support\" },\n  }}\n/&gt;\n</code></pre>"},{"location":"guides/build-interactive-responses-with-widgets/#choose-client-vs-server-handling","title":"Choose client vs server handling","text":"<p>Actions are handled on the server by default and flow into <code>ChatKitServer.action</code>. Set <code>handler: \"client\"</code> in the action to route it to your frontend\u2019s <code>widgets.onAction</code> instead. Use the server when you need to update thread state or stream widgets; use the client for immediate UI work or to chain into a follow-up <code>sendCustomAction</code> after local logic completes.</p> <p>Example widget definition with a client action handler:</p> <pre><code>&lt;Button\n  label=\"Send message\"\n  onClickAction={{\n    type: \"send_message\",\n    handler: \"client\",\n    payload: { text: \"Ping support\" },\n  }}\n/&gt;\n</code></pre>"},{"location":"guides/build-interactive-responses-with-widgets/#handle-actions-on-the-server","title":"Handle actions on the server","text":"<p>Implement <code>ChatKitServer.action</code> to process incoming actions. The <code>sender</code> argument is the widget item that triggered the action (if available).</p> <pre><code>from datetime import datetime\n\nfrom chatkit.server import ChatKitServer, stream_widget\nfrom chatkit.types import HiddenContextItem, WidgetItem\n\n\nclass MyChatKitServer(ChatKitServer[RequestContext]):\n    async def action(self, thread, action, sender, context):\n        if action.type == \"send_message\":\n            await send_to_chat(action.payload[\"text\"])\n\n            # Record the user action so the model can see it on the next turn.\n            hidden = HiddenContextItem(\n                id=\"generated-item-id\",\n                thread_id=thread.id,\n                created_at=datetime.now(),\n                content=f\"User sent message: {action.payload['text']}\",\n            )\n            # HiddenContextItems need to be manually saved because ChatKitServer\n            # only auto-saves streamed items, and HiddenContextItem should never be streamed to the client.\n            await self.store.add_thread_item(thread.id, hidden, context)\n\n            # Stream an updated widget back to the client.\n            updated_widget = build_message_widget(text=action.payload[\"text\"])\n            async for event in stream_widget(\n                thread,\n                updated_widget,\n                generate_id=lambda item_type: self.store.generate_item_id(\n                    item_type, thread, context\n                ),\n            ):\n                yield event\n</code></pre> <p>Treat action payloads as untrusted input from the client.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#handle-actions-on-the-client","title":"Handle actions on the client","text":"<p>Provide <code>widgets.onAction</code> when creating ChatKit on the client; you can still forward follow-up actions to the server from your <code>onAction</code> callback with the <code>sendCustomAction()</code> command if needed.</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  widgets: {\n    onAction: async (action, widgetItem) =&gt; {\n      if (action.type === \"save_profile\") {\n        const result = await saveProfile(action.payload);\n\n        // Optionally invoke a server action after client-side work completes.\n        await chatkit.sendCustomAction(\n          {\n            type: \"save_profile_complete\",\n            payload: {...result, user_id: action.payload.user_id},\n          },\n          widgetItem.id,\n        );\n      }\n    },\n  },\n});\n</code></pre> <p>On the server, handle the follow-up action (<code>save_profile_complete</code>) in the <code>action</code> method to stream refreshed widgets or messages.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#control-loading-behavior","title":"Control loading behavior","text":"<p>Use <code>loadingBehavior</code> to control how actions trigger different loading states in a widget.</p> <pre><code>&lt;Button\n  label=\"Send message\"\n  onClickAction={{\n    type: \"send_message\",\n    loadingBehavior: \"container\",\n  }}\n/&gt;\n</code></pre> Value Behavior <code>auto</code> The action will adapt to how it\u2019s being used. (default) <code>self</code> The action triggers loading state on the widget node that the action was bound to. <code>container</code> The action triggers loading state on the entire widget container. This causes the widget to fade out slightly and become inert. <code>none</code> No loading state <p>Generally, we recommend using <code>auto</code>, which is the default. <code>auto</code> triggers loading states based on where the action is bound, for example:</p> <ul> <li><code>Button.onClickAction</code> \u2192 <code>self</code></li> <li><code>Select.onChangeAction</code> \u2192 <code>none</code></li> <li><code>Card.confirm.action</code> \u2192 <code>container</code></li> </ul>"},{"location":"guides/build-interactive-responses-with-widgets/#create-custom-forms-with-widgets","title":"Create custom forms with widgets","text":"<p>Wrap widgets that collect user input in a <code>Form</code> to have their values automatically injected into every action triggered inside that form. The form values arrive in the action payload, keyed by each field\u2019s <code>name</code>.</p> <ul> <li><code>&lt;Select name=\"title\" /&gt;</code> \u2192 <code>action.payload[\"title\"]</code></li> <li><code>&lt;Select name=\"todo.title\" /&gt;</code> \u2192 <code>action.payload[\"todo\"][\"title\"]</code></li> </ul> <pre><code>&lt;Form\n  direction=\"col\"\n  onSubmitAction={{\n    type: \"update_todo\",\n    payload: { id: todo.id },\n  }}\n&gt;\n  &lt;Title value=\"Edit Todo\" /&gt;\n  &lt;Text value=\"Title\" color=\"secondary\" size=\"sm\" /&gt;\n  &lt;Text\n    value={todo.title}\n    editable={{ name: \"title\", required: true }}\n  /&gt;\n  &lt;Text value=\"Description\" color=\"secondary\" size=\"sm\" /&gt;\n  &lt;Text\n    value={todo.description}\n    editable={{ name: \"description\" }}\n  /&gt;\n  &lt;Button label=\"Save\" submit /&gt;\n&lt;/Form&gt;\n</code></pre> <p>On the server, read the form values from the action payload. Any action originating from inside the form will include the latest field values.</p> <pre><code>from collections.abc import AsyncIterator\n\nfrom chatkit.server import ChatKitServer\nfrom chatkit.types import Action, ThreadMetadata, ThreadStreamEvent, WidgetItem\n\n\nclass MyChatKitServer(ChatKitServer[RequestContext]):\n    async def action(\n        self,\n        thread: ThreadMetadata,\n        action: Action[str, Any],\n        sender: WidgetItem | None,\n        context: RequestContext,\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        if action.type == \"update_todo\":\n            todo_id = action.payload[\"id\"]\n            # Any action that originates from within the Form will\n            # include title and description\n            title = action.payload[\"title\"]\n            description = action.payload[\"description\"]\n\n            # ...\n</code></pre>"},{"location":"guides/build-interactive-responses-with-widgets/#validation","title":"Validation","text":"<p><code>Form</code> uses basic native form validation; it enforces <code>required</code> and <code>pattern</code> on configured fields and blocks submission when any field is invalid.</p> <p>We may add new validation modes with better UX, more expressive validation, and custom error display. Until then, widgets are not a great medium for complex forms with tricky validation. If you need this, a better pattern is to use client-side action handling to trigger a modal, show a custom form there, then pass the result back into ChatKit with <code>sendCustomAction</code>.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#treating-card-as-a-form","title":"Treating <code>Card</code> as a <code>Form</code>","text":"<p>You can pass <code>asForm=True</code> to <code>Card</code> and it will behave as a <code>Form</code>, running validation and passing collected fields to the Card\u2019s <code>confirm</code> action.</p>"},{"location":"guides/build-interactive-responses-with-widgets/#payload-key-collisions","title":"Payload key collisions","text":"<p>If there is a naming collision with some other existing pre-defined key on your payload, the form value will be ignored. This is probably a bug, so we\u2019ll emit an <code>error</code> event when we see this.</p>"},{"location":"guides/handle-feedback/","title":"Handle feedback","text":""},{"location":"guides/handle-feedback/#enable-feedback-actions-on-the-client","title":"Enable feedback actions on the client","text":"<p>Collect thumbs up/down feedback so you can flag broken answers, retrain on good ones, or alert humans. Enable the message actions in the client by setting <code>threadItemActions.feedback</code>; ChatKit.js renders the controls and sends an <code>items.feedback</code> request when a user clicks them.</p> <pre><code>const chatkit = useChatKit({\n    // ...\n    threadItemActions: {\n        feedback: true,\n    },\n})\n</code></pre>"},{"location":"guides/handle-feedback/#implement-add_feedback-on-your-server","title":"Implement <code>add_feedback</code> on your server","text":"<p>Override the <code>add_feedback</code> method on your server to persist the signal anywhere you like.</p> <pre><code>from chatkit.server import ChatKitServer\nfrom chatkit.types import FeedbackKind\n\nclass MyChatKitServer(ChatKitServer[RequestContext]):\n    async def add_feedback(\n        self,\n        thread_id: str,\n        item_ids: list[str],\n        feedback: FeedbackKind,\n        context: RequestContext,\n    ) -&gt; None:\n        # Example: write to your analytics/QA store\n        await record_feedback(\n            thread_id=thread_id,\n            item_ids=item_ids,\n            sentiment=feedback,\n            user_id=context.user_id,\n        )\n</code></pre> <p><code>item_ids</code> can include assistant messages, tool calls, or widgets. If you need to ignore certain items (for example, hidden system prompts), filter them here before recording.</p>"},{"location":"guides/keep-your-app-in-sync-with-chatkit/","title":"Keep your app in sync with ChatKit","text":"<p>Use ChatKit\u2019s client events to mirror runtime state into your host app so you can restore threads, gate your own UI, and safely call imperative helpers.</p> <p>At a high level:</p> <ul> <li>Track the active <code>threadId</code> so you can restore the same thread after navigation or reloads.</li> <li>Track loading and responding state to disable your own controls while ChatKit is busy.</li> </ul>"},{"location":"guides/keep-your-app-in-sync-with-chatkit/#track-the-active-thread","title":"Track the active thread","text":"<p>Use <code>onThreadChange</code> to mirror ChatKit\u2019s active thread into your own app state or router. Persist the <code>threadId</code> wherever you keep session state (for example, URL params, Redux, or local storage) so you can restore it later.</p>"},{"location":"guides/keep-your-app-in-sync-with-chatkit/#track-loading-and-responding-state","title":"Track loading and responding state","text":"<p>ChatKit exposes lifecycle events for thread loading and response streaming. Use them to:</p> <ul> <li>Disable custom toolbars, buttons, or navigation while a response is in flight.</li> <li>Avoid calling imperative helpers while ChatKit is already doing work.</li> </ul>"},{"location":"guides/keep-your-app-in-sync-with-chatkit/#wire-it-all-together-in-usechatkit","title":"Wire it all together in <code>useChatKit</code>","text":"<p>Here\u2019s a minimal React inbox that mirrors thread and loading state:</p> <pre><code>import {ChatKit, useChatKit} from \"@openai/chatkit-react\";\n\nexport function Inbox({clientToken}: { clientToken: string }) {\n  const {\n    control,\n    sendUserMessage,\n    focusComposer,\n    setThreadId,\n  } = useChatKit({\n    // ... your normal options (api, history, composer, etc.)\n\n    onThreadChange: ({threadId}) =&gt; setActiveThread(threadId),\n\n    onThreadLoadStart: () =&gt; setIsLoading(true),\n    onThreadLoadEnd: () =&gt; setIsLoading(false),\n\n    onResponseStart: () =&gt; setIsResponding(true),\n    onResponseEnd: () =&gt; setIsResponding(false),\n  });\n\n  const isBusy = isLoading || isResponding;\n\n  return (\n    &lt;&gt;\n      &lt;Toolbar\n        disabled={isBusy}\n        onNewThread={() =&gt; !isBusy &amp;&amp; setThreadId(undefined)}\n        onFocusComposer={() =&gt; !isBusy &amp;&amp; focusComposer()}\n        onSendQuickMessage={(text) =&gt;\n          !isBusy &amp;&amp; sendUserMessage({text})\n        }\n      /&gt;\n      &lt;ChatKit control={control} /&gt;\n    &lt;/&gt;\n  );\n}\n</code></pre>"},{"location":"guides/keep-your-app-in-sync-with-chatkit/#guard-imperative-helpers-when-chatkit-is-busy","title":"Guard imperative helpers when ChatKit is busy","text":"<p>Commands such as <code>sendUserMessage</code>, <code>focusComposer</code>, and <code>setThreadId</code> can reject if called during a thread load or while a response is streaming.</p> <p>Use your mirrored <code>isLoading</code> / <code>isResponding</code> state to:</p> <ul> <li>Avoid calling commands when ChatKit is busy (as in the example above).</li> <li>Disable your own buttons or menu items until ChatKit finishes.</li> <li>Show \u201cworking\u2026\u201d affordances that line up with the actual ChatKit lifecycle.</li> </ul>"},{"location":"guides/keep-your-app-in-sync-with-chatkit/#hook-in-your-own-ui-state","title":"Hook in your own UI state","text":"<p>Once you have <code>threadId</code>, <code>isLoading</code>, and <code>isResponding</code> mirrored into your app, use them to drive your own UI; for example, disabling controls while ChatKit is busy or restoring the last active thread after navigation or reloads.</p>"},{"location":"guides/let-users-pick-tools-and-models/","title":"Let users pick tools and models","text":"<p>This guide shows how to expose a tool menu and model picker in the composer UI, read the user\u2019s choices as inference options on the server, and fork your inference pipeline based on those choices.</p> <p>At a high level:</p> <ul> <li><code>composer.tools</code> controls which tools appear in the composer tool menu (the plus button).</li> <li><code>composer.models</code> controls which models appear in the model picker in the composer below the text input.</li> <li>The selected tool and model arrive as <code>inference_options</code> on the <code>UserMessageItem</code> in your <code>respond</code> method.</li> </ul>"},{"location":"guides/let-users-pick-tools-and-models/#configure-tools-in-the-composer","title":"Configure tools in the composer","text":"<p>Configure the tools that should appear in the composer tool menu when you initialize ChatKit on the client:</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  composer: {\n    tools: [\n      {\n        id: \"summarize\",\n        icon: \"book-open\",\n        label: \"Summarize\",\n        placeholderOverride: \"Summarize the current page or document.\",\n      },\n      {\n        id: \"search_tickets\",\n        icon: \"search\",\n        label: \"Search tickets\",\n        shortLabel: \"Search\",\n        placeholderOverride: \"Search support tickets for similar issues.\",\n      },\n    ],\n  },\n});\n</code></pre> <p>Each entry defines a user-facing label/shortLabel and a stable <code>id</code> you\u2019ll use on the server to decide how to handle the turn.</p>"},{"location":"guides/let-users-pick-tools-and-models/#configure-the-model-picker-in-the-composer","title":"Configure the model picker in the composer","text":"<p>Expose a small set of model choices so users can trade off speed vs quality.</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  composer: {\n    models: [\n      {\n        id: \"gpt-4.1-mini\",\n        label: \"Fast\",\n        description: \"Answers right away\",\n      },\n      {\n        id: \"gpt-4.1\",\n        label: \"Quality\",\n        description: \"All rounder\"\n        default: true,\n      },\n    ],\n  },\n});\n</code></pre> <p>The selected model id flows through to your server so you can route requests to the right underlying model or configuration.</p>"},{"location":"guides/let-users-pick-tools-and-models/#read-tool-and-model-choices-on-the-server","title":"Read tool and model choices on the server","text":"<p>On the server, <code>UserMessageItem.inference_options</code> carries the tool choice and model id for that turn.</p> <pre><code>from chatkit.types import InferenceOptions\n\n\nclass MyChatKitServer(ChatKitServer[RequestContext]):\n    async def respond(\n        self,\n        thread: ThreadMetadata,\n        input_user_message: UserMessageItem | None,\n        context: RequestContext,\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        options = input_user_message and input_user_message.inference_options\n\n        model = options.model if options and options.model else \"gpt-4.1-mini\"\n        tool_choice = options.tool_choice.id if options and options.tool_choice else None\n\n        # Use `model` and `tool_choice` when building your model request...\n</code></pre> <p>If the user doesn\u2019t pick anything explicit, <code>inference_options</code> may be <code>None</code> or have <code>model</code> / <code>tool_choice</code> unset; fall back to your defaults.</p>"},{"location":"guides/let-users-pick-tools-and-models/#fork-your-inference-pipeline-based-on-user-choices","title":"Fork your inference pipeline based on user choices","text":"<p>Use the tool and model choices to branch into different agents, prompts, or tools.</p>"},{"location":"guides/let-users-pick-tools-and-models/#route-to-different-tools-or-agents","title":"Route to different tools or agents","text":"<p>For example, use the composer\u2019s tool id to decide which agent (or tool set) to run:</p> <pre><code>if tool_choice == \"summarize\":\n    agent = summarization_agent\nelif tool_choice == \"search_tickets\":\n    agent = ticket_search_agent\nelse:\n    agent = default_agent\n\nresult = Runner.run_streamed(agent, input_items, context=agent_context)\n</code></pre> <p>You control which tools each agent exposes; the composer\u2019s tool menu just lets the user express intent up front instead of relying purely on model heuristics.</p>"},{"location":"guides/let-users-pick-tools-and-models/#choose-models-per-turn","title":"Choose models per turn","text":"<p>Use the selected model id to pick an underlying model or configuration when you call the OpenAI Responses API (or another provider):</p> <pre><code>model = inference.model if inference and inference.model else \"gpt-4.1-mini\"\n\nresponse = await client.responses.create(\n    model=model,\n    input=...,\n    # other options\n)\n</code></pre> <p>You can also use the model choice as a coarse \u201cmode\u201d flag\u2014for example, always enabling safer or more verbose prompting on certain models.</p>"},{"location":"guides/let-users-pick-tools-and-models/#combine-tools-and-models","title":"Combine tools and models","text":"<p>Nothing stops you from combining both choices. A common pattern is:</p> <ul> <li>Use the composer tool menu to decide what kind of work to do (summarization, search, drafting, etc.).</li> <li>Use the model picker to decide how heavy the model pass should be (fast vs quality, cheap vs expensive).</li> </ul> <p>This keeps the chat UI simple while still giving advanced users control over how their requests are handled end to end.</p>"},{"location":"guides/let-your-app-draft-and-send-messages/","title":"Let your app draft and send messages","text":"<p>Use ChatKit\u2019s commands to let your app pre-fill the composer and send messages programmatically for quick replies, \u201cask again\u201d buttons, or deep links from the rest of your UI.</p> <p>At a high level:</p> <ul> <li><code>setComposerValue</code> lets your app draft or edit the pending message.</li> <li><code>sendUserMessage</code> lets your app send a message without the user pressing Enter.</li> </ul>"},{"location":"guides/let-your-app-draft-and-send-messages/#get-chatkit-commands-from-usechatkit","title":"Get ChatKit commands from <code>useChatKit</code>","text":"<p>When you call <code>useChatKit</code>, you can destructure commands alongside the <code>control</code> object you pass into <code>&lt;ChatKit /&gt;</code>:</p> <pre><code>import {ChatKit, useChatKit} from \"@openai/chatkit-react\";\n\nexport function Inbox() {\n  const {\n    control,\n    setComposerValue,\n    sendUserMessage,\n    setThreadId,\n  } = useChatKit({\n    // ... your normal options (api, history, composer, etc.)\n  });\n\n  return &lt;ChatKit control={control} /&gt;;\n}\n</code></pre> <p>The commands are safe to call as long as ChatKit is not currently loading a thread or streaming a response; combine them with the loading/response state from Keep your app in sync with ChatKit when you need to guard calls.</p>"},{"location":"guides/let-your-app-draft-and-send-messages/#draft-messages-with-setcomposervalue","title":"Draft messages with <code>setComposerValue</code>","text":"<p>Use <code>setComposerValue</code> to pre-fill or update the composer text from your own UI:</p> <ul> <li>Quick-reply chips that insert a suggested reply.</li> <li>\u201cAsk again with more detail\u201d buttons that tweak the last question.</li> <li>Deep links from outside the chat that open a specific prompt.</li> </ul> <pre><code>function QuickReplies({\n  setComposerValue,\n}: {\n  setComposerValue: (params: {text: string}) =&gt; Promise&lt;void&gt;;\n}) {\n  return (\n    &lt;div className=\"quick-replies\"&gt;\n      &lt;button onClick={() =&gt; setComposerValue({text: \"Can you summarize this thread?\"})}&gt;\n        Summarize this thread\n      &lt;/button&gt;\n      &lt;button onClick={() =&gt; setComposerValue({text: \"Explain this like I'm five.\"})}&gt;\n        Explain like I'm five\n      &lt;/button&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre> <p><code>setComposerValue</code> only changes the draft text; the user can still edit it before sending, or you can pair it with <code>sendUserMessage</code> to fire immediately.</p>"},{"location":"guides/let-your-app-draft-and-send-messages/#send-messages-with-sendusermessage","title":"Send messages with <code>sendUserMessage</code>","text":"<p>Use <code>sendUserMessage</code> when your app needs to initiate a turn directly\u2014for example, from a custom toolbar button or a widget action handled on the client.</p> <pre><code>export function Inbox() {\n  const {\n    control,\n    sendUserMessage,\n    setThreadId,\n  } = useChatKit({\n    // ...\n  });\n\n  const handleHelpClick = () =&gt; {\n    // Send a canned message from a fresh thread\n    sendUserMessage({text: \"I need help with my billing.\", newThread: true});\n  };\n\n  return (\n    &lt;&gt;\n      &lt;button onClick={handleHelpClick}&gt;Contact support&lt;/button&gt;\n      &lt;ChatKit control={control} /&gt;\n    &lt;/&gt;\n  );\n}\n</code></pre> <p>You can also rely on the current active thread when calling <code>sendUserMessage</code> without <code>newThread: true</code>.</p>"},{"location":"guides/pass-extra-app-context-to-your-model/","title":"Pass extra app context to your model","text":"<p>Sometimes the model needs information that is not part of the thread: the current route, user plan, selected document, feature flags, or host-app state. This guide shows several patterns for passing that extra context into your inference pipeline.</p> <p>At a high level:</p> <ul> <li>Send app/user context from the client to your ChatKit server on every request.</li> <li>Fetch context on demand with tools (including client tools).</li> <li>Inject extra context as an additional model input item when you build the request.</li> </ul>"},{"location":"guides/pass-extra-app-context-to-your-model/#send-app-context-with-each-request","title":"Send app context with each request","text":""},{"location":"guides/pass-extra-app-context-to-your-model/#attach-headers-from-usechatkit","title":"Attach headers from <code>useChatKit</code>","text":"<p>Use a custom <code>fetch</code> (or equivalent) when configuring <code>useChatKit</code> to attach app/user context via headers to every request:</p> <pre><code>const chatkit = useChatKit({\n  api: {\n    // ...\n    fetch: (input, init) =&gt;\n      fetch(input, {\n        ...init,\n        headers: {\n          // Make sure to pipe through headers sent by ChatKit\n          ...(init?.headers || {}),\n          \"X-Org-Id\": currentOrgId,\n          \"X-Plan\": currentPlan,\n        },\n      }),\n  },\n});\n</code></pre> <p>On the server, read these headers before calling <code>ChatKitServer.process</code> and add them to your request context:</p> <pre><code>from dataclasses import dataclass\n\n\n@dataclass\nclass RequestContext:\n    user_id: str\n    org_id: str\n    plan: str\n</code></pre> <p>Use this context in your <code>respond</code> method, tools, and store methods to keep the model and your business logic aware of the current app state.</p>"},{"location":"guides/pass-extra-app-context-to-your-model/#fetch-context-on-demand-with-tools","title":"Fetch context on demand with tools","text":"<p>Sometimes you only need extra context for certain requests\u2014fetch it on demand with tools instead of sending it for every turn.</p>"},{"location":"guides/pass-extra-app-context-to-your-model/#server-tools-that-fetch-app-context","title":"Server tools that fetch app context","text":"<p>Define a server tool that looks up app state (for example, the user\u2019s current workspace or preferences) and returns a JSON payload to the model:</p> <pre><code>@function_tool(description_override=\"Fetch the user's workspace context.\")\nasync def get_workspace_context(ctx: RunContextWrapper[AgentContext]):\n    workspace = await load_workspace(ctx.context.request_context.org_id)\n    return {\n        \"workspace_id\": workspace.id,\n        \"features\": workspace.feature_flags,\n    }\n</code></pre> <p>Include this tool in your agent so the model can call it when it needs that information.</p>"},{"location":"guides/pass-extra-app-context-to-your-model/#client-tools-for-browserapp-only-state","title":"Client tools for browser/app-only state","text":"<p>When the context only exists on the client (selection, viewport, local app state), use a client tool:</p> <pre><code>@function_tool(description_override=\"Read the user's current canvas selection.\")\nasync def get_canvas_selection(ctx: RunContextWrapper[AgentContext]) -&gt; None:\n    ctx.context.client_tool_call = ClientToolCall(\n        name=\"get_canvas_selection\",\n        arguments={},\n    )\n</code></pre> <p>On the client, implement the callback:</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  onClientTool: async ({name, params}) =&gt; {\n    if (name === \"get_canvas_selection\") {\n      const selection = myCanvas.getSelection();\n      return {\n        nodes: selection.map((node) =&gt; {\n          name: node.name,\n          description: node.description,\n        }),\n      };\n    }\n  },\n});\n</code></pre> <p>ChatKit will send the client tool result back to the server and continue the run with that data included as model input.</p>"},{"location":"guides/pass-extra-app-context-to-your-model/#inject-extra-context-as-model-input-item","title":"Inject extra context as model input item","text":"<p>You can also inject context directly as an extra model input item when you build the request.</p>"},{"location":"guides/pass-extra-app-context-to-your-model/#add-a-dedicated-context-item","title":"Add a dedicated context item","text":"<p>Before running your agent, prepend a short, structured context item describing app/user state:</p> <pre><code>from openai.types.responses import ResponseInputTextParam\n\n\nextra_context = ResponseInputTextParam(\n    type=\"input_text\",\n    text=(\n        \"&lt;APP_CONTEXT&gt;\\n\"\n        f\"user_id: {context.user_id}\\n\"\n        f\"org_id: {context.org_id}\\n\"\n        f\"plan: {context.plan}\\n\"\n        \"&lt;/APP_CONTEXT&gt;\"\n    ),\n)\n\ninput_items = [extra_context, *input_items]\n</code></pre> <p>Pair this with a short system prompt telling the model how to interpret the <code>&lt;APP_CONTEXT&gt;</code> block.</p>"},{"location":"guides/pass-extra-app-context-to-your-model/#combine-ids-tools","title":"Combine ids + tools","text":"<p>A useful pattern is to combine a lightweight context item with a follow-up tool call:</p> <ol> <li>Add an input item that contains a stable id or handle:</li> </ol> <pre><code>extra_context = ResponseInputTextParam(\n    type=\"input_text\",\n    text=f\"&lt;WORKSPACE_REF id={workspace.id} /&gt;\",\n)\ninput_items = [extra_context, *input_items]\n</code></pre> <ol> <li>Provide a tool (server or client) that can fetch the full details when needed:</li> </ol> <pre><code>@function_tool(description_override=\"Fetch full workspace details.\")\nasync def fetch_workspace(ctx: RunContextWrapper[AgentContext], id: str):\n    workspace = await load_workspace(id)\n    return {\n        \"id\": workspace.id,\n        \"features\": workspace.feature_flags,\n        \"limits\": workspace.limits,\n    }\n</code></pre> <ol> <li> <p>In your prompt, tell the model:</p> </li> <li> <p>The <code>&lt;WORKSPACE_REF&gt;</code> tag carries the id it should use.</p> </li> <li>It should call <code>fetch_workspace</code> when it needs more detail instead of guessing.</li> </ol> <p>This keeps your model inputs compact while still giving the model a reliable way to pull detailed context on demand.</p>"},{"location":"guides/prepare-your-app-for-production/","title":"Prepare your app for production","text":"<p>This guide covers the operational work you should do before rolling out a ChatKit\u2011powered experience in production:</p> <ul> <li>Set up localization so prompts, system messages, and tool output match the user\u2019s locale.</li> <li>Configure monitoring and logging so you can debug issues and correlate ChatKit traffic with your backend traces.</li> <li>Review security and authentication for your ChatKit endpoint.</li> <li>Register and use domain keys to lock ChatKit down to your approved hostnames.</li> </ul> <p>Use it as a checklist alongside your own product\u2019s launch process.</p>"},{"location":"guides/prepare-your-app-for-production/#localize-prompts-ui-copy-and-tool-output","title":"Localize prompts, UI copy, and tool output","text":"<p>By the time you go live, you should have a clear story for which locales you support and how locale flows from the client into your backend and model prompts.</p> <p>ChatKit always picks a single active locale and:</p> <ul> <li>Uses the browser locale by default.</li> <li>Lets you override the locale on the client (for example, from your own locale picker) by passing the <code>locale</code> option when you initialize ChatKit.</li> </ul> <p>For every request to your ChatKit backend, the client sends an <code>Accept-Language</code> header with that single locale value. You can rely on this header to drive your own localization logic on the server.</p> <p>At a minimum:</p> <ul> <li>Decide which locales you support (for example <code>[\"en\", \"fr\", \"de\"]</code>) and what the default/fallback is.</li> <li>Localize tool output and error messages so the assistant\u2019s replies feel consistent with the rest of your product.</li> </ul> <p>For example, you might include locale in your per\u2011request context:</p> <pre><code>from dataclasses import dataclass\n\n\n@dataclass\nclass RequestContext:\n    user_id: str\n    locale: str\n</code></pre> <p>Then, when you build prompts or tool output, read <code>context.locale</code> and render language\u2011appropriate text using your localization system. For example, with <code>gettext</code>:</p> <pre><code>from pathlib import Path\nimport gettext\n\nfrom agents import RunContextWrapper, function_tool\nfrom chatkit.agents import AgentContext\n\n\nLOCALE_DIR = Path(__file__).with_suffix(\"\").parent / \"locales\"\n_translations: dict[str, gettext.NullTranslations] = {}\n\n\ndef get_translations(locale: str) -&gt; gettext.NullTranslations:\n    \"\"\"Return a gettext translation object for the given locale.\"\"\"\n    if locale not in _translations:\n        _translations[locale] = gettext.translation(\n            \"messages\",  # your .po/.mo domain\n            localedir=LOCALE_DIR,\n            languages=[locale],\n            fallback=True,\n        )\n    return _translations[locale]\n\n\n@function_tool()\nasync def load_document(\n    ctx: RunContextWrapper[AgentContext],\n    document_id: str,\n):\n    locale = ctx.context.request_context.locale\n    _ = get_translations(locale).gettext\n    await ctx.context.stream_progress(\n        icon=\"document\",\n        text=_(\"Loading document\u2026\"),\n    )\n    doc = await get_document_by_id(document_id)\n    if not doc:\n        raise ValueError(_(\"We couldn\u2019t find that document.\"))\n    return doc\n</code></pre> <p>When you call the model (for example via the OpenAI Responses API), include the user\u2019s locale either directly in the prompt or as part of a system message so the model responds in the right language.</p>"},{"location":"guides/prepare-your-app-for-production/#monitor-logs-and-errors","title":"Monitor logs and errors","text":"<p>You should be able to answer questions like \u201cwhat went wrong for this user at this time?\u201d and \u201care ChatKit requests healthy right now?\u201d before you roll out broadly.</p>"},{"location":"guides/prepare-your-app-for-production/#capture-client-logs","title":"Capture client logs","text":"<p>On the client side, subscribe to ChatKit\u2019s log and error events and forward them into your own telemetry system, tagged with:</p> <ul> <li>User identifier (or stable anonymous id).</li> <li>Session or request id.</li> <li>The current thread id.</li> </ul> <p>In React, use the <code>onLog</code> and <code>onError</code> options (mirroring the patterns in the ChatKit JS Monitor logs guide):</p> <pre><code>import { ChatKit, useChatKit } from \"@openai/chatkit-react\";\n\nexport function SupportChat({\n  clientToken,\n  userId,\n}: {\n  clientToken: string;\n  userId: string;\n}) {\n  const { control } = useChatKit({\n    api: { clientToken },\n    onLog: ({ name, data }) =&gt;\n      sendToTelemetry({\n        name,\n        // Avoid forwarding raw message text or tool arguments directly.\n        data: scrubSensitiveFields(data),\n        userId,\n      }),\n    onError: ({ error }) =&gt;\n      sendToTelemetry({\n        name: \"chatkit.error\",\n        error: scrubSensitiveFields(error),\n        userId,\n      }),\n  });\n\n  return &lt;ChatKit control={control} className=\"h-[600px]\" /&gt;;\n}\n</code></pre> <p>With the web component, listen for <code>chatkit.log</code> and <code>chatkit.error</code> events:</p> <pre><code>const chatkit = document.getElementById(\"my-chat\") as OpenAIChatKit;\n\nchatkit.addEventListener(\"chatkit.log\", ({ detail }) =&gt; {\n  sendToTelemetry({\n    name: detail.name,\n    data: scrubSensitiveFields(detail.data),\n    userId,\n  });\n});\n\nchatkit.addEventListener(\"chatkit.error\", (event) =&gt; {\n  sendToTelemetry({\n    name: \"chatkit.error\",\n    error: scrubSensitiveFields(event.detail.error),\n    userId,\n  });\n});\n</code></pre> <p>These events can include PII and message contents, so avoid blanket-forwarding entire payloads; instead, extract and forward only the fields you need (for example, error codes, item ids, thread ids, and high\u2011level event names) and/or scrub sensitive fields before sending them to your logging provider.</p> <p>Separately from your own telemetry, the ChatKit iframe sends its own outbound telemetry to OpenAI\u2011controlled endpoints (Datadog and <code>chatgpt.com</code>) for monitoring and debugging. These internal logs do not contain PII or message input/output content and are used only to monitor the health of the ChatKit experience.</p>"},{"location":"guides/prepare-your-app-for-production/#monitor-your-chatkit-endpoint","title":"Monitor your ChatKit endpoint","text":"<p>On the backend, you should still capture basic logs around your ChatKit endpoint so you can correlate client telemetry with server behavior:</p> <ul> <li>Incoming HTTP request (path, method, user id, thread id).</li> <li>Calls to <code>ChatKitServer.process</code> and your <code>Store</code> implementation.</li> <li>Outbound calls to OpenAI or other model providers.</li> <li>Any errors raised from tools or your own business logic.</li> </ul>"},{"location":"guides/prepare-your-app-for-production/#security-and-authentication","title":"Security and authentication","text":"<p>Production deployments should treat your ChatKit endpoint as a privileged backend:</p> <ul> <li>Authenticate every request to your <code>/chatkit</code> endpoint (for example, with your existing session cookies, bearer tokens, or signed JWTs).</li> <li>Authorize access to threads and attachments based on your own user and tenant model.</li> <li>Protect secrets such as OpenAI API keys and internal service credentials in environment variables or a secret manager\u2014never in source control.</li> <li>Validate inputs before calling tools or downstream systems.</li> </ul> <p>You should also be explicit about how you handle prompt injection:</p> <ul> <li>Treat all user text, attachments, and tool output as untrusted input.</li> <li>Avoid building any <code>role=\"system\"</code> model inputs from values that might come from the user (including fields like subject lines, titles, or descriptions).</li> <li>Keep system messages static or derived only from trusted configuration so users cannot silently change your instructions to the model.</li> </ul>"},{"location":"guides/prepare-your-app-for-production/#authenticate-your-chatkit-endpoint","title":"Authenticate your ChatKit endpoint","text":"<p>The Python SDK expects your own app to handle authentication; <code>ChatKitServer</code> works with whatever <code>RequestContext</code> you choose. A common pattern is to:</p> <ol> <li>Authenticate the incoming HTTP request using your web framework (session middleware, OAuth bearer tokens, etc.).</li> <li>Build a <code>RequestContext</code> that includes the authenticated user id, org/tenant, and any roles or scopes.</li> <li>Pass that context into <code>server.process</code>.</li> </ol> <p>For example:</p> <pre><code>from fastapi import Depends, FastAPI, HTTPException, Request, Response\nfrom fastapi.responses import StreamingResponse\n\nfrom chatkit.server import ChatKitServer, StreamingResult\n\n\ndef get_current_user(request: Request) -&gt; str:\n    # Replace this with your real auth: session cookies, JWTs, etc.\n    user_id = request.headers.get(\"x-user-id\")\n    if not user_id:\n        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n    return user_id\n\n\napp = FastAPI()\nstore = MyStore(...)\nserver = MyChatKitServer(store)\n\n\n@app.post(\"/chatkit\")\nasync def chatkit_endpoint(\n    request: Request,\n    user_id: str = Depends(get_current_user),\n):\n    context = RequestContext(user_id=user_id, locale=\"en\")\n    result = await server.process(await request.body(), context)\n    if isinstance(result, StreamingResult):\n        return StreamingResponse(result, media_type=\"text/event-stream\")\n    return Response(content=result.json, media_type=\"application/json\")\n</code></pre> <p>Inside your <code>Store</code> and tools, enforce per\u2011user or per\u2011tenant access by checking <code>context.user_id</code> (and any other identifiers you include) before returning or mutating data.</p>"},{"location":"guides/prepare-your-app-for-production/#handle-pii-and-data-retention","title":"Handle PII and data retention","text":"<p>Because ChatKit threads and items can contain user text, attachments, and tool output:</p> <ul> <li>Decide what you persist and for how long. Implement retention policies in your <code>Store</code> (for example, delete threads older than N days).</li> <li>Avoid storing unnecessary PII in thread metadata or tool return values.</li> <li>Encrypt data at rest using your database\u2019s built\u2011in features or application\u2011level encryption where needed.</li> </ul>"},{"location":"guides/prepare-your-app-for-production/#domain-keys","title":"Domain keys","text":"<p>Domain keys lock ChatKit down to the hostnames you control. When you embed ChatKit in a web app, the client and iframe can use a domain key to prove that the page is allowed to load ChatKit.</p> <ol> <li>Visit the OpenAI domain allowlist page at <code>https://platform.openai.com/settings/organization/security/domain-allowlist</code>.</li> <li>Register each hostname that will host your ChatKit UI (for example, <code>app.example.com</code>, <code>support.example.com</code>).</li> <li>Copy the generated domain key for each entry.</li> </ol> <p>Your client configuration should include that <code>domainKey</code> alongside the URL to your ChatKit Python backend.</p> <pre><code>const options = {\n  api: {\n    url: \"https://your-domain.com/api/chatkit\",\n    // Copy this value from the domain allowlist entry.\n    domainKey: \"your-domain-key\",\n  },\n};\n</code></pre> <p>The ChatKit iframe will make an outbound request to <code>https://api.openai.com</code> to verify the domain key on load. If the key is missing or invalid, ChatKit will refuse to load, preventing unauthorized hostnames from embedding your ChatKit experience.</p> <p>When you go live, make sure all of your production hostnames are registered in the domain allowlist.</p>"},{"location":"guides/respond-to-user-message/","title":"Respond to a user message","text":"<p>This guide covers how to implement and run a ChatKit server that responds to user messages, including thread loading, inference, event streaming, and persistence.</p>"},{"location":"guides/respond-to-user-message/#install-chatkit","title":"Install ChatKit","text":"<p>Install the SDK from PyPI:</p> <pre><code>pip install openai-chatkit\n</code></pre>"},{"location":"guides/respond-to-user-message/#build-and-run-your-chatkit-server","title":"Build and run your ChatKit server","text":"<p>Your ChatKit server does three main things:</p> <ol> <li>Accept HTTP requests from your client.</li> <li>Construct a request context (user id, auth, feature flags, etc.).</li> <li>Call <code>ChatKitServer.respond</code> to produce streamed events.</li> </ol>"},{"location":"guides/respond-to-user-message/#define-a-request-context","title":"Define a request context","text":"<p>First, define a small context object that will be created per request and passed through your server, store, and agents:</p> <pre><code>from dataclasses import dataclass\n\n\n@dataclass\nclass MyRequestContext:\n    user_id: str\n</code></pre>"},{"location":"guides/respond-to-user-message/#implement-your-chatkitserver","title":"Implement your <code>ChatKitServer</code>","text":"<p>Subclass <code>ChatKitServer</code> and implement <code>respond</code>. It runs once per user turn and should yield the events that make up your response. We'll keep this example simple for now and fill in history loading and model calls in later sections.</p> <pre><code>from collections.abc import AsyncIterator\nfrom datetime import datetime\n\nfrom chatkit.server import ChatKitServer\nfrom chatkit.types import (\n    AssistantMessageContent,\n    AssistantMessageItem,\n    ThreadItemDoneEvent,\n    ThreadMetadata,\n    ThreadStreamEvent,\n    UserMessageItem,\n)\n\n\nclass MyChatKitServer(ChatKitServer[MyRequestContext]):\n    async def respond(\n        self,\n        thread: ThreadMetadata,\n        input: UserMessageItem | None,\n        context: MyRequestContext,\n    ) -&gt; AsyncIterator[ThreadStreamEvent]:\n        # Replace this with your inference pipeline.\n        yield ThreadItemDoneEvent(\n            item=AssistantMessageItem(\n                thread_id=thread.id,\n                id=self.store.generate_item_id(\"message\", thread, context),\n                created_at=datetime.now(),\n                content=[AssistantMessageContent(text=\"Hi there!\")],\n            )\n        )\n</code></pre>"},{"location":"guides/respond-to-user-message/#wire-chatkit-to-your-web-framework","title":"Wire ChatKit to your web framework","text":"<p>Expose a single <code>/chatkit</code> endpoint that forwards requests to your <code>MyChatKitServer</code> instance. For example, with FastAPI:</p> <pre><code>from fastapi import FastAPI, Request, Response\nfrom fastapi.responses import StreamingResponse\n\nfrom chatkit.server import ChatKitServer, StreamingResult\n\napp = FastAPI()\nstore = MyPostgresStore(conn_info)\nserver = MyChatKitServer(store)\n\n\n@app.post(\"/chatkit\")\nasync def chatkit_endpoint(request: Request):\n    # Build a per-request context from the incoming HTTP request.\n    context = MyRequestContext(user_id=\"abc123\")\n\n    # Let ChatKit handle the request and return either a streaming or JSON result.\n    result = await server.process(await request.body(), context)\n    if isinstance(result, StreamingResult):\n        return StreamingResponse(result, media_type=\"text/event-stream\")\n    return Response(content=result.json, media_type=\"application/json\")\n</code></pre>"},{"location":"guides/respond-to-user-message/#how-request-context-flows-into-chatkit","title":"How request context flows into ChatKit","text":"<p><code>ChatKitServer[TContext]</code> and <code>Store[TContext]</code> are generic over a request context type you choose (user id, org, auth scopes, feature flags). Construct it per request and pass it to <code>server.process</code>; it flows into <code>respond</code> and your store methods.</p> <pre><code>context = MyRequestContext(user_id=\"abc123\")\nresult = await server.process(await request.body(), context)\n</code></pre> <p>Request metadata in the payload is available before calling <code>process</code>; include it in your context for auth, tracing, or feature flags.</p>"},{"location":"guides/respond-to-user-message/#implement-your-chatkit-data-store","title":"Implement your ChatKit data store","text":"<p>Implement the <code>Store</code> interface to control how threads, messages, tool calls, and widgets are stored. Prefer serializing thread items as JSON so schema changes do not break storage. Example Postgres store:</p> <pre><code>class MyPostgresStore(Store[RequestContext]):\n    def __init__(self, conninfo: str) -&gt; None:\n        self._conninfo = conninfo\n        self._init_schema()\n\n    def _init_schema(self) -&gt; None:\n        with self._connection() as conn, conn.cursor() as cur:\n            cur.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS threads (\n                    id TEXT PRIMARY KEY,\n                    user_id TEXT NOT NULL,\n                    created_at TIMESTAMPTZ NOT NULL,\n                    data JSONB NOT NULL\n                );\n                \"\"\"\n            )\n\n            cur.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS items (\n                    id TEXT PRIMARY KEY,\n                    thread_id TEXT NOT NULL\n                        REFERENCES threads (id)\n                        ON DELETE CASCADE,\n                    user_id TEXT NOT NULL,\n                    created_at TIMESTAMPTZ NOT NULL,\n                    data JSONB NOT NULL\n                );\n                \"\"\"\n            )\n\n            conn.commit()\n\n    async def load_thread(\n        self, thread_id: str, context: RequestContext\n    ) -&gt; ThreadMetadata:\n        with self._connection() as conn, conn.cursor(row_factory=tuple_row) as cur:\n            cur.execute(\n                \"SELECT data FROM threads WHERE id = %s AND user_id = %s\",\n                (thread_id, context.user_id),\n            )\n            row = cur.fetchone()\n            if row is None:\n                raise NotFoundError(f\"Thread {thread_id} not found\")\n            return ThreadMetadata.model_validate(row[0])\n\n    async def save_thread(\n        self, thread: ThreadMetadata, context: RequestContext\n    ) -&gt; None:\n        payload = thread.model_dump(mode=\"json\")\n        with self._connection() as conn, conn.cursor() as cur:\n            cur.execute(\n                \"\"\"\n                INSERT INTO threads (id, user_id, created_at, data)\n                VALUES (%s, %s, %s, %s)\n                \"\"\",\n                (thread.id, context.user_id, thread.created_at, payload),\n            )\n            conn.commit()\n\n    # Implement the remaining Store methods following the same pattern.\n</code></pre> <p>Customize ID generation by overriding <code>generate_thread_id</code> and <code>generate_item_id</code> if you need external or deterministic IDs. Store metadata such as a model <code>last_response_id</code> on <code>ThreadMetadata</code> to drive your inference pipeline.</p>"},{"location":"guides/respond-to-user-message/#generate-a-response-using-your-model","title":"Generate a response using your model","text":"<p>Inside <code>respond</code>, you'll usually:</p> <ol> <li>Load recent thread history.</li> <li>Prepare model input for your agent.</li> <li>Run inference and stream events back to the client.</li> </ol>"},{"location":"guides/respond-to-user-message/#prepare-model-input","title":"Prepare model input","text":"<p>Before you call your model, decide what conversation context you want the model to see.</p>"},{"location":"guides/respond-to-user-message/#load-thread-history-recommended-default","title":"Load thread history (recommended default)","text":"<p>Fetch recent items so the model sees the conversation state before you build the next turn:</p> <pre><code>items_page = await self.store.load_thread_items(\n    thread.id,\n    after=None,\n    limit=20,  # Tune this limit based on your model/context budget.\n    order=\"desc\",\n    context=context,\n)\nitems = list(reversed(items_page.data))\n</code></pre> <ul> <li>Start with the defaults: <code>simple_to_agent_input(items)</code> is a convenience wrapper around the default <code>ThreadItemConverter</code> (it calls <code>ThreadItemConverter().to_agent_input(items)</code> under the hood).</li> <li>Customize for your integration: some item types require app-specific translation into model input (for example: attachments, tags, and some hidden context items). In those cases, subclass <code>ThreadItemConverter</code> and call your converter directly instead of <code>simple_to_agent_input</code>. (If your thread includes attachments/tags and you haven't implemented the converter hooks, conversion will raise <code>NotImplementedError</code>.)</li> </ul> <pre><code>from agents import Runner\n\nfrom chatkit.agents import AgentContext, ThreadItemConverter, simple_to_agent_input\n\n\n# Option A (defaults):\ninput_items = await simple_to_agent_input(items)\n\n# Option B (your integration-specific converter):\n# input_items = await MyThreadItemConverter().to_agent_input(items)\n\nagent_context = AgentContext(\n    thread=thread,\n    store=self.store,\n    request_context=context,\n)\n</code></pre> <p>Respect any <code>input.inference_options</code> the client sends (model, tool choice, etc.) when you build your request to the model.</p>"},{"location":"guides/respond-to-user-message/#using-previous_response_id-openai-responses-api-only","title":"Using <code>previous_response_id</code> (OpenAI Responses API only)","text":"<p>If you are using OpenAI models through the Responses API, you can pass <code>previous_response_id</code> to <code>Runner.run_streamed(...)</code> and (often) send only the new user message as model input. This can simplify input construction when the provider can retrieve prior context server-side.</p> <p>Terminology note: Agents exposes the ID of the most recent model response as <code>result.last_response_id</code>. On the next turn, you pass that saved value as the <code>previous_response_id</code> parameter.</p> <p>Important restrictions:</p> <ul> <li>OpenAI Responses API only. Other model providers won't be able to follow a <code>previous_response_id</code>, so you must send thread history yourself.</li> <li>Only includes model-visible history. If your integration streams ChatKit-only items (e.g. widgets/workflows emitted directly to the client), the model won't know about them unless you also include them in <code>input_items</code>.</li> <li>Works only while the referenced response is retrievable. Persist <code>result.last_response_id</code> and ensure responses are stored (<code>store=True</code> / <code>ModelSettings(store=True)</code>); otherwise fall back to rebuilding input from thread items.</li> </ul> <p>Example:</p> <pre><code># `ThreadMetadata.metadata` is a free-form dict for integration-specific state.\n# ChatKit does not define a first-class `last_response_id` field on `ThreadMetadata`;\n# your integration can store it under a key and reuse it on the next turn.\nlast_response_id = thread.metadata.get(\"last_response_id\")\nlast_response_id = last_response_id if isinstance(last_response_id, str) else None\n\n# Often: send only the new message as input when chaining on the server.\ninput_items = await simple_to_agent_input(input)\n\nresult = Runner.run_streamed(\n    assistant_agent,\n    input_items,\n    context=agent_context,\n    previous_response_id=last_response_id,\n    auto_previous_response_id=True,\n)\n\n# Persist the new response ID so the next turn can chain again.\nif result.last_response_id:\n    thread.metadata[\"last_response_id\"] = result.last_response_id\n    await self.store.save_thread(thread, context=context)\n</code></pre>"},{"location":"guides/respond-to-user-message/#run-inference-and-stream-events","title":"Run inference and stream events","text":"<p>Run your agent and stream events back to the client. <code>stream_agent_response</code> converts an Agents run into ChatKit events; you can also yield events manually.</p> <pre><code>from agents import (\n    InputGuardrailTripwireTriggered,\n    OutputGuardrailTripwireTriggered,\n    Runner,\n)\nfrom chatkit.agents import stream_agent_response\nfrom chatkit.types import ErrorEvent\n\nresult = Runner.run_streamed(\n    assistant_agent,\n    input_items,\n    context=agent_context,\n)\n\ntry:\n    async for event in stream_agent_response(agent_context, result):\n        yield event\nexcept InputGuardrailTripwireTriggered:\n    yield ErrorEvent(message=\"We blocked that message for safety.\")\nexcept OutputGuardrailTripwireTriggered:\n    yield ErrorEvent(\n        message=\"The assistant response was blocked.\",\n        allow_retry=False,\n    )\n</code></pre> <p>To stream events from a server tool during the same turn, use <code>ctx.context.stream(...)</code> inside the tool:</p> <pre><code>from agents import RunContextWrapper, function_tool\nfrom chatkit.agents import AgentContext\nfrom chatkit.types import ProgressUpdateEvent\n\n\n@function_tool()\nasync def load_document(ctx: RunContextWrapper[AgentContext], document_id: str):\n    await ctx.context.stream(ProgressUpdateEvent(icon=\"document\", text=\"Loading document...\"))\n    return await get_document_by_id(document_id)\n</code></pre> <p><code>stream_agent_response</code> will forward these events alongside any assistant text or tool call updates. Client tool calls are also supported via <code>ctx.context.client_tool_call</code> when you register the tool on both client and server.</p>"},{"location":"guides/respond-to-user-message/#next-add-features","title":"Next: add features","text":"<ul> <li>Let users browse past threads</li> <li>Accept rich user input</li> <li>Let users pick tools and models</li> <li>Pass extra app context to your model</li> <li>Update the client during a response</li> <li>Build interactive responses with widgets</li> <li>Add annotations in assistant messages</li> <li>Stream generated images</li> <li>Keep your app in sync with ChatKit</li> <li>Let your app draft and send messages</li> <li>Handle feedback</li> <li>Prepare your app for production</li> </ul>"},{"location":"guides/stream-generated-images/","title":"Stream generated images","text":"<p>Stream generated images to the client while your agent is running, and persist them in a storage-friendly format.</p> <p>This guide covers:</p> <ul> <li>Adding an image generation tool to your agent</li> <li>Converting streamed base64 images into URLs so your datastore does not store raw base64 strings</li> <li>Converting generated image thread items to model input for continued conversation</li> <li>Streaming partial images (progressive previews)</li> </ul>"},{"location":"guides/stream-generated-images/#add-an-image-generation-tool-to-your-agent","title":"Add an image generation tool to your agent","text":"<p>To let the model generate images, add the Agents SDK image generation tool to your agent's tool list.</p> <pre><code>from agents import Agent\nfrom agents.tool import ImageGenerationTool\n\n\nagent = Agent(\n    name=\"designer\",\n    instructions=\"Generate images when asked.\",\n    tools=[ImageGenerationTool(tool_config={\"type\": \"image_generation\"})],\n)\n</code></pre> <p>Once enabled, <code>stream_agent_response</code> will translate image generation output into ChatKit thread items:</p> <ul> <li>A <code>GeneratedImageItem</code> is added when an image generation call starts.</li> <li>It is updated (for partial images) and finalized when the result arrives.</li> </ul>"},{"location":"guides/stream-generated-images/#avoid-storing-raw-base64-in-your-datastore","title":"Avoid storing raw base64 in your datastore","text":"<p>By default, ChatKit stores generated images as a data URL (for example, <code>data:image/png;base64,...</code>) by using <code>ResponseStreamConverter.base64_image_to_url</code>.</p> <p>That's convenient for demos, but it can bloat your persisted thread items. In production, you'll usually want to:</p> <ul> <li>Write the bytes to object storage / a file store</li> <li>Persist only a URL (or a signed URL) on the <code>GeneratedImageItem</code></li> </ul>"},{"location":"guides/stream-generated-images/#override-responsestreamconverterbase64_image_to_url","title":"Override <code>ResponseStreamConverter.base64_image_to_url</code>","text":"<p>Subclass <code>ResponseStreamConverter</code> and override <code>base64_image_to_url</code>. This method is called for both:</p> <ul> <li>Final images</li> <li>Partial images (when <code>partial_images</code> streaming is enabled)</li> </ul> <pre><code>import base64\n\nfrom chatkit.agents import ResponseStreamConverter\n\n\nclass MyResponseStreamConverter(ResponseStreamConverter):\n    async def base64_image_to_url(\n        self,\n        image_id: str,\n        base64_image: str,\n        partial_image_index: int | None = None,\n    ) -&gt; str:\n        # `image_id` stays the same for the whole generation call (including partial updates).\n        # Use `partial_image_index` to derive distinct blob IDs for each partial image.\n        blob_id = (\n            image_id\n            if partial_image_index is None\n            else f\"{image_id}-partial-{partial_image_index}\"\n        )\n        # Replace `upload_blob(...)` with your app's storage call (S3, GCS, filesystem, etc).\n        # It should return a URL that your client can load later.\n        url = upload_blob(\n            blob_id,\n            base64.b64decode(base64_image),\n            \"image/png\",\n        )\n        return url\n</code></pre>"},{"location":"guides/stream-generated-images/#pass-your-converter-to-stream_agent_response","title":"Pass your converter to <code>stream_agent_response</code>","text":"<p>Create your converter and pass it into <code>stream_agent_response</code>. The returned URL will be what gets persisted on the <code>GeneratedImageItem</code>.</p> <pre><code>from agents import Runner\n\nfrom chatkit.agents import AgentContext, stream_agent_response\n\n\nasync def respond(...):\n    agent_context = AgentContext(\n        thread=thread,\n        store=self.store,\n        request_context=context,\n        previous_response_id=thread.previous_response_id,\n    )\n    result = Runner.run_streamed(agent, input_items, context=agent_context)\n\n    async for event in stream_agent_response(\n        agent_context,\n        result,\n        converter=MyResponseStreamConverter(),\n    ):\n        yield event\n</code></pre>"},{"location":"guides/stream-generated-images/#convert-generated-image-thread-items-to-model-input","title":"Convert generated image thread items to model input","text":"<p>On later turns, you'll often feed prior thread items (including generated images) back into the model as context.</p> <p>By default, <code>ThreadItemConverter.generated_image_to_input</code> sends the generated image back to the model as:</p> <ul> <li>A short text preface</li> <li>An <code>input_image</code> content part with <code>image_url=item.image.url</code></li> </ul> <p>If <code>item.image.url</code> is not publicly reachable by the model runtime (for example, it's a private intranet URL, or a localhost URL, or requires cookies), image understanding and image-to-image flows may fail.</p> <p>Two common fixes:</p> <ul> <li>Convert the stored image back into a base64 <code>data:</code> URL when building model input</li> <li>Generate a temporary public (signed) URL for the duration of the run</li> </ul>"},{"location":"guides/stream-generated-images/#override-threaditemconvertergenerated_image_to_input","title":"Override <code>ThreadItemConverter.generated_image_to_input</code>","text":"<p>Override <code>generated_image_to_input</code> and replace <code>image_url</code> with something the image API can fetch.</p> <pre><code>import base64\n\nfrom openai.types.responses import ResponseInputImageParam, ResponseInputTextParam\nfrom openai.types.responses.response_input_item_param import Message\n\nfrom chatkit.agents import ThreadItemConverter\nfrom chatkit.types import GeneratedImageItem\n\n\nclass MyThreadItemConverter(ThreadItemConverter):\n    async def generated_image_to_input(self, item: GeneratedImageItem):\n        if not item.image:\n            return None\n\n        # Option A: rehydrate to a data URL (works when you can fetch bytes yourself).\n        # Replace `download_blob(...)` with your app's storage call to fetch the image bytes.\n        image_bytes = download_blob(item.image.id)\n        b64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n        image_url = f\"data:image/png;base64,{b64}\"\n\n        # Option B: generate a temporary public URL instead:\n        # image_url = create_signed_url(item.image.id, expires_in_seconds=60)\n\n        return Message(\n            type=\"message\",\n            role=\"user\",\n            content=[\n                ResponseInputTextParam(\n                    type=\"input_text\",\n                    text=\"The following image was generated by the agent.\",\n                ),\n                ResponseInputImageParam(\n                    type=\"input_image\",\n                    detail=\"auto\",\n                    image_url=image_url,\n                ),\n            ],\n        )\n</code></pre> <p>When building your model input, use your custom converter instead of <code>simple_to_agent_input</code>:</p> <pre><code>input_items = await MyThreadItemConverter().to_agent_input(items)\n</code></pre>"},{"location":"guides/stream-generated-images/#stream-partial-images-progressive-previews","title":"Stream partial images (progressive previews)","text":"<p>You can stream partial images so users see progressive previews as the image is being generated.</p>"},{"location":"guides/stream-generated-images/#enable-partial-images-in-the-tool-config","title":"Enable partial images in the tool config","text":"<p>Set <code>partial_images</code> in the tool config:</p> <pre><code>from agents.tool import ImageGenerationTool\n\nimage_tool = ImageGenerationTool(\n    tool_config={\"type\": \"image_generation\", \"partial_images\": 3},\n)\n</code></pre>"},{"location":"guides/stream-generated-images/#show-progress-for-partial-images","title":"Show progress for partial images","text":"<p>Pass the same <code>partial_images</code> value to <code>ResponseStreamConverter</code> (or your subclass). ChatKit uses it to compute a <code>progress</code> value (between 0 and 1) for each partial image update.</p> <pre><code>async for event in stream_agent_response(\n    agent_context,\n    result,\n    converter=MyResponseStreamConverter(partial_images=3),\n):\n    yield event\n</code></pre> <p>During the run, ChatKit will emit:</p> <ul> <li><code>ThreadItemAddedEvent</code> for the initial <code>GeneratedImageItem</code></li> <li><code>ThreadItemUpdatedEvent</code> with <code>GeneratedImageUpdated(image=..., progress=...)</code> for each partial image</li> <li><code>ThreadItemDoneEvent</code> when the final image arrives</li> </ul>"},{"location":"guides/update-client-during-response/","title":"Update the client during a response","text":"<p>Keep your UI responsive while the server is working: stream progress text, trigger client-side effects, and run client tools mid-response without blocking everything else.</p> <p>This guide covers three patterns:</p> <ul> <li>Progress updates for lightweight status while tools run</li> <li>Client effects for fire-and-forget UI behavior</li> <li>Client tools for round-trips to the browser/app during inference</li> </ul>"},{"location":"guides/update-client-during-response/#show-progress-while-tools-run","title":"Show progress while tools run","text":"<p>Use <code>ProgressUpdateEvent</code> when you need lightweight, real-time status. These updates stream immediately to the client and disappear after the turn\u2014they are not stored in the thread.</p>"},{"location":"guides/update-client-during-response/#from-tools","title":"From tools","text":"<p>Inside a tool, use <code>AgentContext.stream</code> to enqueue progress events. They are delivered to the client immediately and are not persisted as thread items.</p> <pre><code>from agents import RunContextWrapper, function_tool\nfrom chatkit.agents import AgentContext\nfrom chatkit.types import ProgressUpdateEvent\n\n\n@function_tool()\nasync def ingest_files(ctx: RunContextWrapper[AgentContext], paths: list[str]):\n    await ctx.context.stream(ProgressUpdateEvent(icon=\"upload\", text=\"Uploading...\"))\n    await upload(paths)\n\n    await ctx.context.stream(\n        ProgressUpdateEvent(icon=\"search\", text=\"Indexing and chunking...\")\n    )\n    await index_files(paths)\n\n    await ctx.context.stream(ProgressUpdateEvent(icon=\"check\", text=\"Done\"))\n</code></pre> <p><code>stream_agent_response</code> will forward these events for you alongside any assistant text or tool call updates.</p>"},{"location":"guides/update-client-during-response/#from-custom-pipelines","title":"From custom pipelines","text":"<p>If you are not using the Agents SDK, yield <code>ProgressUpdateEvent</code> directly from your <code>respond</code> or <code>action</code> methods while your backend works:</p> <pre><code>async def respond(...):\n    yield ProgressUpdateEvent(icon=\"search\", text=\"Searching tickets...\")\n    results = await search_tickets()\n\n    yield ProgressUpdateEvent(icon=\"code\", text=\"Generating summary...\")\n    yield from await stream_summary(results)\n</code></pre> <p>Use short, action-oriented messages and throttle updates to meaningful stages instead of every percent to avoid noisy streams.</p>"},{"location":"guides/update-client-during-response/#trigger-client-side-effects-without-blocking","title":"Trigger client-side effects without blocking","text":"<p>Send <code>ClientEffectEvent</code> to trigger fire-and-forget UI work (such as refreshing a view, opening a modal, or showing a toast) without creating thread items or pausing the model stream.</p> <p>Client effects are ephemeral: they stream immediately to ChatKit.js, trigger your registered effect handler, and are not persisted to the thread history. Use client tool calls instead when you need a round-trip response from the client.</p>"},{"location":"guides/update-client-during-response/#stream-a-client-effect-from-your-server","title":"Stream a client effect from your server","text":"<p>Yield client effects directly from the <code>respond</code> or <code>action</code> method:</p> <pre><code>async def respond(...):\n    yield ClientEffectEvent(\n        name=\"highlight_text\",\n        data={\"index\": 142, \"length\": 35},\n    )\n</code></pre> <p>Or from tools, through <code>AgentContext</code>:</p> <pre><code>from agents import RunContextWrapper, function_tool\nfrom chatkit.agents import AgentContext\nfrom chatkit.types import ClientEffectEvent\n\n\n@function_tool()\nasync def highlight_text(ctx: RunContextWrapper[AgentContext], index: int, length: int):\n    await ctx.context.stream(\n        ClientEffectEvent(\n            name=\"highlight_text\",\n            data={\"index\": index, \"length\": length},\n        )\n    )\n</code></pre>"},{"location":"guides/update-client-during-response/#handle-the-client-effect-in-chatkitjs","title":"Handle the client effect in ChatKit.js","text":"<p>Register a client effect handler when initializing ChatKit on the client:</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  onEffect: async ({name, data}) =&gt; {\n    if (name === \"highlight_text\") {\n      const {index, length} = data;\n      highlightArticleText({index, length});\n      // No return value needed\n    }\n  },\n});\n</code></pre>"},{"location":"guides/update-client-during-response/#call-client-tools-mid-inference","title":"Call client tools mid-inference","text":"<p>Client tool calls let the agent invoke browser/app callbacks mid-inference. Register the tool on both client and server; when triggered, ChatKit pauses the model, sends the tool request to the client, and resumes with the returned result.</p> <p>Use client effects instead when you do not need to wait for the client callback response for the rest of your response.</p>"},{"location":"guides/update-client-during-response/#define-a-client-tool-in-your-agent","title":"Define a client tool in your agent","text":"<p>Set <code>ctx.context.client_tool_call</code> inside a tool and configure the agent to stop at that tool. Only one client tool call can run per turn. Include client tools in <code>stop_at_tool_names</code> so the model pauses while the client callback runs and returns its result.</p> <pre><code>from agents import Agent, RunContextWrapper, StopAtTools, function_tool\nfrom chatkit.agents import AgentContext, ClientToolCall\n\n\n@function_tool(description_override=\"Read the user's current canvas selection.\")\nasync def get_selected_canvas_nodes(ctx: RunContextWrapper[AgentContext]) -&gt; None:\n    ctx.context.client_tool_call = ClientToolCall(\n        name=\"get_selected_canvas_nodes\",\n        arguments={\"project\": my_project()},\n    )\n\n\nassistant = Agent[AgentContext](\n    ...,\n    tools=[get_selected_canvas_nodes],\n    # StopAtTools pauses model generation so the pending client callback can run and resume the run.\n    tool_use_behavior=StopAtTools(stop_at_tool_names=[get_selected_canvas_nodes.name]),\n)\n</code></pre>"},{"location":"guides/update-client-during-response/#register-the-client-tool-in-chatkitjs","title":"Register the client tool in ChatKit.js","text":"<p>Provide a matching callback when initializing ChatKit on the client. The function name must match the <code>ClientToolCall.name</code>, and its return value is sent back to the server to resume the run.</p> <pre><code>const chatkit = useChatKit({\n  // ...\n  onClientTool: async ({name, params}) =&gt; {\n    if (name === \"get_selected_canvas_nodes\") {\n      const {project} = params;\n      const nodes = myCanvas.getSelectedNodes(project);\n      return {\n        nodes: nodes.map((node) =&gt; ({id: node.id, kind: node.type})),\n      };\n    }\n  },\n});\n</code></pre>"},{"location":"guides/update-client-during-response/#stream-and-resume","title":"Stream and resume","text":"<p>In <code>respond</code>, stream via <code>stream_agent_response</code> as usual. ChatKit emits a pending client tool call item; the frontend runs your registered client tool, posts the output back, and the server continues the run.</p> <p>When the client posts the tool result, ChatKit stores it as a <code>ClientToolCallItem</code>. The continued inference after the client tool call handler returns the result feeds both the call and its output back to the model through <code>ThreadItemConverter.client_tool_call_to_input</code>, which emits a <code>function_call</code> plus matching <code>function_call_output</code> so the model sees the browser-provided context.</p>"}]}